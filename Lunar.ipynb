{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7764110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "from gym import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb0854e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.gymlibrary.ml/environments/box2d/lunar_lander/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a25ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using OU Noise\n",
    "class OUActionNoise:\n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None):\n",
    "        self.theta = theta\n",
    "        self.mean = mean\n",
    "        self.std_dev = std_deviation\n",
    "        self.dt = dt\n",
    "        self.x_initial = x_initial\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        x = (\n",
    "            self.x_prev\n",
    "            + self.theta * (self.mean - self.x_prev) * self.dt\n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
    "        )\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        if self.x_initial is not None:\n",
    "            self.x_prev = self.x_initial\n",
    "        else:\n",
    "            self.x_prev = np.zeros_like(self.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f235a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(num_states, num_actions, upper_bound, continuous=True, layer1=400, layer2=300):\n",
    "    # Initialize weights between -3e-3 and 3-e3\n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "\n",
    "    inputs = layers.Input(shape=(num_states,))\n",
    "    out = layers.Dense(layer1, activation=\"relu\")(inputs)\n",
    "    out = layers.Dense(layer2, activation=\"relu\")(out)\n",
    "    \n",
    "    # Different output activation based on discrete or continous version\n",
    "    if continuous:\n",
    "        outputs = layers.Dense(num_actions, activation=\"tanh\", kernel_initializer=last_init)(out)\n",
    "    else:\n",
    "        outputs = layers.Dense(num_actions, activation=\"softmax\", kernel_initializer=last_init)(out)\n",
    "\n",
    "    # Multiply to fill the whole action space which should be equal around 0\n",
    "    outputs = outputs * upper_bound\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def get_critic(num_states, num_actions, layer1=400, layer2=300):\n",
    "    # State as input\n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "\n",
    "    # Action as input\n",
    "    action_input = layers.Input(shape=(num_actions))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "\n",
    "    concat = layers.Concatenate()([state_out, action_out])\n",
    "\n",
    "    out = layers.Dense(layer1, activation=\"relu\")(concat)\n",
    "    out = layers.Dense(layer2, activation=\"relu\")(out)\n",
    "\n",
    "    outputs = layers.Dense(num_actions)(out)\n",
    "\n",
    "    # Make it into a keras model\n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "# This updates the weights in a slow manner which keeps stability\n",
    "@tf.function\n",
    "def update_target(target_weights, weights, tau):\n",
    "    for (a, b) in zip(target_weights, weights):\n",
    "        a.assign(b * tau + a * (1 - tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d09a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, num_states, num_actions, lower_bound, upper_bound, continuous=True,\n",
    "            buffer_capacity=50000, batch_size=64, std_dev=0.2, critic_lr=0.002,\n",
    "            actor_lr=0.001, gamma=0.99, tau=0.005):\n",
    "        \n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # For methods\n",
    "        self.lower_bound = lower_bound\n",
    "        self.upper_bound = upper_bound\n",
    "        self.continuous = continuous\n",
    "\n",
    "        # This is used to make sure we only sample from used buffer space\n",
    "        self.buffer_counter = 0\n",
    "\n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        \n",
    "        self.std_dev = std_dev\n",
    "        self.critic_lr = critic_lr\n",
    "        self.actor_lr = actor_lr\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        \n",
    "        self.actor_model = get_actor(num_states, num_actions, upper_bound, continuous=continuous, layer1=400, layer2=300)\n",
    "        self.critic_model = get_critic(num_states, num_actions, layer1=400, layer2=300)\n",
    "\n",
    "        self.target_actor = get_actor(num_states, num_actions, upper_bound, continuous=continuous, layer1=400, layer2=300)\n",
    "        self.target_critic = get_critic(num_states, num_actions, layer1=400, layer2=300)\n",
    "        \n",
    "        self.critic_optimizer = tf.keras.optimizers.Adam(learning_rate=critic_lr,beta_1=0.9,beta_2=0.999,epsilon=1e-07)\n",
    "        self.actor_optimizer = tf.keras.optimizers.Adam(learning_rate=actor_lr,beta_1=0.9,beta_2=0.999,epsilon=1e-07)\n",
    "        \n",
    "        # Making the weights equal initially\n",
    "        self.target_actor.set_weights(self.actor_model.get_weights())\n",
    "        self.target_critic.set_weights(self.critic_model.get_weights())\n",
    "        \n",
    "        self.ou_noise = OUActionNoise(mean=np.zeros(1), std_deviation=float(std_dev) * np.ones(1))\n",
    "    \n",
    "    # Makes a record of the outputted (s,a,r,s') obervation tuple\n",
    "    def record(self, obs_tuple):\n",
    "        # Reuse the same buffer replacing old entries\n",
    "        index = self.buffer_counter % self.buffer_capacity\n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "\n",
    "        self.buffer_counter += 1\n",
    "    \n",
    "    # Move the update and learn function from buffer to Agent to \"decrease\" scope\n",
    "    @tf.function\n",
    "    def update(self, state_batch, action_batch, reward_batch, next_state_batch,):\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = self.target_actor(next_state_batch, training=True)\n",
    "            y = reward_batch + self.gamma * self.target_critic(\n",
    "                [next_state_batch, target_actions], training=True\n",
    "            )\n",
    "            critic_value = self.critic_model([state_batch, action_batch], training=True)\n",
    "            critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n",
    "\n",
    "        critic_grad = tape.gradient(critic_loss, self.critic_model.trainable_variables)\n",
    "        self.critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, self.critic_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions = self.actor_model(state_batch, training=True)\n",
    "            critic_value = self.critic_model([state_batch, actions], training=True)\n",
    "\n",
    "            actor_loss = -tf.math.reduce_mean(critic_value)\n",
    "\n",
    "        actor_grad = tape.gradient(actor_loss, self.actor_model.trainable_variables)\n",
    "        self.actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, self.actor_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "    # We compute the loss and update parameters\n",
    "    def learn(self):\n",
    "        # Sample only valid data\n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        # Randomly sample indices\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "\n",
    "        self.update(state_batch, action_batch, reward_batch, next_state_batch)\n",
    "        \n",
    "    def policy(self, state, noise_object=0, use_noise=True, noise_mult=1):\n",
    "        # Default noise_object to 0 for when it is not needed\n",
    "        # For doing actions without added noise\n",
    "        if not use_noise:     \n",
    "            sampled_actions = tf.squeeze(self.actor_model(state)).numpy()\n",
    "            legal_action = np.clip(sampled_actions, self.lower_bound, self.upper_bound)\n",
    "        else:\n",
    "            sampled_actions = tf.squeeze(self.actor_model(state))\n",
    "            noise = noise_object()\n",
    "            # Adding noise to action\n",
    "            sampled_actions = sampled_actions.numpy() + noise * noise_mult\n",
    "\n",
    "            # We make sure action is within bounds\n",
    "            legal_action = np.clip(sampled_actions, self.lower_bound, self.upper_bound)\n",
    "            \n",
    "        if self.continuous:\n",
    "            return [np.squeeze(legal_action)]\n",
    "        else:\n",
    "            return int(np.squeeze(legal_action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f522c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed(x, episode):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42f9f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(total_trials=1, total_episodes=100, \n",
    "            buffer_capacity=50000, batch_size=64, std_dev=0.2, critic_lr=0.0002, render=False,\n",
    "            actor_lr=0.0001, gamma=0.99, tau=0.005, noise_mult=1, save_weights=True, \n",
    "            directory='Weights/', actor_name='actor', critic_name='critic',\n",
    "            gamma_func=fixed, tau_func=fixed, critic_lr_func=fixed, actor_lr_func=fixed,\n",
    "            noise_mult_func=fixed, std_dev_func=fixed, mean_number=20, output=True,\n",
    "            return_rewards=False, total_time=True, use_guide=False, solved=200,\n",
    "            continuous=True, environment='LunarLander-v2', seed=1453, start_steps=0,\n",
    "            gravity=-10.0, enable_wind=False, wind_power=15.0, turbulence_power=1.5):\n",
    "    tot_time = time.time()\n",
    "    \n",
    "    if environment == 'LunarLander-v2':\n",
    "        env = gym.make(\n",
    "            \"LunarLander-v2\",\n",
    "            continuous=continuous,\n",
    "            gravity=gravity,\n",
    "            enable_wind=enable_wind,\n",
    "            wind_power=wind_power,\n",
    "            turbulence_power=turbulence_power\n",
    "        )\n",
    "    else:\n",
    "        env = gym.make(environment)\n",
    "        \n",
    "    # Apply the seed\n",
    "    _ = env.reset(seed=seed)\n",
    "    \n",
    "    # Stepcount for random start\n",
    "    step = 0\n",
    "        \n",
    "    # This is needed to get the input size for the NN\n",
    "    num_states = env.observation_space.low.shape[0]\n",
    "    if continuous:\n",
    "        num_actions = env.action_space.shape[0]\n",
    "    else:\n",
    "        num_actions = 1\n",
    "\n",
    "    # Normalize action space according to https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
    "    action_space = spaces.Box(low=-1, high=1, shape=(num_actions,), dtype='float32')\n",
    "\n",
    "    # This is needed to clip the actions within the legal boundaries\n",
    "    upper_bound = action_space.high[0]\n",
    "    lower_bound = action_space.low[0]\n",
    "    \n",
    "    # To store reward history of each episode\n",
    "    ep_reward_list = []\n",
    "    # To store average reward history of last few episodes\n",
    "    avg_reward_list = []\n",
    "    # To separate assisted reward structures from the \"true\"\n",
    "    true_reward_list = []\n",
    "    true_avg_reward_list = []\n",
    "    \n",
    "    for trial in range(total_trials):\n",
    "\n",
    "        # add sublists for each trial\n",
    "        avg_reward_list.append([])\n",
    "        ep_reward_list.append([])\n",
    "        \n",
    "        true_reward_list.append([])\n",
    "        true_avg_reward_list.append([])\n",
    "        \n",
    "        agent = Agent(num_states=num_states, num_actions=num_actions, lower_bound=lower_bound, \n",
    "                upper_bound=upper_bound, continuous=continuous, buffer_capacity=buffer_capacity, \n",
    "                batch_size=batch_size, std_dev=std_dev, critic_lr=critic_lr, actor_lr=actor_lr, \n",
    "                gamma=gamma, tau=tau)\n",
    "\n",
    "        for ep in range(total_episodes):\n",
    "            # functions for different parameters\n",
    "            agent.gamma = gamma_func(gamma, ep)\n",
    "            agent.tau = tau_func(tau, ep)\n",
    "            agent.critic_lr = critic_lr_func(critic_lr, ep)\n",
    "            agent.actor_lr = actor_lr_func(actor_lr, ep)\n",
    "            agent.noise_mult = noise_mult_func(noise_mult, ep)\n",
    "            agent.std_dev = std_dev_func(std_dev, ep)\n",
    "            \n",
    "            # Used for time benchmarking\n",
    "            before = time.time()\n",
    "\n",
    "            prev_state = env.reset()\n",
    "            episodic_reward = 0\n",
    "            true_reward = 0\n",
    "\n",
    "            while True:\n",
    "                if render:\n",
    "                    env.render()\n",
    "                \n",
    "                tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
    "\n",
    "                if step >= start_steps:\n",
    "                    action = agent.policy(state=tf_prev_state, noise_object=agent.ou_noise, noise_mult=noise_mult)\n",
    "                    # To get the right format\n",
    "                    if continuous:\n",
    "                        action = action[0]\n",
    "                else:\n",
    "                    action = env.action_space.sample()\n",
    "                \n",
    "                step += 1\n",
    "                \n",
    "                # Recieve state and reward from environment.\n",
    "                state, reward, done, info = env.step(action)\n",
    "                \n",
    "                # Add this before eventual reward modification\n",
    "                true_reward += reward\n",
    "                \n",
    "                # Reward modification\n",
    "                if use_guide:\n",
    "                    # giving penalty for straying far from flags and having high speed\n",
    "                    # x max\n",
    "#                     reward -= int(abs(state[0]) > 0.15) * 2 * abs(state[0])\n",
    "#                     # y top\n",
    "#                     reward -= int(state[1] > 1) * state[1] / 2\n",
    "#                     # horizontal speed\n",
    "#                     reward -= int(abs(state[2]) > 1) * abs(state[2])\n",
    "#                     # down speed\n",
    "#                     reward -= int(state[3] <  -1) * abs(state[3])\n",
    "#                     # up speed\n",
    "#                     reward -= int(state[3] > 0.1) * 3 * state[3]\n",
    "                    reward -= abs(state[2]/2) + abs(state[3]) + (abs(state[0])) + (abs(state[1])/2)\n",
    "\n",
    "                agent.record((prev_state, action, reward, state))\n",
    "                episodic_reward += reward\n",
    "\n",
    "                agent.learn()\n",
    "                update_target(agent.target_actor.variables, agent.actor_model.variables, agent.tau)\n",
    "                update_target(agent.target_critic.variables, agent.critic_model.variables, agent.tau)\n",
    "\n",
    "                # End this episode if en episode is done\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "                prev_state = state\n",
    "\n",
    "            ep_reward_list[trial].append(episodic_reward)\n",
    "            \n",
    "            true_reward_list[trial].append(true_reward)\n",
    "            \n",
    "            true_avg_reward = np.mean(true_reward_list[trial][-mean_number:])\n",
    "            true_avg_reward_list[trial].append(true_avg_reward)\n",
    "\n",
    "            # Mean of last x episodes\n",
    "            avg_reward = np.mean(ep_reward_list[trial][-mean_number:])\n",
    "            if output:\n",
    "                print(\"Ep {} * AvgReward {:.2f} * true AvgReward {:.2f} * Reward {:.2f} * True Reward {:.2f} * time {:.2f} * step {}\"\n",
    "                  .format(ep, avg_reward, true_avg_reward, episodic_reward, true_reward, (time.time() - before), step))\n",
    "            avg_reward_list[trial].append(avg_reward)\n",
    "            \n",
    "            # stop if avg is solved\n",
    "            if true_avg_reward >= solved:\n",
    "                break\n",
    "\n",
    "        # Save weights naming\n",
    "        now = datetime.datetime.now()\n",
    "        timestamp = \"{}.{}.{}.{}.{}.{}\".format(now.year, now.month, now.day, now.hour, now.minute, now.second)\n",
    "        save_name = environment + '_' + str(total_episodes) + '_' + \\\n",
    "        str(buffer_capacity) + '_' + str(batch_size) + '_' + str(std_dev) + '_' + \\\n",
    "        str(critic_lr) + '_' + str(actor_lr) + '_' + str(gamma) + '_' + str(tau) + '_' + \\\n",
    "        str(noise_mult) + '_' + str(gamma_func.__name__) + '_' + str(tau_func.__name__) + '_' + \\\n",
    "        str(critic_lr_func.__name__) + '_' + str(actor_lr_func.__name__) + '_' + \\\n",
    "        str(noise_mult_func.__name__) + '_' + str(std_dev_func.__name__) + '_' + \\\n",
    "        str(mean_number) + '_' + str(use_guide) + '_' + str(solved) + '_' + \\\n",
    "        str(continuous) + '_' + str(start_steps) + '_' + str(gravity) + '_' + str(enable_wind) + '_' + \\\n",
    "        str(wind_power) + '_' + str(turbulence_power) + '_' + str(timestamp)\n",
    "        if save_weights:\n",
    "            agent.actor_model.save_weights(directory + actor_name + '-trial' + str(trial) + '_' + save_name + '.h5')\n",
    "            agent.critic_model.save_weights(directory + critic_name + '-trial' + str(trial) + '_' + save_name + '.h5')\n",
    "    \n",
    "    # Plotting graph\n",
    "    for idx, p in enumerate(true_avg_reward_list):\n",
    "        plt.plot(p, label=str(idx))\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"True Avg. Epsiodic Reward (\" + str(mean_number) + \")\")\n",
    "    plt.legend()\n",
    "    plt.savefig('Graphs/' + save_name + '.png')\n",
    "    plt.show()\n",
    "    \n",
    "    print('total time:',time.time() - tot_time, 's')\n",
    "    \n",
    "    # Return to be able to make graphs etc. later, or use the data for other stuff\n",
    "    if return_rewards:\n",
    "        return true_reward_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a57bcf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(total_episodes=10, actor_weights='Weights/actor-trial0.h5', render=False,\n",
    "        environment=\"LunarLander-v2\", continuous=True, gravity=-10.0, enable_wind=False,\n",
    "        wind_power=15.0, turbulence_power=1.5, seed=1453):\n",
    "    rewards = []\n",
    "    \n",
    "    env = gym.make(\n",
    "        environment,\n",
    "        continuous=continuous,\n",
    "        gravity=gravity,\n",
    "        enable_wind=enable_wind,\n",
    "        wind_power=wind_power,\n",
    "        turbulence_power=turbulence_power\n",
    "    )\n",
    "    \n",
    "        # This is needed to get the input size for the NN\n",
    "    num_states = env.observation_space.low.shape[0]\n",
    "    if continuous:\n",
    "        num_actions = env.action_space.shape[0]\n",
    "    else:\n",
    "        num_actions = 1\n",
    "\n",
    "    # Normalize action space according to https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
    "    action_space = spaces.Box(low=-1, high=1, shape=(num_actions,), dtype='float32')\n",
    "\n",
    "    # This is needed to clip the actions within the legal boundaries\n",
    "    upper_bound = action_space.high[0]\n",
    "    lower_bound = action_space.low[0]\n",
    "    \n",
    "    # Apply the seed\n",
    "    _ = env.reset(seed=seed)\n",
    "    \n",
    "    for ep in range(total_episodes):\n",
    "        ep_reward = 0\n",
    "        \n",
    "        # Used for time benchmarking\n",
    "        before = time.time()\n",
    "        \n",
    "        prev_state = env.reset()\n",
    "        agent = Agent(num_states=num_states, num_actions=num_actions, lower_bound=lower_bound, \n",
    "                upper_bound=upper_bound, continuous=continuous, buffer_capacity=0, batch_size=0, \n",
    "                std_dev=0, critic_lr=0, actor_lr=0, gamma=0, tau=0)\n",
    "        agent.actor_model.load_weights(actor_weights)\n",
    "        \n",
    "        while True:\n",
    "            if render:\n",
    "                env.render()\n",
    "\n",
    "            tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
    "\n",
    "            action = agent.policy(state=tf_prev_state, use_noise=False)\n",
    "            if continuous:\n",
    "                action = action[0]\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            ep_reward += reward\n",
    "\n",
    "            if done:\n",
    "                print(str(time.time() - before) + 's')\n",
    "                rewards.append(ep_reward)\n",
    "                break\n",
    "\n",
    "            prev_state = state\n",
    "            \n",
    "    plt.plot(rewards)\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"True reward\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a90fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random(total_episodes=10, render=False, environment=\"LunarLander-v2\", continuous=True,\n",
    "        gravity=-10.0, enable_wind=False, wind_power=15.0, turbulence_power=1.5, seed=1453):\n",
    "    rewards = []\n",
    "    \n",
    "    env = gym.make(\n",
    "        environment,\n",
    "        continuous=continuous,\n",
    "        gravity=gravity,\n",
    "        enable_wind=enable_wind,\n",
    "        wind_power=wind_power,\n",
    "        turbulence_power=turbulence_power,\n",
    "    )\n",
    "    \n",
    "    # Apply the seed\n",
    "    _ = env.reset(seed=seed)\n",
    "    \n",
    "    for ep in range(total_episodes):\n",
    "        ep_reward = 0\n",
    "        \n",
    "        # Used for time benchmarking\n",
    "        before = time.time()\n",
    "        \n",
    "        prev_state = env.reset()\n",
    "        \n",
    "        while True:\n",
    "            if render:\n",
    "                env.render()\n",
    "            action = env.action_space.sample()\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            ep_reward += reward\n",
    "\n",
    "            if done:\n",
    "                print(str(time.time() - before) + 's')\n",
    "                rewards.append(ep_reward)\n",
    "                break\n",
    "\n",
    "            prev_state = state\n",
    "            \n",
    "    plt.plot(rewards)\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"True reward\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83b8ba",
   "metadata": {},
   "source": [
    "---\n",
    "# Runs and tests\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cf6c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decreasing_std(x, episode):\n",
    "    return x/(1+(episode/500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe01ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decreasing_lr(x, episode):\n",
    "    return x/(1+(episode/500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa226be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 0 * AvgReward -205.31 * true AvgReward -205.31 * Reward -205.31 * True Reward -205.31 * time 1.61 * step 92\n",
      "Ep 1 * AvgReward -174.15 * true AvgReward -174.15 * Reward -142.99 * True Reward -142.99 * time 0.93 * step 189\n",
      "Ep 2 * AvgReward -162.64 * true AvgReward -162.64 * Reward -139.62 * True Reward -139.62 * time 1.04 * step 294\n",
      "Ep 3 * AvgReward -231.42 * true AvgReward -231.42 * Reward -437.78 * True Reward -437.78 * time 1.21 * step 403\n",
      "Ep 4 * AvgReward -249.86 * true AvgReward -249.86 * Reward -323.63 * True Reward -323.63 * time 0.99 * step 496\n",
      "Ep 5 * AvgReward -222.94 * true AvgReward -222.94 * Reward -88.29 * True Reward -88.29 * time 0.73 * step 563\n",
      "Ep 6 * AvgReward -208.63 * true AvgReward -208.63 * Reward -122.81 * True Reward -122.81 * time 0.91 * step 642\n",
      "Ep 7 * AvgReward -212.11 * true AvgReward -212.11 * Reward -236.49 * True Reward -236.49 * time 1.02 * step 740\n",
      "Ep 8 * AvgReward -234.52 * true AvgReward -234.52 * Reward -413.74 * True Reward -413.74 * time 1.39 * step 859\n",
      "Ep 9 * AvgReward -236.83 * true AvgReward -236.83 * Reward -257.68 * True Reward -257.68 * time 1.08 * step 954\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 11.304042100906372 s\n"
     ]
    }
   ],
   "source": [
    "run(total_trials=1, total_episodes=10, start_steps=10000, continuous=False, save_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38b4512c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 0 * AvgReward -66.91 * true AvgReward -66.91 * Reward -66.91 * True Reward -66.91 * time 2.89 * step 183\n",
      "Ep 1 * AvgReward -79.16 * true AvgReward -79.16 * Reward -91.42 * True Reward -91.42 * time 1.03 * step 265\n",
      "Ep 2 * AvgReward -185.53 * true AvgReward -185.53 * Reward -398.27 * True Reward -398.27 * time 1.33 * step 374\n",
      "Ep 3 * AvgReward -204.60 * true AvgReward -204.60 * Reward -261.81 * True Reward -261.81 * time 1.15 * step 463\n",
      "Ep 4 * AvgReward -245.05 * true AvgReward -245.05 * Reward -406.84 * True Reward -406.84 * time 1.51 * step 582\n",
      "Ep 5 * AvgReward -225.01 * true AvgReward -225.01 * Reward -124.84 * True Reward -124.84 * time 0.94 * step 665\n",
      "Ep 6 * AvgReward -246.62 * true AvgReward -246.62 * Reward -376.23 * True Reward -376.23 * time 1.05 * step 753\n",
      "Ep 7 * AvgReward -237.23 * true AvgReward -237.23 * Reward -171.53 * True Reward -171.53 * time 0.84 * step 826\n",
      "Ep 8 * AvgReward -254.77 * true AvgReward -254.77 * Reward -395.10 * True Reward -395.10 * time 1.07 * step 919\n",
      "Ep 9 * AvgReward -252.70 * true AvgReward -252.70 * Reward -234.07 * True Reward -234.07 * time 1.21 * step 1018\n",
      "Ep 10 * AvgReward -273.95 * true AvgReward -273.95 * Reward -486.47 * True Reward -486.47 * time 1.22 * step 1120\n",
      "Ep 11 * AvgReward -281.64 * true AvgReward -281.64 * Reward -366.19 * True Reward -366.19 * time 1.14 * step 1215\n",
      "Ep 12 * AvgReward -289.76 * true AvgReward -289.76 * Reward -387.16 * True Reward -387.16 * time 1.36 * step 1337\n",
      "Ep 13 * AvgReward -281.11 * true AvgReward -281.11 * Reward -168.77 * True Reward -168.77 * time 1.64 * step 1478\n",
      "Ep 14 * AvgReward -266.10 * true AvgReward -266.10 * Reward -55.85 * True Reward -55.85 * time 0.67 * step 1546\n",
      "Ep 15 * AvgReward -259.21 * true AvgReward -259.21 * Reward -155.99 * True Reward -155.99 * time 1.45 * step 1660\n",
      "Ep 16 * AvgReward -249.19 * true AvgReward -249.19 * Reward -88.82 * True Reward -88.82 * time 0.99 * step 1748\n",
      "Ep 17 * AvgReward -238.57 * true AvgReward -238.57 * Reward -57.94 * True Reward -57.94 * time 0.83 * step 1824\n",
      "Ep 18 * AvgReward -245.42 * true AvgReward -245.42 * Reward -368.73 * True Reward -368.73 * time 1.17 * step 1926\n",
      "Ep 19 * AvgReward -256.27 * true AvgReward -256.27 * Reward -462.41 * True Reward -462.41 * time 1.34 * step 2041\n",
      "Ep 20 * AvgReward -247.48 * true AvgReward -247.48 * Reward -71.77 * True Reward -71.77 * time 1.08 * step 2135\n",
      "Ep 21 * AvgReward -240.18 * true AvgReward -240.18 * Reward -86.87 * True Reward -86.87 * time 1.06 * step 2223\n",
      "Ep 22 * AvgReward -234.26 * true AvgReward -234.26 * Reward -104.02 * True Reward -104.02 * time 0.91 * step 2298\n",
      "Ep 23 * AvgReward -236.50 * true AvgReward -236.50 * Reward -287.98 * True Reward -287.98 * time 1.26 * step 2403\n",
      "Ep 24 * AvgReward -243.33 * true AvgReward -243.33 * Reward -407.37 * True Reward -407.37 * time 1.74 * step 2543\n",
      "Ep 25 * AvgReward -246.86 * true AvgReward -246.86 * Reward -335.15 * True Reward -335.15 * time 1.24 * step 2657\n",
      "Ep 26 * AvgReward -239.51 * true AvgReward -239.51 * Reward -48.39 * True Reward -48.39 * time 0.87 * step 2733\n",
      "Ep 27 * AvgReward -238.20 * true AvgReward -238.20 * Reward -202.80 * True Reward -202.80 * time 0.93 * step 2813\n",
      "Ep 28 * AvgReward -230.28 * true AvgReward -230.28 * Reward -8.51 * True Reward -8.51 * time 1.23 * step 2914\n",
      "Ep 29 * AvgReward -232.40 * true AvgReward -232.40 * Reward -293.86 * True Reward -293.86 * time 1.17 * step 3028\n",
      "Ep 30 * AvgReward -227.39 * true AvgReward -227.39 * Reward -76.94 * True Reward -76.94 * time 1.34 * step 3144\n",
      "Ep 31 * AvgReward -228.31 * true AvgReward -228.31 * Reward -257.00 * True Reward -257.00 * time 0.82 * step 3206\n",
      "Ep 32 * AvgReward -225.54 * true AvgReward -225.54 * Reward -136.97 * True Reward -136.97 * time 1.45 * step 3334\n",
      "Ep 33 * AvgReward -220.53 * true AvgReward -220.53 * Reward -54.98 * True Reward -54.98 * time 0.78 * step 3404\n",
      "Ep 34 * AvgReward -216.35 * true AvgReward -216.35 * Reward -74.14 * True Reward -74.14 * time 0.81 * step 3473\n",
      "Ep 35 * AvgReward -214.43 * true AvgReward -214.43 * Reward -147.29 * True Reward -147.29 * time 1.10 * step 3562\n",
      "Ep 36 * AvgReward -209.23 * true AvgReward -209.23 * Reward -22.07 * True Reward -22.07 * time 1.24 * step 3673\n",
      "Ep 37 * AvgReward -207.30 * true AvgReward -207.30 * Reward -135.78 * True Reward -135.78 * time 1.35 * step 3786\n",
      "Ep 38 * AvgReward -206.18 * true AvgReward -206.18 * Reward -163.95 * True Reward -163.95 * time 1.19 * step 3890\n",
      "Ep 39 * AvgReward -210.80 * true AvgReward -210.80 * Reward -390.78 * True Reward -390.78 * time 1.16 * step 3984\n",
      "Ep 40 * AvgReward -217.25 * true AvgReward -217.25 * Reward -324.98 * True Reward -324.98 * time 1.00 * step 4064\n",
      "Ep 41 * AvgReward -223.61 * true AvgReward -223.61 * Reward -345.77 * True Reward -345.77 * time 1.60 * step 4195\n",
      "Ep 42 * AvgReward -223.64 * true AvgReward -223.64 * Reward -399.36 * True Reward -399.36 * time 1.50 * step 4314\n",
      "Ep 43 * AvgReward -221.37 * true AvgReward -221.37 * Reward -171.08 * True Reward -171.08 * time 1.33 * step 4423\n",
      "Ep 44 * AvgReward -212.54 * true AvgReward -212.54 * Reward -53.63 * True Reward -53.63 * time 1.31 * step 4531\n",
      "Ep 45 * AvgReward -213.74 * true AvgReward -213.74 * Reward -172.79 * True Reward -172.79 * time 1.33 * step 4631\n",
      "Ep 46 * AvgReward -212.42 * true AvgReward -212.42 * Reward -323.43 * True Reward -323.43 * time 1.30 * step 4755\n",
      "Ep 47 * AvgReward -212.30 * true AvgReward -212.30 * Reward -166.82 * True Reward -166.82 * time 0.83 * step 4853\n",
      "Ep 48 * AvgReward -204.90 * true AvgReward -204.90 * Reward -99.20 * True Reward -99.20 * time 1.39 * step 4988\n",
      "Ep 49 * AvgReward -199.05 * true AvgReward -199.05 * Reward 0.08 * True Reward 0.08 * time 0.99 * step 5089\n",
      "Ep 50 * AvgReward -194.01 * true AvgReward -194.01 * Reward -285.05 * True Reward -285.05 * time 1.51 * step 5245\n",
      "Ep 51 * AvgReward -191.76 * true AvgReward -191.76 * Reward -276.03 * True Reward -276.03 * time 1.13 * step 5350\n",
      "Ep 52 * AvgReward -190.21 * true AvgReward -190.21 * Reward -325.19 * True Reward -325.19 * time 1.93 * step 5521\n",
      "Ep 53 * AvgReward -192.59 * true AvgReward -192.59 * Reward -263.94 * True Reward -263.94 * time 1.08 * step 5627\n",
      "Ep 54 * AvgReward -192.21 * true AvgReward -192.21 * Reward -40.88 * True Reward -40.88 * time 1.88 * step 5787\n",
      "Ep 55 * AvgReward -197.99 * true AvgReward -197.99 * Reward -386.85 * True Reward -386.85 * time 0.91 * step 5874\n",
      "Ep 56 * AvgReward -203.99 * true AvgReward -203.99 * Reward -329.12 * True Reward -329.12 * time 0.87 * step 5958\n",
      "Ep 57 * AvgReward -211.42 * true AvgReward -211.42 * Reward -354.94 * True Reward -354.94 * time 1.07 * step 6045\n",
      "Ep 58 * AvgReward -204.36 * true AvgReward -204.36 * Reward -86.27 * True Reward -86.27 * time 0.93 * step 6120\n",
      "Ep 59 * AvgReward -194.63 * true AvgReward -194.63 * Reward -73.17 * True Reward -73.17 * time 0.80 * step 6189\n",
      "Ep 60 * AvgReward -203.22 * true AvgReward -203.22 * Reward -415.36 * True Reward -415.36 * time 1.47 * step 6319\n",
      "Ep 61 * AvgReward -209.97 * true AvgReward -209.97 * Reward -356.99 * True Reward -356.99 * time 1.09 * step 6412\n",
      "Ep 62 * AvgReward -214.28 * true AvgReward -214.28 * Reward -276.56 * True Reward -276.56 * time 1.11 * step 6502\n",
      "Ep 63 * AvgReward -211.76 * true AvgReward -211.76 * Reward -187.04 * True Reward -187.04 * time 1.28 * step 6608\n",
      "Ep 64 * AvgReward -203.28 * true AvgReward -203.28 * Reward -68.20 * True Reward -68.20 * time 1.62 * step 6757\n",
      "Ep 65 * AvgReward -205.15 * true AvgReward -205.15 * Reward -410.01 * True Reward -410.01 * time 1.09 * step 6844\n",
      "Ep 66 * AvgReward -210.71 * true AvgReward -210.71 * Reward -270.93 * True Reward -270.93 * time 0.85 * step 6913\n",
      "Ep 67 * AvgReward -213.08 * true AvgReward -213.08 * Reward -297.29 * True Reward -297.29 * time 1.29 * step 7019\n",
      "Ep 68 * AvgReward -219.40 * true AvgReward -219.40 * Reward -261.31 * True Reward -261.31 * time 1.06 * step 7111\n",
      "Ep 69 * AvgReward -218.81 * true AvgReward -218.81 * Reward -270.47 * True Reward -270.47 * time 1.15 * step 7214\n",
      "Ep 70 * AvgReward -220.21 * true AvgReward -220.21 * Reward -132.69 * True Reward -132.69 * time 0.86 * step 7295\n",
      "Ep 71 * AvgReward -219.21 * true AvgReward -219.21 * Reward -217.13 * True Reward -217.13 * time 0.98 * step 7393\n",
      "Ep 72 * AvgReward -222.36 * true AvgReward -222.36 * Reward -262.80 * True Reward -262.80 * time 1.87 * step 7564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 73 * AvgReward -228.81 * true AvgReward -228.81 * Reward -313.14 * True Reward -313.14 * time 1.18 * step 7673\n",
      "Ep 74 * AvgReward -228.64 * true AvgReward -228.64 * Reward -67.31 * True Reward -67.31 * time 0.94 * step 7765\n",
      "Ep 75 * AvgReward -227.34 * true AvgReward -227.34 * Reward -95.30 * True Reward -95.30 * time 1.72 * step 7920\n",
      "Ep 76 * AvgReward -234.55 * true AvgReward -234.55 * Reward -310.67 * True Reward -310.67 * time 1.29 * step 8038\n",
      "Ep 77 * AvgReward -232.65 * true AvgReward -232.65 * Reward -59.70 * True Reward -59.70 * time 0.80 * step 8111\n",
      "Ep 78 * AvgReward -234.83 * true AvgReward -234.83 * Reward -251.17 * True Reward -251.17 * time 1.90 * step 8281\n",
      "Ep 79 * AvgReward -228.27 * true AvgReward -228.27 * Reward -128.13 * True Reward -128.13 * time 1.36 * step 8409\n",
      "Ep 80 * AvgReward -222.87 * true AvgReward -222.87 * Reward -109.10 * True Reward -109.10 * time 1.79 * step 8568\n",
      "Ep 81 * AvgReward -214.94 * true AvgReward -214.94 * Reward -28.46 * True Reward -28.46 * time 0.85 * step 8658\n",
      "Ep 82 * AvgReward -212.31 * true AvgReward -212.31 * Reward -294.31 * True Reward -294.31 * time 0.94 * step 8754\n",
      "Ep 83 * AvgReward -209.31 * true AvgReward -209.31 * Reward -51.07 * True Reward -51.07 * time 1.84 * step 8944\n",
      "Ep 84 * AvgReward -213.38 * true AvgReward -213.38 * Reward -216.59 * True Reward -216.59 * time 1.22 * step 9053\n",
      "Ep 85 * AvgReward -215.27 * true AvgReward -215.27 * Reward -248.37 * True Reward -248.37 * time 1.45 * step 9182\n",
      "Ep 86 * AvgReward -214.58 * true AvgReward -214.58 * Reward -295.69 * True Reward -295.69 * time 1.60 * step 9324\n",
      "Ep 87 * AvgReward -212.01 * true AvgReward -212.01 * Reward -64.22 * True Reward -64.22 * time 0.90 * step 9403\n",
      "Ep 88 * AvgReward -217.87 * true AvgReward -217.87 * Reward -333.44 * True Reward -333.44 * time 1.06 * step 9499\n",
      "Ep 89 * AvgReward -219.32 * true AvgReward -219.32 * Reward -58.00 * True Reward -58.00 * time 0.74 * step 9574\n",
      "Ep 90 * AvgReward -217.58 * true AvgReward -217.58 * Reward -215.45 * True Reward -215.45 * time 1.20 * step 9679\n",
      "Ep 91 * AvgReward -218.78 * true AvgReward -218.78 * Reward -324.07 * True Reward -324.07 * time 0.93 * step 9762\n",
      "Ep 92 * AvgReward -219.07 * true AvgReward -219.07 * Reward -336.78 * True Reward -336.78 * time 0.88 * step 9843\n",
      "Ep 93 * AvgReward -222.52 * true AvgReward -222.52 * Reward -401.94 * True Reward -401.94 * time 2.78 * step 10075\n",
      "Ep 94 * AvgReward -239.40 * true AvgReward -239.40 * Reward -715.81 * True Reward -715.81 * time 0.96 * step 10138\n",
      "Ep 95 * AvgReward -255.64 * true AvgReward -255.64 * Reward -1036.77 * True Reward -1036.77 * time 1.17 * step 10225\n",
      "Ep 96 * AvgReward -304.33 * true AvgReward -304.33 * Reward -2276.68 * True Reward -2276.68 * time 1.99 * step 10373\n",
      "Ep 97 * AvgReward -319.11 * true AvgReward -319.11 * Reward -946.12 * True Reward -946.12 * time 1.10 * step 10459\n",
      "Ep 98 * AvgReward -343.67 * true AvgReward -343.67 * Reward -1068.71 * True Reward -1068.71 * time 1.24 * step 10548\n",
      "Ep 99 * AvgReward -377.79 * true AvgReward -377.79 * Reward -1437.68 * True Reward -1437.68 * time 1.54 * step 10655\n",
      "Ep 100 * AvgReward -393.93 * true AvgReward -393.93 * Reward -1061.28 * True Reward -1061.28 * time 1.26 * step 10741\n",
      "Ep 101 * AvgReward -405.82 * true AvgReward -405.82 * Reward -832.54 * True Reward -832.54 * time 0.94 * step 10808\n",
      "Ep 102 * AvgReward -420.67 * true AvgReward -420.67 * Reward -870.55 * True Reward -870.55 * time 1.31 * step 10898\n",
      "Ep 103 * AvgReward -445.06 * true AvgReward -445.06 * Reward -1162.47 * True Reward -1162.47 * time 1.39 * step 10989\n",
      "Ep 104 * AvgReward -489.60 * true AvgReward -489.60 * Reward -1849.65 * True Reward -1849.65 * time 1.85 * step 11113\n",
      "Ep 105 * AvgReward -498.31 * true AvgReward -498.31 * Reward -758.54 * True Reward -758.54 * time 1.05 * step 11178\n",
      "Ep 106 * AvgReward -509.27 * true AvgReward -509.27 * Reward -709.44 * True Reward -709.44 * time 0.77 * step 11232\n",
      "Ep 107 * AvgReward -519.96 * true AvgReward -519.96 * Reward -724.66 * True Reward -724.66 * time 0.84 * step 11292\n",
      "Ep 108 * AvgReward -563.02 * true AvgReward -563.02 * Reward -1983.96 * True Reward -1983.96 * time 2.01 * step 11424\n",
      "Ep 109 * AvgReward -576.34 * true AvgReward -576.34 * Reward -803.27 * True Reward -803.27 * time 0.94 * step 11489\n",
      "Ep 110 * AvgReward -593.73 * true AvgReward -593.73 * Reward -828.13 * True Reward -828.13 * time 1.02 * step 11555\n",
      "Ep 111 * AvgReward -621.03 * true AvgReward -621.03 * Reward -1309.22 * True Reward -1309.22 * time 1.85 * step 11679\n",
      "Ep 112 * AvgReward -633.05 * true AvgReward -633.05 * Reward -743.44 * True Reward -743.44 * time 0.88 * step 11737\n",
      "Ep 113 * AvgReward -648.13 * true AvgReward -648.13 * Reward -916.31 * True Reward -916.31 * time 1.51 * step 11841\n",
      "Ep 114 * AvgReward -668.94 * true AvgReward -668.94 * Reward -900.01 * True Reward -900.01 * time 1.33 * step 11932\n",
      "Ep 115 * AvgReward -685.09 * true AvgReward -685.09 * Reward -741.17 * True Reward -741.17 * time 0.92 * step 11994\n",
      "Ep 116 * AvgReward -698.25 * true AvgReward -698.25 * Reward -837.20 * True Reward -837.20 * time 1.09 * step 12063\n",
      "Ep 117 * AvgReward -724.32 * true AvgReward -724.32 * Reward -1102.30 * True Reward -1102.30 * time 1.33 * step 12152\n",
      "Ep 118 * AvgReward -738.54 * true AvgReward -738.54 * Reward -819.94 * True Reward -819.94 * time 1.05 * step 12223\n",
      "Ep 119 * AvgReward -784.37 * true AvgReward -784.37 * Reward -1961.50 * True Reward -1961.50 * time 1.98 * step 12354\n",
      "Ep 120 * AvgReward -808.82 * true AvgReward -808.82 * Reward -1086.97 * True Reward -1086.97 * time 1.35 * step 12440\n",
      "Ep 121 * AvgReward -855.05 * true AvgReward -855.05 * Reward -1877.56 * True Reward -1877.56 * time 1.98 * step 12567\n",
      "Ep 122 * AvgReward -865.99 * true AvgReward -865.99 * Reward -732.08 * True Reward -732.08 * time 1.31 * step 12651\n",
      "Ep 123 * AvgReward -884.11 * true AvgReward -884.11 * Reward -775.98 * True Reward -775.98 * time 0.90 * step 12717\n",
      "Ep 124 * AvgReward -900.80 * true AvgReward -900.80 * Reward -883.96 * True Reward -883.96 * time 1.19 * step 12793\n",
      "Ep 125 * AvgReward -914.20 * true AvgReward -914.20 * Reward -784.58 * True Reward -784.58 * time 0.81 * step 12852\n",
      "Ep 126 * AvgReward -937.99 * true AvgReward -937.99 * Reward -1247.07 * True Reward -1247.07 * time 1.36 * step 12947\n",
      "Ep 127 * AvgReward -956.50 * true AvgReward -956.50 * Reward -804.84 * True Reward -804.84 * time 0.89 * step 13007\n",
      "Ep 128 * AvgReward -966.18 * true AvgReward -966.18 * Reward -720.49 * True Reward -720.49 * time 0.75 * step 13066\n",
      "Ep 129 * AvgReward -1014.93 * true AvgReward -1014.93 * Reward -2008.19 * True Reward -2008.19 * time 1.95 * step 13199\n",
      "Ep 130 * AvgReward -1027.97 * true AvgReward -1027.97 * Reward -736.82 * True Reward -736.82 * time 0.94 * step 13258\n",
      "Ep 131 * AvgReward -1039.75 * true AvgReward -1039.75 * Reward -795.22 * True Reward -795.22 * time 0.86 * step 13319\n",
      "Ep 132 * AvgReward -1058.72 * true AvgReward -1058.72 * Reward -1095.91 * True Reward -1095.91 * time 1.35 * step 13411\n",
      "Ep 133 * AvgReward -1072.14 * true AvgReward -1072.14 * Reward -938.64 * True Reward -938.64 * time 0.97 * step 13490\n",
      "Ep 134 * AvgReward -1098.38 * true AvgReward -1098.38 * Reward -1765.49 * True Reward -1765.49 * time 1.81 * step 13615\n",
      "Ep 135 * AvgReward -1093.55 * true AvgReward -1093.55 * Reward -843.44 * True Reward -843.44 * time 0.91 * step 13682\n",
      "Ep 136 * AvgReward -1056.04 * true AvgReward -1056.04 * Reward -776.45 * True Reward -776.45 * time 0.74 * step 13742\n",
      "Ep 137 * AvgReward -1053.38 * true AvgReward -1053.38 * Reward -839.37 * True Reward -839.37 * time 1.23 * step 13819\n",
      "Ep 138 * AvgReward -1057.24 * true AvgReward -1057.24 * Reward -1223.20 * True Reward -1223.20 * time 1.57 * step 13928\n",
      "Ep 139 * AvgReward -1054.34 * true AvgReward -1054.34 * Reward -1321.81 * True Reward -1321.81 * time 1.36 * step 14035\n",
      "Ep 140 * AvgReward -1050.08 * true AvgReward -1050.08 * Reward -890.74 * True Reward -890.74 * time 1.13 * step 14124\n",
      "Ep 141 * AvgReward -1048.05 * true AvgReward -1048.05 * Reward -751.52 * True Reward -751.52 * time 0.89 * step 14192\n",
      "Ep 142 * AvgReward -1036.74 * true AvgReward -1036.74 * Reward -418.06 * True Reward -418.06 * time 1.35 * step 14289\n",
      "Ep 143 * AvgReward -1027.40 * true AvgReward -1027.40 * Reward -789.00 * True Reward -789.00 * time 1.38 * step 14382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 144 * AvgReward -999.74 * true AvgReward -999.74 * Reward -743.07 * True Reward -743.07 * time 1.02 * step 14447\n",
      "Ep 145 * AvgReward -1000.57 * true AvgReward -1000.57 * Reward -791.71 * True Reward -791.71 * time 1.16 * step 14523\n",
      "Ep 146 * AvgReward -1012.67 * true AvgReward -1012.67 * Reward -1193.48 * True Reward -1193.48 * time 1.86 * step 14646\n",
      "Ep 147 * AvgReward -1009.10 * true AvgReward -1009.10 * Reward -581.93 * True Reward -581.93 * time 1.46 * step 14748\n",
      "Ep 148 * AvgReward -1004.66 * true AvgReward -1004.66 * Reward -1806.42 * True Reward -1806.42 * time 2.16 * step 14891\n",
      "Ep 149 * AvgReward -1003.57 * true AvgReward -1003.57 * Reward -759.48 * True Reward -759.48 * time 0.97 * step 14955\n",
      "Ep 150 * AvgReward -1004.13 * true AvgReward -1004.13 * Reward -850.57 * True Reward -850.57 * time 1.14 * step 15030\n",
      "Ep 151 * AvgReward -997.62 * true AvgReward -997.62 * Reward -1048.91 * True Reward -1048.91 * time 1.40 * step 15122\n",
      "Ep 152 * AvgReward -998.83 * true AvgReward -998.83 * Reward -791.81 * True Reward -791.81 * time 1.04 * step 15191\n",
      "Ep 153 * AvgReward -1024.63 * true AvgReward -1024.63 * Reward -1948.43 * True Reward -1948.43 * time 2.15 * step 15335\n",
      "Ep 154 * AvgReward -1039.11 * true AvgReward -1039.11 * Reward -1479.07 * True Reward -1479.07 * time 1.48 * step 15448\n",
      "Ep 155 * AvgReward -1040.99 * true AvgReward -1040.99 * Reward -816.26 * True Reward -816.26 * time 1.04 * step 15515\n",
      "Ep 156 * AvgReward -1049.73 * true AvgReward -1049.73 * Reward -1187.06 * True Reward -1187.06 * time 1.21 * step 15606\n",
      "Ep 157 * AvgReward -1072.54 * true AvgReward -1072.54 * Reward -2014.43 * True Reward -2014.43 * time 1.97 * step 15741\n",
      "Ep 158 * AvgReward -1088.89 * true AvgReward -1088.89 * Reward -1474.03 * True Reward -1474.03 * time 1.84 * step 15868\n",
      "Ep 159 * AvgReward -1061.50 * true AvgReward -1061.50 * Reward -865.93 * True Reward -865.93 * time 1.36 * step 15956\n",
      "Ep 160 * AvgReward -1053.34 * true AvgReward -1053.34 * Reward -760.72 * True Reward -760.72 * time 1.01 * step 16019\n",
      "Ep 161 * AvgReward -1028.59 * true AvgReward -1028.59 * Reward -887.55 * True Reward -887.55 * time 1.46 * step 16118\n",
      "Ep 162 * AvgReward -1044.30 * true AvgReward -1044.30 * Reward -1360.31 * True Reward -1360.31 * time 1.56 * step 16224\n",
      "Ep 163 * AvgReward -1071.89 * true AvgReward -1071.89 * Reward -1879.79 * True Reward -1879.79 * time 2.06 * step 16355\n",
      "Ep 164 * AvgReward -1084.72 * true AvgReward -1084.72 * Reward -1397.06 * True Reward -1397.06 * time 1.57 * step 16466\n",
      "Ep 165 * AvgReward -1096.70 * true AvgReward -1096.70 * Reward -1263.91 * True Reward -1263.91 * time 1.38 * step 16561\n",
      "Ep 166 * AvgReward -1100.96 * true AvgReward -1100.96 * Reward -1417.25 * True Reward -1417.25 * time 1.52 * step 16676\n",
      "Ep 167 * AvgReward -1111.45 * true AvgReward -1111.45 * Reward -1224.53 * True Reward -1224.53 * time 1.39 * step 16772\n",
      "Ep 168 * AvgReward -1115.63 * true AvgReward -1115.63 * Reward -887.73 * True Reward -887.73 * time 1.18 * step 16851\n",
      "Ep 169 * AvgReward -1100.28 * true AvgReward -1100.28 * Reward -1394.12 * True Reward -1394.12 * time 1.56 * step 16959\n",
      "Ep 170 * AvgReward -1103.94 * true AvgReward -1103.94 * Reward -883.20 * True Reward -883.20 * time 0.94 * step 17040\n",
      "Ep 171 * AvgReward -1102.19 * true AvgReward -1102.19 * Reward -725.26 * True Reward -725.26 * time 0.75 * step 17099\n",
      "Ep 172 * AvgReward -1095.20 * true AvgReward -1095.20 * Reward -816.08 * True Reward -816.08 * time 1.03 * step 17181\n",
      "Ep 173 * AvgReward -1099.79 * true AvgReward -1099.79 * Reward -1122.50 * True Reward -1122.50 * time 1.14 * step 17272\n",
      "Ep 174 * AvgReward -1075.06 * true AvgReward -1075.06 * Reward -776.11 * True Reward -776.11 * time 0.85 * step 17334\n",
      "Ep 175 * AvgReward -1076.41 * true AvgReward -1076.41 * Reward -897.72 * True Reward -897.72 * time 1.13 * step 17417\n",
      "Ep 176 * AvgReward -1073.96 * true AvgReward -1073.96 * Reward -678.09 * True Reward -678.09 * time 0.76 * step 17478\n",
      "Ep 177 * AvgReward -1071.27 * true AvgReward -1071.27 * Reward -731.81 * True Reward -731.81 * time 1.17 * step 17566\n",
      "Ep 178 * AvgReward -1058.69 * true AvgReward -1058.69 * Reward -720.15 * True Reward -720.15 * time 0.93 * step 17640\n",
      "Ep 179 * AvgReward -1034.97 * true AvgReward -1034.97 * Reward -372.81 * True Reward -372.81 * time 1.30 * step 17734\n",
      "Ep 180 * AvgReward -1030.86 * true AvgReward -1030.86 * Reward -726.35 * True Reward -726.35 * time 1.10 * step 17811\n",
      "Ep 181 * AvgReward -1038.61 * true AvgReward -1038.61 * Reward -1061.79 * True Reward -1061.79 * time 1.59 * step 17921\n",
      "Ep 182 * AvgReward -1046.52 * true AvgReward -1046.52 * Reward -734.56 * True Reward -734.56 * time 1.26 * step 18018\n",
      "Ep 183 * AvgReward -1032.11 * true AvgReward -1032.11 * Reward -212.52 * True Reward -212.52 * time 1.73 * step 18149\n",
      "Ep 184 * AvgReward -1013.45 * true AvgReward -1013.45 * Reward 3.39 * True Reward 3.39 * time 1.13 * step 18241\n",
      "Ep 185 * AvgReward -1000.63 * true AvgReward -1000.63 * Reward -279.04 * True Reward -279.04 * time 1.43 * step 18346\n",
      "Ep 186 * AvgReward -979.85 * true AvgReward -979.85 * Reward -362.02 * True Reward -362.02 * time 1.16 * step 18442\n",
      "Ep 187 * AvgReward -989.80 * true AvgReward -989.80 * Reward -979.84 * True Reward -979.84 * time 2.37 * step 18619\n",
      "Ep 188 * AvgReward -960.97 * true AvgReward -960.97 * Reward -653.57 * True Reward -653.57 * time 0.83 * step 18686\n",
      "Ep 189 * AvgReward -962.97 * true AvgReward -962.97 * Reward -839.32 * True Reward -839.32 * time 1.65 * step 18818\n",
      "Ep 190 * AvgReward -974.32 * true AvgReward -974.32 * Reward -1304.71 * True Reward -1304.71 * time 1.93 * step 18967\n",
      "Ep 191 * AvgReward -966.00 * true AvgReward -966.00 * Reward -716.03 * True Reward -716.03 * time 1.28 * step 19055\n",
      "Ep 192 * AvgReward -974.97 * true AvgReward -974.97 * Reward -1150.38 * True Reward -1150.38 * time 1.33 * step 19161\n",
      "Ep 193 * AvgReward -945.10 * true AvgReward -945.10 * Reward -753.63 * True Reward -753.63 * time 0.88 * step 19232\n",
      "Ep 194 * AvgReward -926.98 * true AvgReward -926.98 * Reward -754.36 * True Reward -754.36 * time 0.71 * step 19290\n",
      "Ep 195 * AvgReward -930.52 * true AvgReward -930.52 * Reward -958.02 * True Reward -958.02 * time 0.98 * step 19372\n",
      "Ep 196 * AvgReward -926.22 * true AvgReward -926.22 * Reward -1015.04 * True Reward -1015.04 * time 1.18 * step 19457\n",
      "Ep 197 * AvgReward -896.74 * true AvgReward -896.74 * Reward -835.16 * True Reward -835.16 * time 0.82 * step 19526\n",
      "Ep 198 * AvgReward -881.94 * true AvgReward -881.94 * Reward -881.86 * True Reward -881.86 * time 0.99 * step 19599\n",
      "Ep 199 * AvgReward -884.05 * true AvgReward -884.05 * Reward -950.65 * True Reward -950.65 * time 1.19 * step 19696\n",
      "Ep 200 * AvgReward -883.89 * true AvgReward -883.89 * Reward -754.28 * True Reward -754.28 * time 0.98 * step 19766\n",
      "Ep 201 * AvgReward -880.08 * true AvgReward -880.08 * Reward -735.03 * True Reward -735.03 * time 1.29 * step 19854\n",
      "Ep 202 * AvgReward -878.88 * true AvgReward -878.88 * Reward -1312.37 * True Reward -1312.37 * time 1.31 * step 19951\n",
      "Ep 203 * AvgReward -850.87 * true AvgReward -850.87 * Reward -759.29 * True Reward -759.29 * time 0.76 * step 20015\n",
      "Ep 204 * AvgReward -838.90 * true AvgReward -838.90 * Reward -918.42 * True Reward -918.42 * time 0.96 * step 20092\n",
      "Ep 205 * AvgReward -826.24 * true AvgReward -826.24 * Reward -757.57 * True Reward -757.57 * time 0.87 * step 20155\n",
      "Ep 206 * AvgReward -812.98 * true AvgReward -812.98 * Reward -886.70 * True Reward -886.70 * time 1.17 * step 20231\n",
      "Ep 207 * AvgReward -801.97 * true AvgReward -801.97 * Reward -784.20 * True Reward -784.20 * time 0.82 * step 20291\n",
      "Ep 208 * AvgReward -808.41 * true AvgReward -808.41 * Reward -1145.22 * True Reward -1145.22 * time 1.37 * step 20380\n",
      "Ep 209 * AvgReward -794.73 * true AvgReward -794.73 * Reward -846.84 * True Reward -846.84 * time 0.82 * step 20449\n",
      "Ep 210 * AvgReward -791.40 * true AvgReward -791.40 * Reward -750.08 * True Reward -750.08 * time 0.70 * step 20508\n",
      "Ep 211 * AvgReward -803.63 * true AvgReward -803.63 * Reward -1214.57 * True Reward -1214.57 * time 1.38 * step 20610\n",
      "Ep 212 * AvgReward -816.49 * true AvgReward -816.49 * Reward -1330.24 * True Reward -1330.24 * time 1.39 * step 20710\n",
      "Ep 213 * AvgReward -826.92 * true AvgReward -826.92 * Reward -1539.98 * True Reward -1539.98 * time 1.57 * step 20823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 214 * AvgReward -839.90 * true AvgReward -839.90 * Reward -1294.97 * True Reward -1294.97 * time 1.22 * step 20921\n",
      "Ep 215 * AvgReward -862.81 * true AvgReward -862.81 * Reward -1814.23 * True Reward -1814.23 * time 1.69 * step 21052\n",
      "Ep 216 * AvgReward -866.29 * true AvgReward -866.29 * Reward -817.20 * True Reward -817.20 * time 0.80 * step 21114\n",
      "Ep 217 * AvgReward -895.39 * true AvgReward -895.39 * Reward -1896.01 * True Reward -1896.01 * time 1.72 * step 21251\n",
      "Ep 218 * AvgReward -923.19 * true AvgReward -923.19 * Reward -1832.11 * True Reward -1832.11 * time 2.16 * step 21402\n",
      "Ep 219 * AvgReward -931.51 * true AvgReward -931.51 * Reward -705.50 * True Reward -705.50 * time 1.02 * step 21464\n",
      "Ep 220 * AvgReward -933.65 * true AvgReward -933.65 * Reward -812.06 * True Reward -812.06 * time 1.11 * step 21536\n",
      "Ep 221 * AvgReward -944.03 * true AvgReward -944.03 * Reward -1477.13 * True Reward -1477.13 * time 2.30 * step 21690\n",
      "Ep 222 * AvgReward -943.27 * true AvgReward -943.27 * Reward -703.91 * True Reward -703.91 * time 0.96 * step 21752\n",
      "Ep 223 * AvgReward -948.13 * true AvgReward -948.13 * Reward -406.91 * True Reward -406.91 * time 1.58 * step 21856\n",
      "Ep 224 * AvgReward -979.95 * true AvgReward -979.95 * Reward -1269.65 * True Reward -1269.65 * time 1.77 * step 21972\n",
      "Ep 225 * AvgReward -988.24 * true AvgReward -988.24 * Reward -610.36 * True Reward -610.36 * time 1.00 * step 22036\n",
      "Ep 226 * AvgReward -1002.06 * true AvgReward -1002.06 * Reward -915.01 * True Reward -915.01 * time 1.69 * step 22146\n",
      "Ep 227 * AvgReward -996.75 * true AvgReward -996.75 * Reward -767.24 * True Reward -767.24 * time 1.69 * step 22258\n",
      "Ep 228 * AvgReward -996.95 * true AvgReward -996.95 * Reward -661.79 * True Reward -661.79 * time 1.66 * step 22359\n",
      "Ep 229 * AvgReward -993.37 * true AvgReward -993.37 * Reward -695.92 * True Reward -695.92 * time 1.15 * step 22434\n",
      "Ep 230 * AvgReward -977.57 * true AvgReward -977.57 * Reward -672.80 * True Reward -672.80 * time 0.83 * step 22495\n",
      "Ep 231 * AvgReward -980.11 * true AvgReward -980.11 * Reward -817.68 * True Reward -817.68 * time 1.23 * step 22580\n",
      "Ep 232 * AvgReward -967.51 * true AvgReward -967.51 * Reward -646.42 * True Reward -646.42 * time 2.36 * step 22732\n",
      "Ep 233 * AvgReward -965.72 * true AvgReward -965.72 * Reward -682.20 * True Reward -682.20 * time 1.81 * step 22850\n",
      "Ep 234 * AvgReward -957.01 * true AvgReward -957.01 * Reward -405.75 * True Reward -405.75 * time 1.22 * step 22932\n",
      "Ep 235 * AvgReward -948.07 * true AvgReward -948.07 * Reward -600.45 * True Reward -600.45 * time 1.27 * step 23017\n",
      "Ep 236 * AvgReward -951.53 * true AvgReward -951.53 * Reward -1153.54 * True Reward -1153.54 * time 1.70 * step 23134\n",
      "Ep 237 * AvgReward -939.68 * true AvgReward -939.68 * Reward -361.23 * True Reward -361.23 * time 1.35 * step 23222\n",
      "Ep 238 * AvgReward -936.78 * true AvgReward -936.78 * Reward -765.62 * True Reward -765.62 * time 2.60 * step 23391\n",
      "Ep 239 * AvgReward -923.84 * true AvgReward -923.84 * Reward -433.14 * True Reward -433.14 * time 2.78 * step 23563\n",
      "Ep 240 * AvgReward -908.77 * true AvgReward -908.77 * Reward -151.64 * True Reward -151.64 * time 1.09 * step 23637\n",
      "Ep 241 * AvgReward -890.65 * true AvgReward -890.65 * Reward -10.23 * True Reward -10.23 * time 1.12 * step 23701\n",
      "Ep 242 * AvgReward -860.39 * true AvgReward -860.39 * Reward -101.68 * True Reward -101.68 * time 1.09 * step 23785\n",
      "Ep 243 * AvgReward -846.12 * true AvgReward -846.12 * Reward -188.63 * True Reward -188.63 * time 1.22 * step 23876\n",
      "Ep 244 * AvgReward -827.46 * true AvgReward -827.46 * Reward -171.94 * True Reward -171.94 * time 0.80 * step 23941\n",
      "Ep 245 * AvgReward -811.75 * true AvgReward -811.75 * Reward -129.21 * True Reward -129.21 * time 0.80 * step 24004\n",
      "Ep 246 * AvgReward -793.00 * true AvgReward -793.00 * Reward -136.57 * True Reward -136.57 * time 0.92 * step 24077\n",
      "Ep 247 * AvgReward -781.18 * true AvgReward -781.18 * Reward -311.36 * True Reward -311.36 * time 1.07 * step 24162\n",
      "Ep 248 * AvgReward -819.39 * true AvgReward -819.39 * Reward -2673.72 * True Reward -2673.72 * time 4.40 * step 24457\n",
      "Ep 249 * AvgReward -823.93 * true AvgReward -823.93 * Reward -1028.60 * True Reward -1028.60 * time 1.15 * step 24542\n",
      "Ep 250 * AvgReward -826.51 * true AvgReward -826.51 * Reward -853.10 * True Reward -853.10 * time 1.05 * step 24613\n",
      "Ep 251 * AvgReward -839.46 * true AvgReward -839.46 * Reward -1732.81 * True Reward -1732.81 * time 1.80 * step 24736\n",
      "Ep 252 * AvgReward -830.83 * true AvgReward -830.83 * Reward -984.78 * True Reward -984.78 * time 1.27 * step 24821\n",
      "Ep 253 * AvgReward -819.32 * true AvgReward -819.32 * Reward -1079.62 * True Reward -1079.62 * time 1.41 * step 24913\n",
      "Ep 254 * AvgReward -839.14 * true AvgReward -839.14 * Reward -2087.86 * True Reward -2087.86 * time 1.97 * step 25047\n",
      "Ep 255 * AvgReward -813.91 * true AvgReward -813.91 * Reward -805.16 * True Reward -805.16 * time 1.04 * step 25112\n",
      "Ep 256 * AvgReward -823.08 * true AvgReward -823.08 * Reward -1183.74 * True Reward -1183.74 * time 1.35 * step 25203\n",
      "Ep 257 * AvgReward -807.65 * true AvgReward -807.65 * Reward -1279.12 * True Reward -1279.12 * time 1.28 * step 25299\n",
      "Ep 258 * AvgReward -795.29 * true AvgReward -795.29 * Reward -1337.45 * True Reward -1337.45 * time 1.37 * step 25397\n",
      "Ep 259 * AvgReward -804.18 * true AvgReward -804.18 * Reward -1061.01 * True Reward -1061.01 * time 1.19 * step 25483\n",
      "Ep 260 * AvgReward -813.88 * true AvgReward -813.88 * Reward -1200.08 * True Reward -1200.08 * time 1.66 * step 25598\n",
      "Ep 261 * AvgReward -796.34 * true AvgReward -796.34 * Reward -775.54 * True Reward -775.54 * time 0.92 * step 25663\n",
      "Ep 262 * AvgReward -797.80 * true AvgReward -797.80 * Reward -762.42 * True Reward -762.42 * time 0.71 * step 25719\n",
      "Ep 263 * AvgReward -832.62 * true AvgReward -832.62 * Reward -1799.83 * True Reward -1799.83 * time 1.71 * step 25845\n",
      "Ep 264 * AvgReward -824.36 * true AvgReward -824.36 * Reward -939.11 * True Reward -939.11 * time 1.19 * step 25932\n",
      "Ep 265 * AvgReward -836.30 * true AvgReward -836.30 * Reward -1088.19 * True Reward -1088.19 * time 1.11 * step 26020\n",
      "Ep 266 * AvgReward -848.31 * true AvgReward -848.31 * Reward -1395.31 * True Reward -1395.31 * time 1.59 * step 26126\n",
      "Ep 267 * AvgReward -849.54 * true AvgReward -849.54 * Reward -816.32 * True Reward -816.32 * time 1.02 * step 26192\n",
      "Ep 268 * AvgReward -872.25 * true AvgReward -872.25 * Reward -1570.09 * True Reward -1570.09 * time 1.60 * step 26311\n",
      "Ep 269 * AvgReward -879.02 * true AvgReward -879.02 * Reward -966.68 * True Reward -966.68 * time 1.23 * step 26402\n",
      "Ep 270 * AvgReward -899.39 * true AvgReward -899.39 * Reward -1487.88 * True Reward -1487.88 * time 1.55 * step 26517\n",
      "Ep 271 * AvgReward -899.62 * true AvgReward -899.62 * Reward -826.86 * True Reward -826.86 * time 0.96 * step 26585\n",
      "Ep 272 * AvgReward -905.70 * true AvgReward -905.70 * Reward -889.62 * True Reward -889.62 * time 1.14 * step 26661\n",
      "Ep 273 * AvgReward -914.49 * true AvgReward -914.49 * Reward -1033.60 * True Reward -1033.60 * time 1.34 * step 26753\n",
      "Ep 274 * AvgReward -921.96 * true AvgReward -921.96 * Reward -704.70 * True Reward -704.70 * time 0.69 * step 26809\n",
      "Ep 275 * AvgReward -926.88 * true AvgReward -926.88 * Reward -797.07 * True Reward -797.07 * time 0.79 * step 26870\n",
      "Ep 276 * AvgReward -923.23 * true AvgReward -923.23 * Reward -1007.87 * True Reward -1007.87 * time 1.23 * step 26956\n",
      "Ep 277 * AvgReward -943.88 * true AvgReward -943.88 * Reward -1186.96 * True Reward -1186.96 * time 1.33 * step 27047\n",
      "Ep 278 * AvgReward -944.87 * true AvgReward -944.87 * Reward -805.40 * True Reward -805.40 * time 0.92 * step 27107\n",
      "Ep 279 * AvgReward -965.16 * true AvgReward -965.16 * Reward -1244.78 * True Reward -1244.78 * time 1.26 * step 27210\n",
      "Ep 280 * AvgReward -994.86 * true AvgReward -994.86 * Reward -1339.58 * True Reward -1339.58 * time 1.25 * step 27308\n",
      "Ep 281 * AvgReward -1041.55 * true AvgReward -1041.55 * Reward -1877.93 * True Reward -1877.93 * time 1.87 * step 27441\n",
      "Ep 282 * AvgReward -1074.68 * true AvgReward -1074.68 * Reward -1426.66 * True Reward -1426.66 * time 1.45 * step 27546\n",
      "Ep 283 * AvgReward -1090.10 * true AvgReward -1090.10 * Reward -805.62 * True Reward -805.62 * time 1.13 * step 27631\n",
      "Ep 284 * AvgReward -1116.90 * true AvgReward -1116.90 * Reward -1243.66 * True Reward -1243.66 * time 1.32 * step 27730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 285 * AvgReward -1133.38 * true AvgReward -1133.38 * Reward -788.51 * True Reward -788.51 * time 0.92 * step 27794\n",
      "Ep 286 * AvgReward -1147.95 * true AvgReward -1147.95 * Reward -719.28 * True Reward -719.28 * time 0.84 * step 27851\n",
      "Ep 287 * AvgReward -1168.03 * true AvgReward -1168.03 * Reward -1114.64 * True Reward -1114.64 * time 1.30 * step 27941\n",
      "Ep 288 * AvgReward -1142.51 * true AvgReward -1142.51 * Reward -1652.79 * True Reward -1652.79 * time 1.73 * step 28063\n",
      "Ep 289 * AvgReward -1148.01 * true AvgReward -1148.01 * Reward -1248.84 * True Reward -1248.84 * time 1.23 * step 28157\n",
      "Ep 290 * AvgReward -1146.14 * true AvgReward -1146.14 * Reward -778.39 * True Reward -778.39 * time 0.98 * step 28220\n",
      "Ep 291 * AvgReward -1145.85 * true AvgReward -1145.85 * Reward -1721.02 * True Reward -1721.02 * time 1.58 * step 28339\n",
      "Ep 292 * AvgReward -1164.58 * true AvgReward -1164.58 * Reward -1734.12 * True Reward -1734.12 * time 1.64 * step 28460\n",
      "Ep 293 * AvgReward -1164.83 * true AvgReward -1164.83 * Reward -1089.53 * True Reward -1089.53 * time 1.43 * step 28552\n",
      "Ep 294 * AvgReward -1132.23 * true AvgReward -1132.23 * Reward -783.85 * True Reward -783.85 * time 0.75 * step 28612\n",
      "Ep 295 * AvgReward -1129.99 * true AvgReward -1129.99 * Reward -715.59 * True Reward -715.59 * time 0.83 * step 28667\n",
      "Ep 296 * AvgReward -1129.78 * true AvgReward -1129.78 * Reward -1175.30 * True Reward -1175.30 * time 1.41 * step 28757\n",
      "Ep 297 * AvgReward -1130.04 * true AvgReward -1130.04 * Reward -1289.38 * True Reward -1289.38 * time 1.27 * step 28853\n",
      "Ep 298 * AvgReward -1117.18 * true AvgReward -1117.18 * Reward -823.20 * True Reward -823.20 * time 0.84 * step 28919\n",
      "Ep 299 * AvgReward -1122.23 * true AvgReward -1122.23 * Reward -1262.94 * True Reward -1262.94 * time 1.20 * step 29013\n",
      "Ep 300 * AvgReward -1109.60 * true AvgReward -1109.60 * Reward -694.85 * True Reward -694.85 * time 0.82 * step 29068\n",
      "Ep 301 * AvgReward -1106.71 * true AvgReward -1106.71 * Reward -659.99 * True Reward -659.99 * time 1.01 * step 29142\n",
      "Ep 302 * AvgReward -1116.20 * true AvgReward -1116.20 * Reward -1142.21 * True Reward -1142.21 * time 1.24 * step 29236\n",
      "Ep 303 * AvgReward -1092.70 * true AvgReward -1092.70 * Reward -859.82 * True Reward -859.82 * time 0.81 * step 29306\n",
      "Ep 304 * AvgReward -1115.73 * true AvgReward -1115.73 * Reward -1860.03 * True Reward -1860.03 * time 1.61 * step 29436\n",
      "Ep 305 * AvgReward -1108.14 * true AvgReward -1108.14 * Reward -784.87 * True Reward -784.87 * time 0.90 * step 29502\n",
      "Ep 306 * AvgReward -1090.61 * true AvgReward -1090.61 * Reward -694.16 * True Reward -694.16 * time 0.71 * step 29559\n",
      "Ep 307 * AvgReward -1113.53 * true AvgReward -1113.53 * Reward -1732.91 * True Reward -1732.91 * time 1.69 * step 29681\n",
      "Ep 308 * AvgReward -1112.79 * true AvgReward -1112.79 * Reward -1540.70 * True Reward -1540.70 * time 1.75 * step 29803\n",
      "Ep 309 * AvgReward -1107.79 * true AvgReward -1107.79 * Reward -766.37 * True Reward -766.37 * time 0.93 * step 29865\n",
      "Ep 310 * AvgReward -1106.91 * true AvgReward -1106.91 * Reward -1452.76 * True Reward -1452.76 * time 1.57 * step 29976\n",
      "Ep 311 * AvgReward -1114.05 * true AvgReward -1114.05 * Reward -1112.61 * True Reward -1112.61 * time 1.24 * step 30074\n",
      "Ep 312 * AvgReward -1141.13 * true AvgReward -1141.13 * Reward -1972.63 * True Reward -1972.63 * time 2.06 * step 30218\n",
      "Ep 313 * AvgReward -1136.62 * true AvgReward -1136.62 * Reward -853.11 * True Reward -853.11 * time 0.99 * step 30292\n",
      "Ep 314 * AvgReward -1160.06 * true AvgReward -1160.06 * Reward -1642.44 * True Reward -1642.44 * time 1.73 * step 30415\n",
      "Ep 315 * AvgReward -1161.49 * true AvgReward -1161.49 * Reward -854.25 * True Reward -854.25 * time 0.89 * step 30489\n",
      "Ep 316 * AvgReward -1166.50 * true AvgReward -1166.50 * Reward -1208.38 * True Reward -1208.38 * time 1.50 * step 30596\n",
      "Ep 317 * AvgReward -1167.55 * true AvgReward -1167.55 * Reward -1228.78 * True Reward -1228.78 * time 1.43 * step 30690\n",
      "Ep 318 * AvgReward -1170.32 * true AvgReward -1170.32 * Reward -916.24 * True Reward -916.24 * time 1.23 * step 30784\n",
      "Ep 319 * AvgReward -1160.52 * true AvgReward -1160.52 * Reward -852.98 * True Reward -852.98 * time 1.17 * step 30875\n",
      "Ep 320 * AvgReward -1151.61 * true AvgReward -1151.61 * Reward -982.97 * True Reward -982.97 * time 1.32 * step 30969\n",
      "Ep 321 * AvgReward -1135.68 * true AvgReward -1135.68 * Reward -1240.80 * True Reward -1240.80 * time 1.58 * step 31075\n",
      "Ep 322 * AvgReward -1131.38 * true AvgReward -1131.38 * Reward -1254.67 * True Reward -1254.67 * time 1.48 * step 31172\n",
      "Ep 323 * AvgReward -1130.84 * true AvgReward -1130.84 * Reward -784.17 * True Reward -784.17 * time 1.07 * step 31241\n",
      "Ep 324 * AvgReward -1118.33 * true AvgReward -1118.33 * Reward -743.28 * True Reward -743.28 * time 0.94 * step 31306\n",
      "Ep 325 * AvgReward -1117.48 * true AvgReward -1117.48 * Reward -754.16 * True Reward -754.16 * time 0.93 * step 31367\n",
      "Ep 326 * AvgReward -1127.74 * true AvgReward -1127.74 * Reward -1129.83 * True Reward -1129.83 * time 1.43 * step 31468\n",
      "Ep 327 * AvgReward -1119.57 * true AvgReward -1119.57 * Reward -787.71 * True Reward -787.71 * time 0.88 * step 31528\n",
      "Ep 328 * AvgReward -1121.37 * true AvgReward -1121.37 * Reward -1724.95 * True Reward -1724.95 * time 1.77 * step 31654\n",
      "Ep 329 * AvgReward -1111.97 * true AvgReward -1111.97 * Reward -872.81 * True Reward -872.81 * time 1.24 * step 31741\n",
      "Ep 330 * AvgReward -1111.13 * true AvgReward -1111.13 * Reward -744.80 * True Reward -744.80 * time 0.94 * step 31807\n",
      "Ep 331 * AvgReward -1095.37 * true AvgReward -1095.37 * Reward -1090.65 * True Reward -1090.65 * time 1.60 * step 31917\n",
      "Ep 332 * AvgReward -1060.56 * true AvgReward -1060.56 * Reward -341.79 * True Reward -341.79 * time 1.49 * step 32018\n",
      "Ep 333 * AvgReward -1052.98 * true AvgReward -1052.98 * Reward -786.26 * True Reward -786.26 * time 1.15 * step 32103\n",
      "Ep 334 * AvgReward -1052.45 * true AvgReward -1052.45 * Reward -762.44 * True Reward -762.44 * time 1.49 * step 32197\n",
      "Ep 335 * AvgReward -1052.48 * true AvgReward -1052.48 * Reward -716.97 * True Reward -716.97 * time 0.80 * step 32253\n",
      "Ep 336 * AvgReward -1040.64 * true AvgReward -1040.64 * Reward -701.66 * True Reward -701.66 * time 0.85 * step 32310\n",
      "Ep 337 * AvgReward -1030.17 * true AvgReward -1030.17 * Reward -870.56 * True Reward -870.56 * time 1.09 * step 32385\n",
      "Ep 338 * AvgReward -1030.56 * true AvgReward -1030.56 * Reward -838.99 * True Reward -838.99 * time 0.90 * step 32457\n",
      "Ep 339 * AvgReward -1027.63 * true AvgReward -1027.63 * Reward -1145.64 * True Reward -1145.64 * time 1.38 * step 32565\n",
      "Ep 340 * AvgReward -1032.48 * true AvgReward -1032.48 * Reward -888.95 * True Reward -888.95 * time 1.28 * step 32655\n",
      "Ep 341 * AvgReward -1042.10 * true AvgReward -1042.10 * Reward -1044.66 * True Reward -1044.66 * time 1.60 * step 32758\n",
      "Ep 342 * AvgReward -1031.56 * true AvgReward -1031.56 * Reward -720.49 * True Reward -720.49 * time 1.20 * step 32841\n",
      "Ep 343 * AvgReward -1027.29 * true AvgReward -1027.29 * Reward -689.16 * True Reward -689.16 * time 1.41 * step 32950\n",
      "Ep 344 * AvgReward -1010.69 * true AvgReward -1010.69 * Reward -1196.02 * True Reward -1196.02 * time 1.66 * step 33065\n",
      "Ep 345 * AvgReward -1009.04 * true AvgReward -1009.04 * Reward -718.72 * True Reward -718.72 * time 0.84 * step 33126\n",
      "Ep 346 * AvgReward -1014.63 * true AvgReward -1014.63 * Reward -918.04 * True Reward -918.04 * time 1.09 * step 33204\n",
      "Ep 347 * AvgReward -992.79 * true AvgReward -992.79 * Reward -859.08 * True Reward -859.08 * time 1.00 * step 33277\n",
      "Ep 348 * AvgReward -986.31 * true AvgReward -986.31 * Reward -1281.43 * True Reward -1281.43 * time 1.34 * step 33374\n",
      "Ep 349 * AvgReward -1016.10 * true AvgReward -1016.10 * Reward -1958.06 * True Reward -1958.06 * time 1.98 * step 33508\n",
      "Ep 350 * AvgReward -1015.03 * true AvgReward -1015.03 * Reward -1410.14 * True Reward -1410.14 * time 1.51 * step 33613\n",
      "Ep 351 * AvgReward -1015.50 * true AvgReward -1015.50 * Reward -1131.28 * True Reward -1131.28 * time 1.42 * step 33713\n",
      "Ep 352 * AvgReward -996.69 * true AvgReward -996.69 * Reward -1220.08 * True Reward -1220.08 * time 1.31 * step 33813\n",
      "Ep 353 * AvgReward -997.35 * true AvgReward -997.35 * Reward -879.51 * True Reward -879.51 * time 0.94 * step 33885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 354 * AvgReward -975.14 * true AvgReward -975.14 * Reward -754.11 * True Reward -754.11 * time 1.02 * step 33959\n",
      "Ep 355 * AvgReward -983.93 * true AvgReward -983.93 * Reward -1206.12 * True Reward -1206.12 * time 1.29 * step 34051\n",
      "Ep 356 * AvgReward -994.45 * true AvgReward -994.45 * Reward -1629.19 * True Reward -1629.19 * time 1.69 * step 34173\n",
      "Ep 357 * AvgReward -983.63 * true AvgReward -983.63 * Reward -795.91 * True Reward -795.91 * time 0.93 * step 34235\n",
      "Ep 358 * AvgReward -1002.93 * true AvgReward -1002.93 * Reward -1688.09 * True Reward -1688.09 * time 1.60 * step 34356\n",
      "Ep 359 * AvgReward -1016.34 * true AvgReward -1016.34 * Reward -1389.45 * True Reward -1389.45 * time 1.50 * step 34459\n",
      "Ep 360 * AvgReward -1021.78 * true AvgReward -1021.78 * Reward -1200.59 * True Reward -1200.59 * time 1.39 * step 34552\n",
      "Ep 361 * AvgReward -1031.20 * true AvgReward -1031.20 * Reward -1617.56 * True Reward -1617.56 * time 1.88 * step 34677\n",
      "Ep 362 * AvgReward -1010.93 * true AvgReward -1010.93 * Reward -443.86 * True Reward -443.86 * time 1.89 * step 34807\n",
      "Ep 363 * AvgReward -1001.95 * true AvgReward -1001.95 * Reward -424.99 * True Reward -424.99 * time 1.42 * step 34907\n",
      "Ep 364 * AvgReward -989.76 * true AvgReward -989.76 * Reward -255.52 * True Reward -255.52 * time 1.20 * step 34989\n",
      "Ep 365 * AvgReward -976.97 * true AvgReward -976.97 * Reward -242.58 * True Reward -242.58 * time 5.40 * step 35349\n",
      "Ep 366 * AvgReward -952.81 * true AvgReward -952.81 * Reward -163.73 * True Reward -163.73 * time 1.86 * step 35481\n",
      "Ep 367 * AvgReward -945.80 * true AvgReward -945.80 * Reward -507.18 * True Reward -507.18 * time 2.47 * step 35645\n",
      "Ep 368 * AvgReward -921.14 * true AvgReward -921.14 * Reward -738.48 * True Reward -738.48 * time 2.03 * step 35785\n",
      "Ep 369 * AvgReward -930.22 * true AvgReward -930.22 * Reward -1236.14 * True Reward -1236.14 * time 2.37 * step 35943\n",
      "Ep 370 * AvgReward -931.76 * true AvgReward -931.76 * Reward -806.18 * True Reward -806.18 * time 0.99 * step 36012\n",
      "Ep 371 * AvgReward -929.29 * true AvgReward -929.29 * Reward -992.05 * True Reward -992.05 * time 1.26 * step 36101\n",
      "Ep 372 * AvgReward -941.88 * true AvgReward -941.88 * Reward -845.44 * True Reward -845.44 * time 1.33 * step 36214\n",
      "Ep 373 * AvgReward -930.69 * true AvgReward -930.69 * Reward -338.54 * True Reward -338.54 * time 1.34 * step 36332\n",
      "Ep 374 * AvgReward -920.21 * true AvgReward -920.21 * Reward -343.24 * True Reward -343.24 * time 1.14 * step 36433\n",
      "Ep 375 * AvgReward -910.41 * true AvgReward -910.41 * Reward -325.02 * True Reward -325.02 * time 1.91 * step 36581\n",
      "Ep 376 * AvgReward -925.28 * true AvgReward -925.28 * Reward -1296.32 * True Reward -1296.32 * time 1.32 * step 36696\n",
      "Ep 377 * AvgReward -947.09 * true AvgReward -947.09 * Reward -1743.01 * True Reward -1743.01 * time 1.79 * step 36832\n",
      "Ep 378 * AvgReward -976.17 * true AvgReward -976.17 * Reward -2002.12 * True Reward -2002.12 * time 1.78 * step 36965\n",
      "Ep 379 * AvgReward -966.58 * true AvgReward -966.58 * Reward -762.16 * True Reward -762.16 * time 0.58 * step 37021\n",
      "Ep 380 * AvgReward -992.22 * true AvgReward -992.22 * Reward -1914.73 * True Reward -1914.73 * time 1.62 * step 37151\n",
      "Ep 381 * AvgReward -987.70 * true AvgReward -987.70 * Reward -863.71 * True Reward -863.71 * time 1.10 * step 37226\n",
      "Ep 382 * AvgReward -986.77 * true AvgReward -986.77 * Reward -683.12 * True Reward -683.12 * time 0.87 * step 37285\n",
      "Ep 383 * AvgReward -987.14 * true AvgReward -987.14 * Reward -703.95 * True Reward -703.95 * time 0.70 * step 37342\n",
      "Ep 384 * AvgReward -978.27 * true AvgReward -978.27 * Reward -841.42 * True Reward -841.42 * time 0.97 * step 37415\n",
      "Ep 385 * AvgReward -978.61 * true AvgReward -978.61 * Reward -732.19 * True Reward -732.19 * time 0.73 * step 37476\n",
      "Ep 386 * AvgReward -974.01 * true AvgReward -974.01 * Reward -734.32 * True Reward -734.32 * time 0.83 * step 37537\n",
      "Ep 387 * AvgReward -979.61 * true AvgReward -979.61 * Reward -1082.74 * True Reward -1082.74 * time 1.10 * step 37623\n",
      "Ep 388 * AvgReward -969.00 * true AvgReward -969.00 * Reward -857.18 * True Reward -857.18 * time 1.25 * step 37712\n",
      "Ep 389 * AvgReward -939.59 * true AvgReward -939.59 * Reward -781.59 * True Reward -781.59 * time 0.83 * step 37777\n",
      "Ep 390 * AvgReward -926.32 * true AvgReward -926.32 * Reward -879.52 * True Reward -879.52 * time 1.02 * step 37849\n",
      "Ep 391 * AvgReward -919.34 * true AvgReward -919.34 * Reward -851.98 * True Reward -851.98 * time 1.02 * step 37919\n",
      "Ep 392 * AvgReward -916.23 * true AvgReward -916.23 * Reward -1095.61 * True Reward -1095.61 * time 1.33 * step 38011\n",
      "Ep 393 * AvgReward -914.67 * true AvgReward -914.67 * Reward -817.06 * True Reward -817.06 * time 1.26 * step 38099\n",
      "Ep 394 * AvgReward -919.50 * true AvgReward -919.50 * Reward -947.38 * True Reward -947.38 * time 1.38 * step 38188\n",
      "Ep 395 * AvgReward -908.23 * true AvgReward -908.23 * Reward -755.37 * True Reward -755.37 * time 0.90 * step 38247\n",
      "Ep 396 * AvgReward -885.79 * true AvgReward -885.79 * Reward -731.67 * True Reward -731.67 * time 0.78 * step 38304\n",
      "Ep 397 * AvgReward -890.53 * true AvgReward -890.53 * Reward -985.40 * True Reward -985.40 * time 1.26 * step 38385\n",
      "Ep 398 * AvgReward -879.20 * true AvgReward -879.20 * Reward -1234.82 * True Reward -1234.82 * time 1.54 * step 38481\n",
      "Ep 399 * AvgReward -874.16 * true AvgReward -874.16 * Reward -1188.01 * True Reward -1188.01 * time 1.67 * step 38593\n",
      "Ep 400 * AvgReward -877.94 * true AvgReward -877.94 * Reward -1351.85 * True Reward -1351.85 * time 1.49 * step 38693\n",
      "Ep 401 * AvgReward -886.65 * true AvgReward -886.65 * Reward -1965.83 * True Reward -1965.83 * time 1.99 * step 38826\n",
      "Ep 402 * AvgReward -895.22 * true AvgReward -895.22 * Reward -786.65 * True Reward -786.65 * time 1.00 * step 38896\n",
      "Ep 403 * AvgReward -906.99 * true AvgReward -906.99 * Reward -895.88 * True Reward -895.88 * time 1.05 * step 38971\n",
      "Ep 404 * AvgReward -917.14 * true AvgReward -917.14 * Reward -661.54 * True Reward -661.54 * time 1.14 * step 39048\n",
      "Ep 405 * AvgReward -930.14 * true AvgReward -930.14 * Reward -762.33 * True Reward -762.33 * time 0.88 * step 39109\n",
      "Ep 406 * AvgReward -945.61 * true AvgReward -945.61 * Reward -782.49 * True Reward -782.49 * time 1.01 * step 39172\n",
      "Ep 407 * AvgReward -960.59 * true AvgReward -960.59 * Reward -1106.48 * True Reward -1106.48 * time 1.51 * step 39294\n",
      "Ep 408 * AvgReward -973.99 * true AvgReward -973.99 * Reward -1274.37 * True Reward -1274.37 * time 1.05 * step 39389\n",
      "Ep 409 * AvgReward -975.64 * true AvgReward -975.64 * Reward -1302.28 * True Reward -1302.28 * time 1.08 * step 39490\n",
      "Ep 410 * AvgReward -974.49 * true AvgReward -974.49 * Reward -760.10 * True Reward -760.10 * time 0.76 * step 39555\n",
      "Ep 411 * AvgReward -968.69 * true AvgReward -968.69 * Reward -760.22 * True Reward -760.22 * time 0.70 * step 39618\n",
      "Ep 412 * AvgReward -978.39 * true AvgReward -978.39 * Reward -1233.56 * True Reward -1233.56 * time 1.37 * step 39721\n",
      "Ep 413 * AvgReward -995.40 * true AvgReward -995.40 * Reward -1018.80 * True Reward -1018.80 * time 1.01 * step 39806\n",
      "Ep 414 * AvgReward -1009.36 * true AvgReward -1009.36 * Reward -901.50 * True Reward -901.50 * time 1.17 * step 39895\n",
      "Ep 415 * AvgReward -1027.07 * true AvgReward -1027.07 * Reward -1033.71 * True Reward -1033.71 * time 1.45 * step 39993\n",
      "Ep 416 * AvgReward -1021.65 * true AvgReward -1021.65 * Reward -1079.39 * True Reward -1079.39 * time 1.20 * step 40080\n",
      "Ep 417 * AvgReward -1020.88 * true AvgReward -1020.88 * Reward -1712.09 * True Reward -1712.09 * time 1.76 * step 40201\n",
      "Ep 418 * AvgReward -992.58 * true AvgReward -992.58 * Reward -870.12 * True Reward -870.12 * time 1.03 * step 40276\n",
      "Ep 419 * AvgReward -1014.88 * true AvgReward -1014.88 * Reward -1654.29 * True Reward -1654.29 * time 1.48 * step 40395\n",
      "Ep 420 * AvgReward -986.98 * true AvgReward -986.98 * Reward -798.81 * True Reward -798.81 * time 0.92 * step 40459\n",
      "Ep 421 * AvgReward -987.15 * true AvgReward -987.15 * Reward -870.45 * True Reward -870.45 * time 1.05 * step 40538\n",
      "Ep 422 * AvgReward -988.24 * true AvgReward -988.24 * Reward -726.79 * True Reward -726.79 * time 0.83 * step 40607\n",
      "Ep 423 * AvgReward -992.09 * true AvgReward -992.09 * Reward -857.97 * True Reward -857.97 * time 1.04 * step 40690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 424 * AvgReward -989.48 * true AvgReward -989.48 * Reward -736.93 * True Reward -736.93 * time 0.95 * step 40757\n",
      "Ep 425 * AvgReward -993.06 * true AvgReward -993.06 * Reward -875.10 * True Reward -875.10 * time 1.16 * step 40841\n",
      "Ep 426 * AvgReward -1003.50 * true AvgReward -1003.50 * Reward -1152.12 * True Reward -1152.12 * time 1.43 * step 40950\n",
      "Ep 427 * AvgReward -1007.82 * true AvgReward -1007.82 * Reward -1255.47 * True Reward -1255.47 * time 1.56 * step 41057\n",
      "Ep 428 * AvgReward -1004.34 * true AvgReward -1004.34 * Reward -717.91 * True Reward -717.91 * time 0.84 * step 41112\n",
      "Ep 429 * AvgReward -1002.76 * true AvgReward -1002.76 * Reward -718.42 * True Reward -718.42 * time 0.83 * step 41171\n",
      "Ep 430 * AvgReward -1003.26 * true AvgReward -1003.26 * Reward -899.56 * True Reward -899.56 * time 1.06 * step 41253\n",
      "Ep 431 * AvgReward -999.18 * true AvgReward -999.18 * Reward -688.69 * True Reward -688.69 * time 0.92 * step 41321\n",
      "Ep 432 * AvgReward -1003.57 * true AvgReward -1003.57 * Reward -1271.37 * True Reward -1271.37 * time 1.82 * step 41463\n",
      "Ep 433 * AvgReward -1005.20 * true AvgReward -1005.20 * Reward -882.07 * True Reward -882.07 * time 1.25 * step 41547\n",
      "Ep 434 * AvgReward -999.29 * true AvgReward -999.29 * Reward -711.34 * True Reward -711.34 * time 0.86 * step 41603\n",
      "Ep 435 * AvgReward -1011.20 * true AvgReward -1011.20 * Reward -1231.77 * True Reward -1231.77 * time 1.40 * step 41702\n",
      "Ep 436 * AvgReward -1011.77 * true AvgReward -1011.77 * Reward -754.39 * True Reward -754.39 * time 1.00 * step 41765\n",
      "Ep 437 * AvgReward -1003.89 * true AvgReward -1003.89 * Reward -670.03 * True Reward -670.03 * time 0.95 * step 41825\n",
      "Ep 438 * AvgReward -991.76 * true AvgReward -991.76 * Reward -749.87 * True Reward -749.87 * time 1.13 * step 41894\n",
      "Ep 439 * AvgReward -994.57 * true AvgReward -994.57 * Reward -1300.25 * True Reward -1300.25 * time 1.66 * step 42002\n",
      "Ep 440 * AvgReward -973.54 * true AvgReward -973.54 * Reward -510.76 * True Reward -510.76 * time 1.13 * step 42079\n",
      "Ep 441 * AvgReward -944.46 * true AvgReward -944.46 * Reward -802.43 * True Reward -802.43 * time 1.11 * step 42150\n",
      "Ep 442 * AvgReward -942.37 * true AvgReward -942.37 * Reward -703.01 * True Reward -703.01 * time 0.80 * step 42209\n",
      "Ep 443 * AvgReward -957.05 * true AvgReward -957.05 * Reward -1483.31 * True Reward -1483.31 * time 1.69 * step 42331\n",
      "Ep 444 * AvgReward -948.78 * true AvgReward -948.78 * Reward -330.61 * True Reward -330.61 * time 1.12 * step 42425\n",
      "Ep 445 * AvgReward -973.82 * true AvgReward -973.82 * Reward -1763.77 * True Reward -1763.77 * time 1.97 * step 42572\n",
      "Ep 446 * AvgReward -983.85 * true AvgReward -983.85 * Reward -1183.83 * True Reward -1183.83 * time 1.53 * step 42688\n",
      "Ep 447 * AvgReward -976.98 * true AvgReward -976.98 * Reward -831.59 * True Reward -831.59 * time 0.97 * step 42761\n",
      "Ep 448 * AvgReward -964.41 * true AvgReward -964.41 * Reward -771.84 * True Reward -771.84 * time 0.77 * step 42823\n",
      "Ep 449 * AvgReward -961.91 * true AvgReward -961.91 * Reward -1202.01 * True Reward -1202.01 * time 1.48 * step 42929\n",
      "Ep 450 * AvgReward -966.38 * true AvgReward -966.38 * Reward -939.14 * True Reward -939.14 * time 1.21 * step 43009\n",
      "Ep 451 * AvgReward -964.50 * true AvgReward -964.50 * Reward -685.03 * True Reward -685.03 * time 0.69 * step 43064\n",
      "Ep 452 * AvgReward -975.39 * true AvgReward -975.39 * Reward -1669.12 * True Reward -1669.12 * time 1.95 * step 43200\n",
      "Ep 453 * AvgReward -967.76 * true AvgReward -967.76 * Reward -713.41 * True Reward -713.41 * time 0.79 * step 43261\n",
      "Ep 454 * AvgReward -964.47 * true AvgReward -964.47 * Reward -770.10 * True Reward -770.10 * time 0.91 * step 43331\n",
      "Ep 455 * AvgReward -968.36 * true AvgReward -968.36 * Reward -1189.03 * True Reward -1189.03 * time 1.52 * step 43434\n",
      "Ep 456 * AvgReward -960.13 * true AvgReward -960.13 * Reward -750.36 * True Reward -750.36 * time 1.39 * step 43525\n",
      "Ep 457 * AvgReward -964.08 * true AvgReward -964.08 * Reward -1869.98 * True Reward -1869.98 * time 2.18 * step 43674\n",
      "Ep 458 * AvgReward -959.84 * true AvgReward -959.84 * Reward -700.67 * True Reward -700.67 * time 0.93 * step 43737\n",
      "Ep 459 * AvgReward -936.49 * true AvgReward -936.49 * Reward -720.09 * True Reward -720.09 * time 1.10 * step 43805\n",
      "Ep 460 * AvgReward -934.83 * true AvgReward -934.83 * Reward -732.47 * True Reward -732.47 * time 0.99 * step 43868\n",
      "Ep 461 * AvgReward -944.68 * true AvgReward -944.68 * Reward -1264.62 * True Reward -1264.62 * time 1.90 * step 43991\n",
      "Ep 462 * AvgReward -947.58 * true AvgReward -947.58 * Reward -842.72 * True Reward -842.72 * time 1.49 * step 44095\n",
      "Ep 463 * AvgReward -950.20 * true AvgReward -950.20 * Reward -962.89 * True Reward -962.89 * time 1.45 * step 44189\n",
      "Ep 464 * AvgReward -952.64 * true AvgReward -952.64 * Reward -834.57 * True Reward -834.57 * time 1.35 * step 44276\n",
      "Ep 465 * AvgReward -955.83 * true AvgReward -955.83 * Reward -1002.52 * True Reward -1002.52 * time 1.50 * step 44384\n",
      "Ep 466 * AvgReward -944.96 * true AvgReward -944.96 * Reward -717.29 * True Reward -717.29 * time 0.82 * step 44444\n",
      "Ep 467 * AvgReward -930.33 * true AvgReward -930.33 * Reward -670.30 * True Reward -670.30 * time 0.99 * step 44513\n",
      "Ep 468 * AvgReward -930.74 * true AvgReward -930.74 * Reward -734.50 * True Reward -734.50 * time 0.82 * step 44573\n",
      "Ep 469 * AvgReward -933.27 * true AvgReward -933.27 * Reward -819.41 * True Reward -819.41 * time 1.34 * step 44663\n",
      "Ep 470 * AvgReward -932.23 * true AvgReward -932.23 * Reward -858.04 * True Reward -858.04 * time 1.36 * step 44755\n",
      "Ep 471 * AvgReward -941.50 * true AvgReward -941.50 * Reward -1059.30 * True Reward -1059.30 * time 1.54 * step 44859\n",
      "Ep 472 * AvgReward -927.57 * true AvgReward -927.57 * Reward -714.24 * True Reward -714.24 * time 0.87 * step 44920\n",
      "Ep 473 * AvgReward -952.95 * true AvgReward -952.95 * Reward -1897.35 * True Reward -1897.35 * time 2.04 * step 45054\n",
      "Ep 474 * AvgReward -980.72 * true AvgReward -980.72 * Reward -1822.12 * True Reward -1822.12 * time 1.88 * step 45188\n",
      "Ep 475 * AvgReward -966.71 * true AvgReward -966.71 * Reward -671.35 * True Reward -671.35 * time 0.81 * step 45248\n",
      "Ep 476 * AvgReward -964.52 * true AvgReward -964.52 * Reward -666.71 * True Reward -666.71 * time 1.22 * step 45324\n",
      "Ep 477 * AvgReward -966.21 * true AvgReward -966.21 * Reward -737.59 * True Reward -737.59 * time 1.12 * step 45399\n",
      "Ep 478 * AvgReward -962.92 * true AvgReward -962.92 * Reward -618.39 * True Reward -618.39 * time 0.92 * step 45462\n",
      "Ep 479 * AvgReward -948.21 * true AvgReward -948.21 * Reward -712.01 * True Reward -712.01 * time 1.01 * step 45528\n",
      "Ep 480 * AvgReward -952.47 * true AvgReward -952.47 * Reward -681.13 * True Reward -681.13 * time 0.92 * step 45592\n",
      "Ep 481 * AvgReward -961.25 * true AvgReward -961.25 * Reward -1153.48 * True Reward -1153.48 * time 1.52 * step 45695\n",
      "Ep 482 * AvgReward -962.92 * true AvgReward -962.92 * Reward -769.86 * True Reward -769.86 * time 1.06 * step 45767\n",
      "Ep 483 * AvgReward -938.24 * true AvgReward -938.24 * Reward -496.31 * True Reward -496.31 * time 1.49 * step 45865\n",
      "Ep 484 * AvgReward -947.55 * true AvgReward -947.55 * Reward -702.85 * True Reward -702.85 * time 1.62 * step 45978\n",
      "Ep 485 * AvgReward -929.97 * true AvgReward -929.97 * Reward -1060.55 * True Reward -1060.55 * time 2.15 * step 46123\n",
      "Ep 486 * AvgReward -918.42 * true AvgReward -918.42 * Reward -722.02 * True Reward -722.02 * time 1.01 * step 46191\n",
      "Ep 487 * AvgReward -928.20 * true AvgReward -928.20 * Reward -1222.68 * True Reward -1222.68 * time 1.57 * step 46295\n",
      "Ep 488 * AvgReward -927.35 * true AvgReward -927.35 * Reward -737.92 * True Reward -737.92 * time 0.88 * step 46352\n",
      "Ep 489 * AvgReward -943.69 * true AvgReward -943.69 * Reward -1855.41 * True Reward -1855.41 * time 2.04 * step 46483\n",
      "Ep 490 * AvgReward -939.38 * true AvgReward -939.38 * Reward -766.99 * True Reward -766.99 * time 0.94 * step 46544\n",
      "Ep 491 * AvgReward -943.12 * true AvgReward -943.12 * Reward -834.43 * True Reward -834.43 * time 1.03 * step 46613\n",
      "Ep 492 * AvgReward -918.84 * true AvgReward -918.84 * Reward -698.08 * True Reward -698.08 * time 0.86 * step 46669\n",
      "Ep 493 * AvgReward -932.15 * true AvgReward -932.15 * Reward -1245.87 * True Reward -1245.87 * time 1.54 * step 46764\n",
      "Ep 494 * AvgReward -934.22 * true AvgReward -934.22 * Reward -852.80 * True Reward -852.80 * time 0.93 * step 46835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 495 * AvgReward -939.76 * true AvgReward -939.76 * Reward -1410.74 * True Reward -1410.74 * time 1.62 * step 46944\n",
      "Ep 496 * AvgReward -981.91 * true AvgReward -981.91 * Reward -2436.10 * True Reward -2436.10 * time 2.96 * step 47135\n",
      "Ep 497 * AvgReward -955.18 * true AvgReward -955.18 * Reward -800.98 * True Reward -800.98 * time 1.05 * step 47203\n",
      "Ep 498 * AvgReward -969.25 * true AvgReward -969.25 * Reward -1263.14 * True Reward -1263.14 * time 1.60 * step 47308\n",
      "Ep 499 * AvgReward -992.05 * true AvgReward -992.05 * Reward -1632.27 * True Reward -1632.27 * time 1.78 * step 47426\n",
      "Ep 500 * AvgReward -1011.81 * true AvgReward -1011.81 * Reward -1522.88 * True Reward -1522.88 * time 1.71 * step 47543\n",
      "Ep 501 * AvgReward -1027.87 * true AvgReward -1027.87 * Reward -1907.18 * True Reward -1907.18 * time 2.04 * step 47674\n",
      "Ep 502 * AvgReward -1025.71 * true AvgReward -1025.71 * Reward -756.08 * True Reward -756.08 * time 0.91 * step 47733\n",
      "Ep 503 * AvgReward -1020.16 * true AvgReward -1020.16 * Reward -741.01 * True Reward -741.01 * time 0.94 * step 47793\n",
      "Ep 504 * AvgReward -1020.87 * true AvgReward -1020.87 * Reward -862.91 * True Reward -862.91 * time 1.11 * step 47865\n",
      "Ep 505 * AvgReward -1017.67 * true AvgReward -1017.67 * Reward -874.35 * True Reward -874.35 * time 1.35 * step 47956\n",
      "Ep 506 * AvgReward -1034.46 * true AvgReward -1034.46 * Reward -1389.11 * True Reward -1389.11 * time 1.51 * step 48058\n",
      "Ep 507 * AvgReward -1036.65 * true AvgReward -1036.65 * Reward -757.87 * True Reward -757.87 * time 0.87 * step 48119\n",
      "Ep 508 * AvgReward -1052.27 * true AvgReward -1052.27 * Reward -1359.14 * True Reward -1359.14 * time 1.52 * step 48219\n",
      "Ep 509 * AvgReward -1052.21 * true AvgReward -1052.21 * Reward -817.20 * True Reward -817.20 * time 0.91 * step 48285\n",
      "Ep 510 * AvgReward -1065.21 * true AvgReward -1065.21 * Reward -1378.14 * True Reward -1378.14 * time 1.54 * step 48387\n",
      "Ep 511 * AvgReward -1056.74 * true AvgReward -1056.74 * Reward -720.40 * True Reward -720.40 * time 0.85 * step 48442\n",
      "Ep 512 * AvgReward -1060.83 * true AvgReward -1060.83 * Reward -877.77 * True Reward -877.77 * time 1.24 * step 48522\n",
      "Ep 513 * AvgReward -1034.62 * true AvgReward -1034.62 * Reward -848.89 * True Reward -848.89 * time 1.29 * step 48606\n",
      "Ep 514 * AvgReward -1025.44 * true AvgReward -1025.44 * Reward -1455.16 * True Reward -1455.16 * time 1.64 * step 48720\n",
      "Ep 515 * AvgReward -1036.69 * true AvgReward -1036.69 * Reward -1121.17 * True Reward -1121.17 * time 1.33 * step 48807\n",
      "Ep 516 * AvgReward -1063.68 * true AvgReward -1063.68 * Reward -1746.50 * True Reward -1746.50 * time 1.89 * step 48931\n",
      "Ep 517 * AvgReward -1075.51 * true AvgReward -1075.51 * Reward -1210.74 * True Reward -1210.74 * time 1.44 * step 49024\n",
      "Ep 518 * AvgReward -1088.18 * true AvgReward -1088.18 * Reward -1125.09 * True Reward -1125.09 * time 1.37 * step 49112\n",
      "Ep 519 * AvgReward -1091.26 * true AvgReward -1091.26 * Reward -835.20 * True Reward -835.20 * time 0.92 * step 49178\n",
      "Ep 520 * AvgReward -1119.86 * true AvgReward -1119.86 * Reward -1825.11 * True Reward -1825.11 * time 2.02 * step 49313\n",
      "Ep 521 * AvgReward -1109.30 * true AvgReward -1109.30 * Reward -731.29 * True Reward -731.29 * time 0.92 * step 49372\n",
      "Ep 522 * AvgReward -1107.07 * true AvgReward -1107.07 * Reward -680.34 * True Reward -680.34 * time 0.75 * step 49427\n",
      "Ep 523 * AvgReward -1136.09 * true AvgReward -1136.09 * Reward -1657.36 * True Reward -1657.36 * time 1.82 * step 49548\n",
      "Ep 524 * AvgReward -1139.71 * true AvgReward -1139.71 * Reward -847.42 * True Reward -847.42 * time 1.11 * step 49619\n",
      "Ep 525 * AvgReward -1148.52 * true AvgReward -1148.52 * Reward -1413.10 * True Reward -1413.10 * time 1.70 * step 49733\n",
      "Ep 526 * AvgReward -1161.72 * true AvgReward -1161.72 * Reward -1250.16 * True Reward -1250.16 * time 1.54 * step 49838\n",
      "Ep 527 * AvgReward -1161.10 * true AvgReward -1161.10 * Reward -1197.55 * True Reward -1197.55 * time 1.42 * step 49927\n",
      "Ep 528 * AvgReward -1166.46 * true AvgReward -1166.46 * Reward -952.44 * True Reward -952.44 * time 1.23 * step 50006\n",
      "Ep 529 * AvgReward -1139.74 * true AvgReward -1139.74 * Reward -786.60 * True Reward -786.60 * time 1.05 * step 50079\n",
      "Ep 530 * AvgReward -1145.31 * true AvgReward -1145.31 * Reward -989.84 * True Reward -989.84 * time 1.42 * step 50181\n",
      "Ep 531 * AvgReward -1139.18 * true AvgReward -1139.18 * Reward -589.08 * True Reward -589.08 * time 1.05 * step 50252\n",
      "Ep 532 * AvgReward -1144.22 * true AvgReward -1144.22 * Reward -899.82 * True Reward -899.82 * time 1.41 * step 50351\n",
      "Ep 533 * AvgReward -1131.28 * true AvgReward -1131.28 * Reward -728.13 * True Reward -728.13 * time 1.17 * step 50429\n",
      "Ep 534 * AvgReward -1126.11 * true AvgReward -1126.11 * Reward -646.19 * True Reward -646.19 * time 0.98 * step 50492\n",
      "Ep 535 * AvgReward -1113.73 * true AvgReward -1113.73 * Reward -915.47 * True Reward -915.47 * time 1.57 * step 50589\n",
      "Ep 536 * AvgReward -1083.08 * true AvgReward -1083.08 * Reward -1210.30 * True Reward -1210.30 * time 1.73 * step 50699\n",
      "Ep 537 * AvgReward -1084.98 * true AvgReward -1084.98 * Reward -876.69 * True Reward -876.69 * time 1.41 * step 50789\n",
      "Ep 538 * AvgReward -1085.22 * true AvgReward -1085.22 * Reward -1272.99 * True Reward -1272.99 * time 2.14 * step 50937\n",
      "Ep 539 * AvgReward -1072.83 * true AvgReward -1072.83 * Reward -1136.70 * True Reward -1136.70 * time 1.40 * step 51032\n",
      "Ep 540 * AvgReward -1054.01 * true AvgReward -1054.01 * Reward -769.79 * True Reward -769.79 * time 0.99 * step 51107\n",
      "Ep 541 * AvgReward -1035.12 * true AvgReward -1035.12 * Reward -1151.87 * True Reward -1151.87 * time 1.40 * step 51209\n",
      "Ep 542 * AvgReward -1035.56 * true AvgReward -1035.56 * Reward -773.67 * True Reward -773.67 * time 0.94 * step 51277\n",
      "Ep 543 * AvgReward -1057.70 * true AvgReward -1057.70 * Reward -1626.31 * True Reward -1626.31 * time 1.82 * step 51400\n",
      "Ep 544 * AvgReward -1055.17 * true AvgReward -1055.17 * Reward -761.94 * True Reward -761.94 * time 0.78 * step 51459\n",
      "Ep 545 * AvgReward -1060.56 * true AvgReward -1060.56 * Reward -1089.97 * True Reward -1089.97 * time 1.85 * step 51586\n",
      "Ep 546 * AvgReward -1052.54 * true AvgReward -1052.54 * Reward -1068.09 * True Reward -1068.09 * time 1.30 * step 51677\n",
      "Ep 547 * AvgReward -1058.83 * true AvgReward -1058.83 * Reward -1009.44 * True Reward -1009.44 * time 1.23 * step 51760\n",
      "Ep 548 * AvgReward -1050.05 * true AvgReward -1050.05 * Reward -1008.16 * True Reward -1008.16 * time 1.26 * step 51844\n",
      "Ep 549 * AvgReward -1053.78 * true AvgReward -1053.78 * Reward -966.22 * True Reward -966.22 * time 1.21 * step 51925\n",
      "Ep 550 * AvgReward -1047.29 * true AvgReward -1047.29 * Reward -1118.50 * True Reward -1118.50 * time 1.42 * step 52020\n",
      "Ep 551 * AvgReward -1055.99 * true AvgReward -1055.99 * Reward -1068.72 * True Reward -1068.72 * time 1.30 * step 52109\n",
      "Ep 552 * AvgReward -1054.52 * true AvgReward -1054.52 * Reward -818.97 * True Reward -818.97 * time 1.22 * step 52193\n",
      "Ep 553 * AvgReward -1075.95 * true AvgReward -1075.95 * Reward -1705.75 * True Reward -1705.75 * time 1.85 * step 52315\n",
      "Ep 554 * AvgReward -1083.88 * true AvgReward -1083.88 * Reward -1772.58 * True Reward -1772.58 * time 1.95 * step 52441\n",
      "Ep 555 * AvgReward -1073.37 * true AvgReward -1073.37 * Reward -700.60 * True Reward -700.60 * time 0.81 * step 52497\n",
      "Ep 556 * AvgReward -1051.62 * true AvgReward -1051.62 * Reward -876.50 * True Reward -876.50 * time 1.12 * step 52570\n",
      "Ep 557 * AvgReward -1050.08 * true AvgReward -1050.08 * Reward -1149.32 * True Reward -1149.32 * time 1.32 * step 52660\n",
      "Ep 558 * AvgReward -1054.41 * true AvgReward -1054.41 * Reward -1298.09 * True Reward -1298.09 * time 1.32 * step 52757\n",
      "Ep 559 * AvgReward -1058.45 * true AvgReward -1058.45 * Reward -997.09 * True Reward -997.09 * time 1.17 * step 52841\n",
      "Ep 560 * AvgReward -1043.86 * true AvgReward -1043.86 * Reward -1241.46 * True Reward -1241.46 * time 1.64 * step 52948\n",
      "Ep 561 * AvgReward -1065.30 * true AvgReward -1065.30 * Reward -1588.59 * True Reward -1588.59 * time 1.77 * step 53063\n",
      "Ep 562 * AvgReward -1088.70 * true AvgReward -1088.70 * Reward -1616.43 * True Reward -1616.43 * time 1.90 * step 53185\n",
      "Ep 563 * AvgReward -1068.36 * true AvgReward -1068.36 * Reward -843.74 * True Reward -843.74 * time 1.22 * step 53264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 564 * AvgReward -1067.82 * true AvgReward -1067.82 * Reward -825.81 * True Reward -825.81 * time 0.93 * step 53331\n",
      "Ep 565 * AvgReward -1053.72 * true AvgReward -1053.72 * Reward -849.35 * True Reward -849.35 * time 1.01 * step 53401\n",
      "Ep 566 * AvgReward -1051.33 * true AvgReward -1051.33 * Reward -1154.60 * True Reward -1154.60 * time 1.27 * step 53489\n",
      "Ep 567 * AvgReward -1039.79 * true AvgReward -1039.79 * Reward -735.98 * True Reward -735.98 * time 0.88 * step 53549\n",
      "Ep 568 * AvgReward -1044.74 * true AvgReward -1044.74 * Reward -1150.46 * True Reward -1150.46 * time 1.39 * step 53639\n",
      "Ep 569 * AvgReward -1044.43 * true AvgReward -1044.43 * Reward -774.14 * True Reward -774.14 * time 0.89 * step 53698\n",
      "Ep 570 * AvgReward -1064.79 * true AvgReward -1064.79 * Reward -1804.06 * True Reward -1804.06 * time 2.00 * step 53823\n",
      "Ep 571 * AvgReward -1092.39 * true AvgReward -1092.39 * Reward -1693.21 * True Reward -1693.21 * time 1.77 * step 53943\n",
      "Ep 572 * AvgReward -1097.92 * true AvgReward -1097.92 * Reward -1120.76 * True Reward -1120.76 * time 1.49 * step 54041\n",
      "Ep 573 * AvgReward -1110.03 * true AvgReward -1110.03 * Reward -1212.78 * True Reward -1212.78 * time 1.53 * step 54143\n",
      "Ep 574 * AvgReward -1136.49 * true AvgReward -1136.49 * Reward -1704.39 * True Reward -1704.39 * time 1.63 * step 54269\n",
      "Ep 575 * AvgReward -1149.01 * true AvgReward -1149.01 * Reward -1416.47 * True Reward -1416.47 * time 1.49 * step 54373\n",
      "Ep 576 * AvgReward -1154.90 * true AvgReward -1154.90 * Reward -1445.91 * True Reward -1445.91 * time 1.43 * step 54481\n",
      "Ep 577 * AvgReward -1150.60 * true AvgReward -1150.60 * Reward -704.82 * True Reward -704.82 * time 0.77 * step 54539\n",
      "Ep 578 * AvgReward -1137.51 * true AvgReward -1137.51 * Reward -749.34 * True Reward -749.34 * time 0.79 * step 54598\n",
      "Ep 579 * AvgReward -1126.91 * true AvgReward -1126.91 * Reward -712.60 * True Reward -712.60 * time 0.78 * step 54655\n",
      "Ep 580 * AvgReward -1127.09 * true AvgReward -1127.09 * Reward -777.06 * True Reward -777.06 * time 0.94 * step 54722\n",
      "Ep 581 * AvgReward -1117.17 * true AvgReward -1117.17 * Reward -754.92 * True Reward -754.92 * time 0.92 * step 54787\n",
      "Ep 582 * AvgReward -1116.58 * true AvgReward -1116.58 * Reward -750.06 * True Reward -750.06 * time 0.75 * step 54846\n",
      "Ep 583 * AvgReward -1118.98 * true AvgReward -1118.98 * Reward -1722.47 * True Reward -1722.47 * time 1.66 * step 54968\n",
      "Ep 584 * AvgReward -1118.78 * true AvgReward -1118.78 * Reward -753.78 * True Reward -753.78 * time 0.73 * step 55025\n",
      "Ep 585 * AvgReward -1114.64 * true AvgReward -1114.64 * Reward -924.25 * True Reward -924.25 * time 1.10 * step 55104\n",
      "Ep 586 * AvgReward -1106.74 * true AvgReward -1106.74 * Reward -752.09 * True Reward -752.09 * time 0.85 * step 55160\n",
      "Ep 587 * AvgReward -1122.10 * true AvgReward -1122.10 * Reward -1624.16 * True Reward -1624.16 * time 1.64 * step 55278\n",
      "Ep 588 * AvgReward -1125.28 * true AvgReward -1125.28 * Reward -1135.28 * True Reward -1135.28 * time 1.32 * step 55366\n",
      "Ep 589 * AvgReward -1122.16 * true AvgReward -1122.16 * Reward -841.51 * True Reward -841.51 * time 1.10 * step 55438\n",
      "Ep 590 * AvgReward -1119.24 * true AvgReward -1119.24 * Reward -1001.69 * True Reward -1001.69 * time 1.33 * step 55529\n",
      "Ep 591 * AvgReward -1110.19 * true AvgReward -1110.19 * Reward -706.49 * True Reward -706.49 * time 0.95 * step 55585\n",
      "Ep 592 * AvgReward -1108.94 * true AvgReward -1108.94 * Reward -769.18 * True Reward -769.18 * time 0.90 * step 55646\n",
      "Ep 593 * AvgReward -1099.96 * true AvgReward -1099.96 * Reward -1346.55 * True Reward -1346.55 * time 1.42 * step 55748\n",
      "Ep 594 * AvgReward -1088.14 * true AvgReward -1088.14 * Reward -1299.50 * True Reward -1299.50 * time 1.54 * step 55856\n",
      "Ep 595 * AvgReward -1088.93 * true AvgReward -1088.93 * Reward -732.41 * True Reward -732.41 * time 0.86 * step 55913\n",
      "Ep 596 * AvgReward -1086.23 * true AvgReward -1086.23 * Reward -768.49 * True Reward -768.49 * time 0.80 * step 55968\n",
      "Ep 597 * AvgReward -1079.48 * true AvgReward -1079.48 * Reward -879.49 * True Reward -879.49 * time 1.03 * step 56040\n",
      "Ep 598 * AvgReward -1078.21 * true AvgReward -1078.21 * Reward -1246.95 * True Reward -1246.95 * time 1.64 * step 56155\n",
      "Ep 599 * AvgReward -1074.73 * true AvgReward -1074.73 * Reward -857.82 * True Reward -857.82 * time 0.95 * step 56224\n",
      "Ep 600 * AvgReward -1086.58 * true AvgReward -1086.58 * Reward -1715.61 * True Reward -1715.61 * time 1.77 * step 56346\n",
      "Ep 601 * AvgReward -1065.79 * true AvgReward -1065.79 * Reward -756.99 * True Reward -756.99 * time 0.95 * step 56411\n",
      "Ep 602 * AvgReward -1042.40 * true AvgReward -1042.40 * Reward -681.02 * True Reward -681.02 * time 1.57 * step 56519\n",
      "Ep 603 * AvgReward -1032.23 * true AvgReward -1032.23 * Reward -436.76 * True Reward -436.76 * time 1.31 * step 56614\n",
      "Ep 604 * AvgReward -1035.98 * true AvgReward -1035.98 * Reward -975.79 * True Reward -975.79 * time 1.43 * step 56721\n",
      "Ep 605 * AvgReward -1035.84 * true AvgReward -1035.84 * Reward -843.65 * True Reward -843.65 * time 1.26 * step 56822\n",
      "Ep 606 * AvgReward -1050.59 * true AvgReward -1050.59 * Reward -1744.71 * True Reward -1744.71 * time 1.95 * step 56964\n",
      "Ep 607 * AvgReward -1053.29 * true AvgReward -1053.29 * Reward -844.24 * True Reward -844.24 * time 1.08 * step 57046\n",
      "Ep 608 * AvgReward -1043.64 * true AvgReward -1043.64 * Reward -764.24 * True Reward -764.24 * time 1.20 * step 57135\n",
      "Ep 609 * AvgReward -1054.76 * true AvgReward -1054.76 * Reward -1219.03 * True Reward -1219.03 * time 1.35 * step 57229\n",
      "Ep 610 * AvgReward -1035.13 * true AvgReward -1035.13 * Reward -1018.72 * True Reward -1018.72 * time 1.24 * step 57315\n",
      "Ep 611 * AvgReward -1028.88 * true AvgReward -1028.88 * Reward -1443.10 * True Reward -1443.10 * time 1.66 * step 57430\n",
      "Ep 612 * AvgReward -1019.64 * true AvgReward -1019.64 * Reward -751.39 * True Reward -751.39 * time 0.92 * step 57491\n",
      "Ep 613 * AvgReward -1014.88 * true AvgReward -1014.88 * Reward -1022.43 * True Reward -1022.43 * time 1.23 * step 57573\n",
      "Ep 614 * AvgReward -991.08 * true AvgReward -991.08 * Reward -752.08 * True Reward -752.08 * time 1.13 * step 57654\n",
      "Ep 615 * AvgReward -987.07 * true AvgReward -987.07 * Reward -1256.28 * True Reward -1256.28 * time 1.41 * step 57748\n",
      "Ep 616 * AvgReward -982.16 * true AvgReward -982.16 * Reward -1249.34 * True Reward -1249.34 * time 1.35 * step 57845\n",
      "Ep 617 * AvgReward -985.93 * true AvgReward -985.93 * Reward -855.89 * True Reward -855.89 * time 1.34 * step 57932\n",
      "Ep 618 * AvgReward -986.16 * true AvgReward -986.16 * Reward -758.45 * True Reward -758.45 * time 0.83 * step 57989\n",
      "Ep 619 * AvgReward -995.94 * true AvgReward -995.94 * Reward -1103.76 * True Reward -1103.76 * time 1.49 * step 58087\n",
      "Ep 620 * AvgReward -999.16 * true AvgReward -999.16 * Reward -905.72 * True Reward -905.72 * time 1.18 * step 58164\n",
      "Ep 621 * AvgReward -1017.33 * true AvgReward -1017.33 * Reward -1482.03 * True Reward -1482.03 * time 1.69 * step 58281\n",
      "Ep 622 * AvgReward -1035.15 * true AvgReward -1035.15 * Reward -1462.81 * True Reward -1462.81 * time 1.82 * step 58402\n",
      "Ep 623 * AvgReward -1018.98 * true AvgReward -1018.98 * Reward -1075.42 * True Reward -1075.42 * time 1.26 * step 58492\n",
      "Ep 624 * AvgReward -1019.09 * true AvgReward -1019.09 * Reward -758.17 * True Reward -758.17 * time 1.07 * step 58559\n",
      "Ep 625 * AvgReward -1037.92 * true AvgReward -1037.92 * Reward -1677.75 * True Reward -1677.75 * time 1.73 * step 58684\n",
      "Ep 626 * AvgReward -1051.09 * true AvgReward -1051.09 * Reward -1278.91 * True Reward -1278.91 * time 1.62 * step 58811\n",
      "Ep 627 * AvgReward -1047.17 * true AvgReward -1047.17 * Reward -1467.09 * True Reward -1467.09 * time 1.66 * step 58935\n",
      "Ep 628 * AvgReward -1038.22 * true AvgReward -1038.22 * Reward -777.39 * True Reward -777.39 * time 0.90 * step 59009\n",
      "Ep 629 * AvgReward -1035.84 * true AvgReward -1035.84 * Reward -746.27 * True Reward -746.27 * time 0.82 * step 59070\n",
      "Ep 630 * AvgReward -1046.31 * true AvgReward -1046.31 * Reward -1420.42 * True Reward -1420.42 * time 1.52 * step 59181\n",
      "Ep 631 * AvgReward -1054.91 * true AvgReward -1054.91 * Reward -1050.47 * True Reward -1050.47 * time 1.15 * step 59269\n",
      "Ep 632 * AvgReward -1065.83 * true AvgReward -1065.83 * Reward -1205.89 * True Reward -1205.89 * time 1.23 * step 59361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 633 * AvgReward -1051.84 * true AvgReward -1051.84 * Reward -787.32 * True Reward -787.32 * time 0.87 * step 59422\n",
      "Ep 634 * AvgReward -1042.28 * true AvgReward -1042.28 * Reward -916.80 * True Reward -916.80 * time 1.19 * step 59519\n",
      "Ep 635 * AvgReward -1044.89 * true AvgReward -1044.89 * Reward -836.84 * True Reward -836.84 * time 0.81 * step 59588\n",
      "Ep 636 * AvgReward -1050.86 * true AvgReward -1050.86 * Reward -1007.47 * True Reward -1007.47 * time 1.36 * step 59678\n",
      "Ep 637 * AvgReward -1049.68 * true AvgReward -1049.68 * Reward -832.04 * True Reward -832.04 * time 1.10 * step 59763\n",
      "Ep 638 * AvgReward -1039.94 * true AvgReward -1039.94 * Reward -857.54 * True Reward -857.54 * time 1.00 * step 59835\n",
      "Ep 639 * AvgReward -1039.31 * true AvgReward -1039.31 * Reward -832.76 * True Reward -832.76 * time 1.05 * step 59915\n",
      "Ep 640 * AvgReward -1016.82 * true AvgReward -1016.82 * Reward -815.97 * True Reward -815.97 * time 1.03 * step 59987\n",
      "Ep 641 * AvgReward -1027.41 * true AvgReward -1027.41 * Reward -1180.51 * True Reward -1180.51 * time 1.43 * step 60090\n",
      "Ep 642 * AvgReward -1039.52 * true AvgReward -1039.52 * Reward -1165.45 * True Reward -1165.45 * time 1.37 * step 60181\n",
      "Ep 643 * AvgReward -1063.64 * true AvgReward -1063.64 * Reward -1401.58 * True Reward -1401.58 * time 1.60 * step 60287\n",
      "Ep 644 * AvgReward -1070.72 * true AvgReward -1070.72 * Reward -1258.85 * True Reward -1258.85 * time 1.51 * step 60391\n",
      "Ep 645 * AvgReward -1068.73 * true AvgReward -1068.73 * Reward -764.00 * True Reward -764.00 * time 0.89 * step 60454\n",
      "Ep 646 * AvgReward -1046.20 * true AvgReward -1046.20 * Reward -843.70 * True Reward -843.70 * time 1.07 * step 60525\n",
      "Ep 647 * AvgReward -1059.86 * true AvgReward -1059.86 * Reward -1390.42 * True Reward -1390.42 * time 1.50 * step 60627\n",
      "Ep 648 * AvgReward -1067.71 * true AvgReward -1067.71 * Reward -1078.35 * True Reward -1078.35 * time 1.37 * step 60712\n",
      "Ep 649 * AvgReward -1057.48 * true AvgReward -1057.48 * Reward -809.86 * True Reward -809.86 * time 1.03 * step 60778\n",
      "Ep 650 * AvgReward -1050.31 * true AvgReward -1050.31 * Reward -731.75 * True Reward -731.75 * time 0.77 * step 60836\n",
      "Ep 651 * AvgReward -1039.99 * true AvgReward -1039.99 * Reward -1030.56 * True Reward -1030.56 * time 1.40 * step 60927\n",
      "Ep 652 * AvgReward -1057.65 * true AvgReward -1057.65 * Reward -1457.73 * True Reward -1457.73 * time 1.42 * step 61034\n",
      "Ep 653 * AvgReward -1054.17 * true AvgReward -1054.17 * Reward -883.30 * True Reward -883.30 * time 1.16 * step 61113\n",
      "Ep 654 * AvgReward -1055.45 * true AvgReward -1055.45 * Reward -803.27 * True Reward -803.27 * time 1.08 * step 61180\n",
      "Ep 655 * AvgReward -1043.71 * true AvgReward -1043.71 * Reward -786.71 * True Reward -786.71 * time 0.92 * step 61242\n",
      "Ep 656 * AvgReward -1043.30 * true AvgReward -1043.30 * Reward -1232.61 * True Reward -1232.61 * time 1.60 * step 61348\n",
      "Ep 657 * AvgReward -1047.06 * true AvgReward -1047.06 * Reward -1006.36 * True Reward -1006.36 * time 1.47 * step 61443\n",
      "Ep 658 * AvgReward -1064.18 * true AvgReward -1064.18 * Reward -1443.27 * True Reward -1443.27 * time 1.76 * step 61557\n",
      "Ep 659 * AvgReward -1057.05 * true AvgReward -1057.05 * Reward -818.74 * True Reward -818.74 * time 0.97 * step 61621\n",
      "Ep 660 * AvgReward -1052.75 * true AvgReward -1052.75 * Reward -733.59 * True Reward -733.59 * time 0.78 * step 61678\n",
      "Ep 661 * AvgReward -1049.02 * true AvgReward -1049.02 * Reward -1332.96 * True Reward -1332.96 * time 1.54 * step 61778\n",
      "Ep 662 * AvgReward -1032.84 * true AvgReward -1032.84 * Reward -815.63 * True Reward -815.63 * time 0.95 * step 61845\n",
      "Ep 663 * AvgReward -1039.41 * true AvgReward -1039.41 * Reward -1338.20 * True Reward -1338.20 * time 1.56 * step 61944\n",
      "Ep 664 * AvgReward -1048.72 * true AvgReward -1048.72 * Reward -1130.48 * True Reward -1130.48 * time 1.19 * step 62033\n",
      "Ep 665 * AvgReward -1038.53 * true AvgReward -1038.53 * Reward -1270.05 * True Reward -1270.05 * time 1.54 * step 62129\n",
      "Ep 666 * AvgReward -1024.87 * true AvgReward -1024.87 * Reward -732.51 * True Reward -732.51 * time 0.88 * step 62186\n",
      "Ep 667 * AvgReward -1009.22 * true AvgReward -1009.22 * Reward -841.23 * True Reward -841.23 * time 1.06 * step 62256\n",
      "Ep 668 * AvgReward -1008.17 * true AvgReward -1008.17 * Reward -735.25 * True Reward -735.25 * time 0.82 * step 62315\n",
      "Ep 669 * AvgReward -1010.04 * true AvgReward -1010.04 * Reward -821.21 * True Reward -821.21 * time 1.08 * step 62387\n",
      "Ep 670 * AvgReward -993.28 * true AvgReward -993.28 * Reward -749.82 * True Reward -749.82 * time 0.83 * step 62445\n",
      "Ep 671 * AvgReward -987.97 * true AvgReward -987.97 * Reward -838.24 * True Reward -838.24 * time 1.38 * step 62540\n",
      "Ep 672 * AvgReward -975.02 * true AvgReward -975.02 * Reward -687.80 * True Reward -687.80 * time 0.88 * step 62599\n",
      "Ep 673 * AvgReward -992.80 * true AvgReward -992.80 * Reward -1498.76 * True Reward -1498.76 * time 1.90 * step 62723\n",
      "Ep 674 * AvgReward -988.81 * true AvgReward -988.81 * Reward -756.93 * True Reward -756.93 * time 1.41 * step 62813\n",
      "Ep 675 * AvgReward -985.38 * true AvgReward -985.38 * Reward -699.89 * True Reward -699.89 * time 0.80 * step 62870\n",
      "Ep 676 * AvgReward -991.91 * true AvgReward -991.91 * Reward -1268.68 * True Reward -1268.68 * time 1.61 * step 62977\n",
      "Ep 677 * AvgReward -989.19 * true AvgReward -989.19 * Reward -722.97 * True Reward -722.97 * time 0.88 * step 63036\n",
      "Ep 678 * AvgReward -999.34 * true AvgReward -999.34 * Reward -1263.81 * True Reward -1263.81 * time 1.67 * step 63147\n",
      "Ep 679 * AvgReward -1004.73 * true AvgReward -1004.73 * Reward -1048.20 * True Reward -1048.20 * time 1.47 * step 63247\n",
      "Ep 680 * AvgReward -1000.04 * true AvgReward -1000.04 * Reward -628.34 * True Reward -628.34 * time 1.16 * step 63326\n",
      "Ep 681 * AvgReward -990.87 * true AvgReward -990.87 * Reward -813.66 * True Reward -813.66 * time 1.22 * step 63411\n",
      "Ep 682 * AvgReward -982.34 * true AvgReward -982.34 * Reward -824.39 * True Reward -824.39 * time 1.25 * step 63494\n",
      "Ep 683 * AvgReward -968.34 * true AvgReward -968.34 * Reward -841.66 * True Reward -841.66 * time 1.24 * step 63576\n",
      "Ep 684 * AvgReward -970.45 * true AvgReward -970.45 * Reward -1342.93 * True Reward -1342.93 * time 1.62 * step 63680\n",
      "Ep 685 * AvgReward -976.45 * true AvgReward -976.45 * Reward -1004.04 * True Reward -1004.04 * time 1.38 * step 63775\n",
      "Ep 686 * AvgReward -973.72 * true AvgReward -973.72 * Reward -734.72 * True Reward -734.72 * time 0.88 * step 63836\n",
      "Ep 687 * AvgReward -964.98 * true AvgReward -964.98 * Reward -1040.69 * True Reward -1040.69 * time 1.34 * step 63926\n",
      "Ep 688 * AvgReward -957.01 * true AvgReward -957.01 * Reward -759.68 * True Reward -759.68 * time 1.16 * step 64014\n",
      "Ep 689 * AvgReward -964.67 * true AvgReward -964.67 * Reward -1116.23 * True Reward -1116.23 * time 1.54 * step 64113\n",
      "Ep 690 * AvgReward -973.14 * true AvgReward -973.14 * Reward -1070.62 * True Reward -1070.62 * time 1.36 * step 64205\n",
      "Ep 691 * AvgReward -968.59 * true AvgReward -968.59 * Reward -848.41 * True Reward -848.41 * time 1.38 * step 64295\n",
      "Ep 692 * AvgReward -967.12 * true AvgReward -967.12 * Reward -1399.07 * True Reward -1399.07 * time 1.55 * step 64400\n",
      "Ep 693 * AvgReward -964.48 * true AvgReward -964.48 * Reward -777.41 * True Reward -777.41 * time 0.81 * step 64458\n",
      "Ep 694 * AvgReward -971.15 * true AvgReward -971.15 * Reward -1070.27 * True Reward -1070.27 * time 1.41 * step 64547\n",
      "Ep 695 * AvgReward -984.63 * true AvgReward -984.63 * Reward -1325.71 * True Reward -1325.71 * time 1.61 * step 64655\n",
      "Ep 696 * AvgReward -972.73 * true AvgReward -972.73 * Reward -756.81 * True Reward -756.81 * time 0.79 * step 64712\n",
      "Ep 697 * AvgReward -967.03 * true AvgReward -967.03 * Reward -778.32 * True Reward -778.32 * time 0.91 * step 64774\n",
      "Ep 698 * AvgReward -951.06 * true AvgReward -951.06 * Reward -804.33 * True Reward -804.33 * time 0.97 * step 64838\n",
      "Ep 699 * AvgReward -949.88 * true AvgReward -949.88 * Reward -771.73 * True Reward -771.73 * time 0.86 * step 64896\n",
      "Ep 700 * AvgReward -996.41 * true AvgReward -996.41 * Reward -2594.80 * True Reward -2594.80 * time 2.15 * step 65052\n",
      "Ep 701 * AvgReward -982.17 * true AvgReward -982.17 * Reward -763.50 * True Reward -763.50 * time 0.87 * step 65114\n",
      "Ep 702 * AvgReward -979.91 * true AvgReward -979.91 * Reward -725.10 * True Reward -725.10 * time 0.88 * step 65173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 703 * AvgReward -964.77 * true AvgReward -964.77 * Reward -732.38 * True Reward -732.38 * time 0.98 * step 65230\n",
      "Ep 704 * AvgReward -957.55 * true AvgReward -957.55 * Reward -842.01 * True Reward -842.01 * time 1.04 * step 65299\n",
      "Ep 705 * AvgReward -948.85 * true AvgReward -948.85 * Reward -921.76 * True Reward -921.76 * time 1.19 * step 65381\n",
      "Ep 706 * AvgReward -949.82 * true AvgReward -949.82 * Reward -771.45 * True Reward -771.45 * time 0.99 * step 65446\n",
      "Ep 707 * AvgReward -951.16 * true AvgReward -951.16 * Reward -894.68 * True Reward -894.68 * time 1.13 * step 65521\n",
      "Ep 708 * AvgReward -966.00 * true AvgReward -966.00 * Reward -1328.92 * True Reward -1328.92 * time 1.49 * step 65625\n",
      "Ep 709 * AvgReward -963.04 * true AvgReward -963.04 * Reward -702.71 * True Reward -702.71 * time 0.82 * step 65680\n",
      "Ep 710 * AvgReward -963.49 * true AvgReward -963.49 * Reward -768.09 * True Reward -768.09 * time 0.90 * step 65745\n",
      "Ep 711 * AvgReward -978.50 * true AvgReward -978.50 * Reward -1438.38 * True Reward -1438.38 * time 1.64 * step 65861\n",
      "Ep 712 * AvgReward -980.50 * true AvgReward -980.50 * Reward -768.00 * True Reward -768.00 * time 0.93 * step 65922\n",
      "Ep 713 * AvgReward -961.99 * true AvgReward -961.99 * Reward -758.21 * True Reward -758.21 * time 0.86 * step 65981\n",
      "Ep 714 * AvgReward -974.77 * true AvgReward -974.77 * Reward -1268.38 * True Reward -1268.38 * time 1.63 * step 66092\n",
      "Ep 715 * AvgReward -979.27 * true AvgReward -979.27 * Reward -879.64 * True Reward -879.64 * time 1.13 * step 66165\n",
      "Ep 716 * AvgReward -970.74 * true AvgReward -970.74 * Reward -927.60 * True Reward -927.60 * time 1.18 * step 66242\n",
      "Ep 717 * AvgReward -972.43 * true AvgReward -972.43 * Reward -790.55 * True Reward -790.55 * time 0.89 * step 66306\n",
      "Ep 718 * AvgReward -968.04 * true AvgReward -968.04 * Reward -1088.38 * True Reward -1088.38 * time 2.06 * step 66442\n",
      "Ep 719 * AvgReward -969.38 * true AvgReward -969.38 * Reward -1101.57 * True Reward -1101.57 * time 1.35 * step 66541\n",
      "Ep 720 * AvgReward -988.79 * true AvgReward -988.79 * Reward -1404.73 * True Reward -1404.73 * time 2.12 * step 66679\n",
      "Ep 721 * AvgReward -999.93 * true AvgReward -999.93 * Reward -1259.17 * True Reward -1259.17 * time 1.68 * step 66791\n",
      "Ep 722 * AvgReward -996.88 * true AvgReward -996.88 * Reward -702.53 * True Reward -702.53 * time 1.32 * step 66878\n",
      "Ep 723 * AvgReward -992.28 * true AvgReward -992.28 * Reward -657.61 * True Reward -657.61 * time 2.68 * step 67064\n",
      "Ep 724 * AvgReward -965.66 * true AvgReward -965.66 * Reward -278.29 * True Reward -278.29 * time 1.68 * step 67180\n",
      "Ep 725 * AvgReward -957.22 * true AvgReward -957.22 * Reward -666.25 * True Reward -666.25 * time 0.88 * step 67257\n",
      "Ep 726 * AvgReward -956.15 * true AvgReward -956.15 * Reward -691.89 * True Reward -691.89 * time 0.99 * step 67325\n",
      "Ep 727 * AvgReward -951.01 * true AvgReward -951.01 * Reward -835.27 * True Reward -835.27 * time 1.27 * step 67405\n",
      "Ep 728 * AvgReward -966.01 * true AvgReward -966.01 * Reward -1359.53 * True Reward -1359.53 * time 2.11 * step 67546\n",
      "Ep 729 * AvgReward -952.72 * true AvgReward -952.72 * Reward -584.57 * True Reward -584.57 * time 1.22 * step 67637\n",
      "Ep 730 * AvgReward -943.40 * true AvgReward -943.40 * Reward -698.06 * True Reward -698.06 * time 0.80 * step 67709\n",
      "Ep 731 * AvgReward -930.26 * true AvgReward -930.26 * Reward -322.73 * True Reward -322.73 * time 1.88 * step 67854\n",
      "Ep 732 * AvgReward -913.91 * true AvgReward -913.91 * Reward -745.06 * True Reward -745.06 * time 1.50 * step 67972\n",
      "Ep 733 * AvgReward -946.01 * true AvgReward -946.01 * Reward -2061.41 * True Reward -2061.41 * time 4.54 * step 68286\n",
      "Ep 734 * AvgReward -938.41 * true AvgReward -938.41 * Reward -766.41 * True Reward -766.41 * time 1.21 * step 68378\n",
      "Ep 735 * AvgReward -925.16 * true AvgReward -925.16 * Reward -795.66 * True Reward -795.66 * time 1.19 * step 68460\n",
      "Ep 736 * AvgReward -930.36 * true AvgReward -930.36 * Reward -964.95 * True Reward -964.95 * time 1.28 * step 68560\n",
      "Ep 737 * AvgReward -923.66 * true AvgReward -923.66 * Reward -509.99 * True Reward -509.99 * time 1.34 * step 68665\n",
      "Ep 738 * AvgReward -914.55 * true AvgReward -914.55 * Reward -439.92 * True Reward -439.92 * time 1.04 * step 68749\n",
      "Ep 739 * AvgReward -921.92 * true AvgReward -921.92 * Reward -1066.62 * True Reward -1066.62 * time 1.38 * step 68858\n",
      "Ep 740 * AvgReward -898.84 * true AvgReward -898.84 * Reward -1671.56 * True Reward -1671.56 * time 1.73 * step 68992\n",
      "Ep 741 * AvgReward -908.36 * true AvgReward -908.36 * Reward -1144.25 * True Reward -1144.25 * time 1.52 * step 69106\n",
      "Ep 742 * AvgReward -912.20 * true AvgReward -912.20 * Reward -878.69 * True Reward -878.69 * time 1.05 * step 69184\n",
      "Ep 743 * AvgReward -914.54 * true AvgReward -914.54 * Reward -825.96 * True Reward -825.96 * time 1.13 * step 69260\n",
      "Ep 744 * AvgReward -911.90 * true AvgReward -911.90 * Reward -736.49 * True Reward -736.49 * time 0.85 * step 69324\n",
      "Ep 745 * AvgReward -919.70 * true AvgReward -919.70 * Reward -1234.00 * True Reward -1234.00 * time 1.57 * step 69447\n",
      "Ep 746 * AvgReward -944.33 * true AvgReward -944.33 * Reward -1756.64 * True Reward -1756.64 * time 1.94 * step 69587\n",
      "Ep 747 * AvgReward -955.66 * true AvgReward -955.66 * Reward -1347.91 * True Reward -1347.91 * time 1.41 * step 69689\n",
      "Ep 748 * AvgReward -948.16 * true AvgReward -948.16 * Reward -1028.57 * True Reward -1028.57 * time 1.18 * step 69774\n",
      "Ep 749 * AvgReward -949.28 * true AvgReward -949.28 * Reward -747.74 * True Reward -747.74 * time 0.83 * step 69833\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 968.1444172859192 s\n"
     ]
    }
   ],
   "source": [
    "run(total_episodes=750, start_steps=10000, save_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a6b6736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test(render=True, continuous=False, total_episodes=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
