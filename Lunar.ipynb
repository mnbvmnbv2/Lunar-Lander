{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7764110b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\flatbuffers\\compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:36: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  'nearest': pil_image.NEAREST,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:37: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  'bilinear': pil_image.BILINEAR,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:38: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  'bicubic': pil_image.BICUBIC,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:39: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "  'hamming': pil_image.HAMMING,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:40: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "  'box': pil_image.BOX,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:41: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  'lanczos': pil_image.LANCZOS,\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from gym import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593313f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of State Space ->  8\n",
      "Size of Action Space ->  2\n",
      "Max Value of Action ->  1.0\n",
      "Min Value of Action ->  -1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set seed\n",
    "seed = 1453\n",
    "\n",
    "env = gym.make('LunarLander-v2',\n",
    "              continuous=True)\n",
    "\n",
    "# env = gym.make(\n",
    "#     \"LunarLander-v2\",\n",
    "#     continuous=False,\n",
    "#     gravity=-10.0,\n",
    "#     enable_wind=False,\n",
    "#     wind_power=15.0,\n",
    "#     turbulence_power=1.5,\n",
    "# )\n",
    "\n",
    "# This is needed to get the input size for the NN\n",
    "num_states = env.observation_space.low.shape[0]\n",
    "print(\"Size of State Space ->  {}\".format(num_states))\n",
    "num_actions = env.action_space.shape[0]\n",
    "print(\"Size of Action Space ->  {}\".format(num_actions))\n",
    "\n",
    "action_space = spaces.Box(low=-1, high=1, shape=(num_actions,), dtype='float32')\n",
    "\n",
    "# This is needed to clip the actions within the legal boundaries\n",
    "upper_bound = action_space.high[0]\n",
    "lower_bound = action_space.low[0]\n",
    "\n",
    "print(\"Max Value of Action ->  {}\".format(upper_bound))\n",
    "print(\"Min Value of Action ->  {}\".format(lower_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a25ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using OU Noise\n",
    "class OUActionNoise:\n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None):\n",
    "        self.theta = theta\n",
    "        self.mean = mean\n",
    "        self.std_dev = std_deviation\n",
    "        self.dt = dt\n",
    "        self.x_initial = x_initial\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        x = (\n",
    "            self.x_prev\n",
    "            + self.theta * (self.mean - self.x_prev) * self.dt\n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
    "        )\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        if self.x_initial is not None:\n",
    "            self.x_prev = self.x_initial\n",
    "        else:\n",
    "            self.x_prev = np.zeros_like(self.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f235a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(layer1=400, layer2=300):\n",
    "    # Initialize weights between -3e-3 and 3-e3\n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "\n",
    "    inputs = layers.Input(shape=(num_states,))\n",
    "    out = layers.Dense(layer1, activation=\"relu\")(inputs)\n",
    "    out = layers.Dense(layer2, activation=\"relu\")(out)\n",
    "    outputs = layers.Dense(1, activation=\"tanh\", kernel_initializer=last_init)(out)\n",
    "\n",
    "    # Multiply to fill the whole action space which should be equal around 0\n",
    "    outputs = outputs * upper_bound\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def get_critic(layer1=400, layer2=300):\n",
    "    # State as input\n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "\n",
    "    # Action as input\n",
    "    action_input = layers.Input(shape=(num_actions))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "\n",
    "    concat = layers.Concatenate()([state_out, action_out])\n",
    "\n",
    "    out = layers.Dense(layer1, activation=\"relu\")(concat)\n",
    "    out = layers.Dense(layer2, activation=\"relu\")(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "\n",
    "    # Make it into a keras model\n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "# This updates the weights in a slow manner which keeps stability\n",
    "@tf.function\n",
    "def update_target(target_weights, weights, tau):\n",
    "    for (a, b) in zip(target_weights, weights):\n",
    "        a.assign(b * tau + a * (1 - tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d09a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, buffer_capacity=50000, batch_size=64, std_dev=0.2, critic_lr=0.002,\n",
    "            actor_lr=0.001, gamma=0.99, tau=0.005):\n",
    "        \n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # This is used to make sure we only sample from used buffer space\n",
    "        self.buffer_counter = 0\n",
    "\n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        \n",
    "        self.std_dev = std_dev\n",
    "        self.critic_lr = critic_lr\n",
    "        self.actor_lr = actor_lr\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        \n",
    "        self.actor_model = get_actor(layer1=400, layer2=300)\n",
    "        self.critic_model = get_critic(layer1=400, layer2=300)\n",
    "\n",
    "        self.target_actor = get_actor(layer1=400, layer2=300)\n",
    "        self.target_critic = get_critic(layer1=400, layer2=300)\n",
    "        \n",
    "        self.critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "        self.actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "        \n",
    "        # Making the weights equal initially\n",
    "        self.target_actor.set_weights(self.actor_model.get_weights())\n",
    "        self.target_critic.set_weights(self.critic_model.get_weights())\n",
    "        \n",
    "        self.ou_noise = OUActionNoise(mean=np.zeros(1), std_deviation=float(std_dev) * np.ones(1))\n",
    "    \n",
    "    # Makes a record of the outputted (s,a,r,s') obervation tuple\n",
    "    def record(self, obs_tuple):\n",
    "        # Reuse the same buffer replacing old entries\n",
    "        index = self.buffer_counter % self.buffer_capacity\n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "\n",
    "        self.buffer_counter += 1\n",
    "    \n",
    "    # Move the update and learn function from buffer to Agent to \"decrease\" scope\n",
    "    @tf.function\n",
    "    def update(\n",
    "        self, state_batch, action_batch, reward_batch, next_state_batch,\n",
    "    ):\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = self.target_actor(next_state_batch, training=True)\n",
    "            y = reward_batch + self.gamma * self.target_critic(\n",
    "                [next_state_batch, target_actions], training=True\n",
    "            )\n",
    "            critic_value = self.critic_model([state_batch, action_batch], training=True)\n",
    "            critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n",
    "\n",
    "        critic_grad = tape.gradient(critic_loss, self.critic_model.trainable_variables)\n",
    "        self.critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, self.critic_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions = self.actor_model(state_batch, training=True)\n",
    "            critic_value = self.critic_model([state_batch, actions], training=True)\n",
    "\n",
    "            actor_loss = -tf.math.reduce_mean(critic_value)\n",
    "\n",
    "        actor_grad = tape.gradient(actor_loss, self.actor_model.trainable_variables)\n",
    "        self.actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, self.actor_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "    # We compute the loss and update parameters\n",
    "    def learn(self):\n",
    "        # Sample only valid data\n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        # Randomly sample indices\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "\n",
    "        self.update(state_batch, action_batch, reward_batch, next_state_batch)\n",
    "        \n",
    "    def policy(self, state, noise_object, use_noise=True, noise_mult=1):\n",
    "        # For doing actions without added noise\n",
    "        if not use_noise:     \n",
    "            sampled_actions = tf.squeeze(self.actor_model(state)).numpy()\n",
    "            legal_action = np.clip(sampled_actions, lower_bound, upper_bound)\n",
    "\n",
    "            return [np.squeeze(legal_action)]\n",
    "        else:\n",
    "            sampled_actions = tf.squeeze(self.actor_model(state))\n",
    "            noise = noise_object()\n",
    "            # Adding noise to action\n",
    "            sampled_actions = sampled_actions.numpy() + noise * noise_mult\n",
    "\n",
    "            # We make sure action is within bounds\n",
    "            legal_action = np.clip(sampled_actions, lower_bound, upper_bound)\n",
    "\n",
    "            return [np.squeeze(legal_action)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f522c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed(x, episode):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42f9f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(total_trials=3, total_episodes=100, \n",
    "            buffer_capacity=50000, batch_size=64, std_dev=0.2, critic_lr=0.002, render=False,\n",
    "            actor_lr=0.001, gamma=0.99, tau=0.005, noise_mult=1, save_weights=False, \n",
    "            directory='Weights/', actor_name='actor', critic_name='critic',\n",
    "            gamma_func=fixed, tau_func=fixed, critic_lr_func=fixed, actor_lr_func=fixed,\n",
    "            noise_mult_func=fixed, std_dev_func=fixed, mean_number=40):\n",
    "    # To store reward history of each episode\n",
    "    ep_reward_list = []\n",
    "    # To store average reward history of last few episodes\n",
    "    avg_reward_list = []\n",
    "    # To separate assisted reward structures from the \"true\"\n",
    "    true_reward_list = []\n",
    "    true_avg_reward_list = []\n",
    "    \n",
    "    for trial in range(total_trials):\n",
    "\n",
    "        # add sublists for each trial\n",
    "        avg_reward_list.append([])\n",
    "        ep_reward_list.append([])\n",
    "        \n",
    "        true_reward_list.append([])\n",
    "        true_avg_reward_list.append([])\n",
    "        \n",
    "        agent = Agent(buffer_capacity=buffer_capacity, batch_size=batch_size, std_dev=std_dev, \n",
    "                critic_lr=critic_lr, actor_lr=actor_lr, gamma=gamma, tau=tau)\n",
    "\n",
    "        for ep in range(total_episodes):\n",
    "            # functions for different parameters\n",
    "            agent.gamma = gamma_func(gamma, ep)\n",
    "            agent.tau = tau_func(tau, ep)\n",
    "            agent.critic_lr = critic_lr_func(critic_lr, ep)\n",
    "            agent.actor_lr = actor_lr_func(actor_lr, ep)\n",
    "            agent.noise_mult = noise_mult_func(noise_mult, ep)\n",
    "            agent.std_dev = std_dev_func(std_dev, ep)\n",
    "            \n",
    "            # Used for time benchmarking\n",
    "            before = time.time()\n",
    "\n",
    "            prev_state = env.reset()\n",
    "            episodic_reward = 0\n",
    "            true_reward = 0\n",
    "\n",
    "            while True:\n",
    "                if render:\n",
    "                    env.render()\n",
    "                \n",
    "                tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
    "\n",
    "                action = agent.policy(tf_prev_state, agent.ou_noise, noise_mult=noise_mult)\n",
    "                # Recieve state and reward from environment.\n",
    "                state, reward, done, info = env.step(action)\n",
    "                \n",
    "                # Add this before eventual reward modification\n",
    "                true_reward += reward\n",
    "                \n",
    "                # Eventual reward modification goes here\n",
    "\n",
    "                agent.record((prev_state, action, reward, state))\n",
    "                episodic_reward += reward\n",
    "\n",
    "                agent.learn()\n",
    "                update_target(agent.target_actor.variables, agent.actor_model.variables, agent.tau)\n",
    "                update_target(agent.target_critic.variables, agent.critic_model.variables, agent.tau)\n",
    "\n",
    "                # End this episode if en episode is done\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "                prev_state = state\n",
    "\n",
    "            ep_reward_list[trial].append(episodic_reward)\n",
    "            \n",
    "            true_reward_list[trial].append(true_reward)\n",
    "            \n",
    "            true_avg_reward = np.mean(true_reward_list[trial][-mean_number:])\n",
    "            true_avg_reward_list[trial].append(true_avg_reward)\n",
    "\n",
    "            # Mean of last x episodes\n",
    "            avg_reward = np.mean(ep_reward_list[trial][-mean_number:])\n",
    "            print(\"Episode * {} * Avg Reward is ==> {} * true_avg_reward: {} * time used: {}\"\n",
    "                  .format(ep, avg_reward, true_avg_reward, (time.time() - before)))\n",
    "            avg_reward_list[trial].append(avg_reward)\n",
    "\n",
    "        if save_weights:\n",
    "            agent.actor_model.save_weights(directory + actor_name + '-trial' + str(trial) + '.h5')\n",
    "            agent.critic_model.save_weights(directory + critic_name + '-trial' + str(trial) + '.h5')\n",
    "    \n",
    "    # Plotting graph\n",
    "    for idx, p in enumerate(true_avg_reward_list):\n",
    "        plt.plot(p, label=str(idx))\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"True Avg. Epsiodic Reward (\" + str(mean_number) + \")\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return to be able to make graphs etc. later, or use the data for other stuff\n",
    "    return true_reward_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a57bcf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(total_episodes=10, actor_weights='Weights/actor-trial0.h5', render=False):\n",
    "    rewards = []\n",
    "    \n",
    "    for ep in range(total_episodes):\n",
    "        ep_reward = 0\n",
    "        \n",
    "        # Used for time benchmarking\n",
    "        before = time.time()\n",
    "        \n",
    "        prev_state = env.reset()\n",
    "        agent = Agent(buffer_capacity=0, batch_size=0, std_dev=0, \n",
    "                critic_lr=0, actor_lr=0, gamma=0, tau=0)\n",
    "        agent.actor_model.load_weights(actor_weights)\n",
    "        \n",
    "        while True:\n",
    "            if render:\n",
    "                env.render()\n",
    "\n",
    "            tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
    "\n",
    "            action = agent.policy(tf_prev_state, 0, use_noise=False)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            ep_reward += reward\n",
    "\n",
    "            if done:\n",
    "                print(str(time.time() - before) + 's')\n",
    "                rewards.append(ep_reward)\n",
    "                break\n",
    "\n",
    "            prev_state = state\n",
    "            \n",
    "    plt.plot(rewards)\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"True reward\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09f7ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random(total_episodes=10, render=False):\n",
    "    rewards = []\n",
    "    \n",
    "    for ep in range(total_episodes):\n",
    "        ep_reward = 0\n",
    "        \n",
    "        # Used for time benchmarking\n",
    "        before = time.time()\n",
    "        \n",
    "        prev_state = env.reset()\n",
    "        \n",
    "        while True:\n",
    "            if render:\n",
    "                env.render()\n",
    "            action = env.action_space.sample()\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            ep_reward += reward\n",
    "\n",
    "            if done:\n",
    "                print(str(time.time() - before) + 's')\n",
    "                rewards.append(ep_reward)\n",
    "                break\n",
    "\n",
    "            prev_state = state\n",
    "            \n",
    "    plt.plot(rewards)\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"True reward\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83b8ba",
   "metadata": {},
   "source": [
    "---\n",
    "# Runs and tests\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9a917bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.784902811050415s\n",
      "2.457620859146118s\n",
      "1.3718876838684082s\n",
      "1.6930670738220215s\n",
      "2.425684928894043s\n",
      "3.6305603981018066s\n",
      "2.762542724609375s\n",
      "2.5557613372802734s\n",
      "1.3751306533813477s\n",
      "2.5373198986053467s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEGCAYAAACZ0MnKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5Z0lEQVR4nO3dd3xc9ZXw/8/RqHeruKhZliUbXCnGxkamGJaQDYkJJKEFSLIbQmKS/J4t2ZRns5tk2d1n9/ntZhNKQliSkFA2gRAIkISYbtywwRrZGLAsF43cJNkayerlPH/oyoyNZI+kmbkzmvN+ve7L0p2Ze48GoTPfdr6iqhhjjDHBSHA7AGOMMbHDkoYxxpigWdIwxhgTNEsaxhhjgmZJwxhjTNAS3Q4g3AoKCrS8vNztMIwxJmZs3bq1WVULR3ps0ieN8vJytmzZ4nYYxhgTM0Rk32iPWfeUMcaYoFnSMMYYE7SYSxoicpWIvCsidSLydbfjMcaYeBJTSUNEPMA9wIeBecCNIjLP3aiMMSZ+xFTSAJYCdapar6q9wGPAapdjMsaYuBFrSaMYaAj43uecO4mI3C4iW0RkS1NTU8SCM8aYyS7WkkZQVPV+VV2iqksKC0ecamyMMWYcYi1pNAKlAd+XOOdMGHX29vPIpv30Dwy6HYoxxmWxljTeAKpEZJaIJAM3AE+7HNOk97uaA3zzyVqeeNPndijGGJfFVNJQ1X7gTuCPwE7gV6q6w92oJr8anx+A+17eba0NY+JcTCUNAFV9TlXnqOpsVb3L7XjigdfXSlZqIntbOnm29qDb4RhjXBRzScNEVnffAO8eauemZWXMmZbJ3S/WMThoWwQbE68saZjTevdQO30Dyjkluay5rJJdR47z/NuH3A7LGOMSSxrmtLyNQ+MZi0pzuXpREeX56dz9Uh2q1towJh5Z0jCn5W1oJT8jmaKcVDwJwpcurWR7Yxsvv2eLJo2JR5Y0zGnVNvpZWJKDiABwzbnFFOemcfeL1towJh5Z0jCj6uod4L3D7SwqyT1xLjkxgTsuqWDrvmNsrD/qXnDGGFdY0jCj2nHAz6DCouKck85/ckkphVkp3P3SLpciM8a4xZKGGZXXWdS3qOTkpJGa5OH2lRW8XtfC1n3H3AjNGOMSSxpmVLWNfqZnpzI1O/UDj920rIwp6Unc81KdC5EZY9xiScOMqsbXysJTWhnDMlIS+dxFs3jxnSNsd6blGmMmP0saZkTt3X3UN3V8YDwj0K0ryslKSeTel621YUy8sKRhRrS9sQ0YWtQ3mpy0JG5bUc7vtx+i7kh7hCIzxrjJkoYZkdfXCsDC07Q0AD5XPYvURA/3vrQ7AlEZY9xmScOMyNvop2RKGnkZyad9Xl5GMjcvK+OpmgPsa+mIUHTGGLdY0jAjqvX5WRywqO90Pn9xBZ4E4UevWGvDmMnOkob5gGMdvew/2jnqzKlTTctO5folpTy+1ceB1q4wR2eMcZMlDfMBtcOVbc8wnhHoC5dUoAr3v1ofrrCMMVEg6pKGiPyjiDSKyDbn+POAx74hInUi8q6IfMjNOCez4aQxfwxJo2RKOh8/t5hHN++nqb0nXKEZY1wWdUnD8Z+qeo5zPAcgIvOAG4D5wFXAvSLicTPIyaqmoZWKggxy0pLG9LovXjqbvoFBHlhnrQ1jJqtoTRojWQ08pqo9qroHqAOWuhzTpDRcDn2sKgozuXpREb/csI/Wzt4wRGaMcVu0Jo07RcQrIg+KyBTnXDHQEPAcn3POhNCR9m4O+rvPuD5jNGsuq6Sjd4Cfvr43tIEZY6KCK0lDRNaKyPYRjtXAfcBs4BzgIPD/j+P6t4vIFhHZ0tRkO8yNRa1T2XbxaVaCn87c6VlcOW8aP319D+3dfSGMzBgTDVxJGqp6haouGOF4SlUPq+qAqg4CP+H9LqhGoDTgMiXOuZGuf7+qLlHVJYWFheH9YSYZr89PgsC8Gdnjvsadqypp6+7nFxv3hTAyY0w0iLruKRGZEfDtx4HtztdPAzeISIqIzAKqgM2Rjm+yq230Uzk1k4yUxHFfY1FJLpfMKeS/X9tDV+9ACKMzxrgt6pIG8G8iUisiXuAy4H8BqOoO4FfA28AfgDWqan+RQkhV8fr8J23vOl53rqqkpaOXRzfvn3hgxpioMf6Pk2Giqrec5rG7gLsiGE5cOejvpvl4zwd26huPC8rzWDYrjx+/upubLywjJdFmRxszGURjS8O4ZHh71/HOnDrVl1dVcbith8e3+kJyPWOM+yxpmBNqG1tJTBDOnsAgeKCLKvNZXJrLfS/vpm9gMCTXNMa4y5KGOcHr8zN3ehapSaHpShIRvnxZJb5jXTy97UBIrmmMcZclDQMEDoKHpmtq2OVnT+XsGdnc83IdA4Ma0msbE20ajnby/bXvTerfdUsaBoCGo134u/pCMnMqkIhw52WV1Dd18Ifth0J6bWOiza+3NPD9tbtYu/Ow26GEjSUNA0BNkNu7jsdVC6ZTUZjBD1/cherk/QRmjNepEP3z9XvdDSSMLGkYYGhRX3JiAnOmZYX82p4EYc2llbxzqJ0Xdh4J+fWNiQbDXbxpSR7W727hvcPtbocUFpY0DABeXytnz8gmOTE8vxIfO6eI0rw0fvhSnbU2zKTU2NrF0Y5evnTpbJITE3how163QwoLSxqGwUFle2Mbi0M8CB4oyZPAFy+ppKahldfrWsJ2H2PcMrzO6ZK5haxeXMRv3mykbRIW7bSkYahv7uB4T39YxjMCXXd+MdOzU/nhi7vCeh9j3FDjayXJI8ydnsVtK8rp7B3g11sm38JWSxqG2sZWgJDPnDpVSqKH2y+uYNOeo7yx92hY72VMpNX6/Jw9I5uURA8LinM4f+YUfrFhL4OTbPqtJQ1DTcPQ4F3l1Myw3+vGpWXkZyRz94t1Yb+XMZEyOKjU+vwntdZvW1HO3pZOXtk1ufb0saRhqG30s6A4G0+ChP1eacke/mLlLF55rwmvM83XmFi3t6WD9p5+Fge01q+aP52pWSmTbvqtJY041z8wyI4DfhYW50bsnrdcOJPs1ERrbZhJ40Sxz4DJJMmJCdy0rIyX321iT3OHW6GFnCWNOLfryHG6+wZZXBreQfBAWalJfPaiWTz/9mHeOdQWsfsaEy5en5/UpASqTunivWlZGUke4RcbJs8ulpY04lxtiMuhB+uzF5WTkezh3pd2R/S+xoSD19fK/KIcEj0n/0mdmpXKny+cwa+3NNDR0+9SdKFlSSPOeRtbyUpJpDw/I6L3zU1P5tPLZ/KM9wD1Tccjem9jQmmoi7dt1GKft60op72nn9+81RjhyMLDkkacq/X5WViSQ0IEBsFP9ZfVFSR5ErjvZWttmNhV13Scrr6BkwbBA51bmsvC4hweWr93UlRDcCVpiMgnRWSHiAyKyJJTHvuGiNSJyLsi8qGA81c55+pE5OuRj3ry6e0fZOfB9pMG7yKpMCuFG5eW8eRbjfiOdboSgzETNdIgeCAR4bYV5ew6cpwNu2O/GoJbLY3twLXAq4EnRWQecAMwH7gKuFdEPCLiAe4BPgzMA250nmsm4N1D7fQODLIogjOnTvWFSyoQgR+/Uu9aDMZMhNc31MU76zRdvFcvmkFeRjI/mwTTb11JGqq6U1XfHeGh1cBjqtqjqnuAOmCpc9Spar2q9gKPOc81E+A9sRLcnZYGwIycND5xfgn/s6WBw23drsVhzHjV+vwsKD59F29qkocbLihl7c7DMd+qjrYxjWKgIeB7n3NutPMjEpHbRWSLiGxpappcqzFDydvgZ0p6EiVT0lyN44uXVDIwqPzkVWttmNgy3MW7KIgp65++cCYiwi82xvb027AlDRFZKyLbRzjC3kJQ1ftVdYmqLiksLAz37WKWt9HPwpJcRCI/CB6oLD+d1YuLeHjTfo529LoaizFj8c6htqC7eIty07hy3jT+540GuvsGwh9cmIQtaajqFaq6YITjqdO8rBEoDfi+xDk32nkzTt19A7x3uJ1FEV6fMZovXTab7v4BHly3x+1QTktVWbermV9s3Me6Xc00tnZNuoJ0JnjDg+DBdvHeuryc1s4+nt52IJxhhVWi2wGc4mngERH5D6AIqAI2AwJUicgshpLFDcBNrkU5Cew40MbAoLo6nhGocmoWH14wnZ+v38vnL64gJy3J7ZBOoqq8uquZ7699j7f2t570WEpiArMKMqgozGBWQQazCjKHvi/IYEpGsjsBm4jw+lrH1MV7YUUec6dl8bP1e/nkkhLXW/nj4UrSEJGPAz8ECoFnRWSbqn5IVXeIyK+At4F+YI2qDjivuRP4I+ABHlTVHW7EPlnUOsUCw10OfSzWXFbJc7WHeGj9Xr58eZXb4QBDyeI1J1m8ub+VopxU7vr4Ai6dO5X9LZ3UNx9nT1MHe5o7eOdgO8/vOEx/QMsjNz3JSSCZAUklg/L8DNKSPS7+ZCYUvD4/i8bQxTs8/fabT9aydd8xlpTnhTnC0HMlaajqk8CTozx2F3DXCOefA54Lc2hxw9vopzArhWnZKW6HcsL8ohwuP2sqD76+h89VzyIjxb2G8GjJ4hPnl5CSOPTHvjg3jeWz8096Xd/AIL5jXexpPk59Uwf1zR3saerg9bpmnnjz5A15inJSmVU4lFBmFWQ4X2dQnJv2gXIUJvp09Q6w68hx/mzetDG97ppzi/jX3+/kZ+v3WtIwscPr87O4JCfqmsdrVlVy7b3reWTTfj5/cUXE76+qrKtr5vtrd7F13zGKclL5p2sW8Mkl7yeL00nyJJxoTaw66+THOnr62dsy1CoZbp3sbu7gt9saae/uD7iGUJaXzqyCTGYHtE5mFWZQmJkSdf/N4tXbB/1OF2/umF6XnpzIp5aU8rP1eznc1s207NTwBBgmljTi0PGefnY3Heeji4rcDuUDziubwkWV+dz/Wj23LJ9JalJkunBOTRYzxpgsgpGRksj8ohzmF508jqSqHO3oZU+z0zIJSCqv7mqit3/wxHMzUxJPJJGKwgyWV+SzdFaeJRIX1DSMbRA80K3Ly/nv1/fw8MZ9/NWVc0MdWlhZ0ohDOxr9qLq7qO907rysiht/spFfb2ngluXlYb2XqvJ6XQvfX/seW5xk8b1rFvCpECaLMxER8jNTyM9M+UB3xcCgcqC1ayiROEd9cwdvNRzjd94DfH/tLiqnZnLT0jKuO6+EnPTomkAwmdU2+pmWnTKulkJZfjqr5k7lkc37WbOqMmK/a6FgSSMOnalWjtsurMhjycwp/OiVeq6/oIzkxND370dDsgiGJ0EozUunNC+di+ecvOaos7efZ70HeWTzfr77zNv8nz+8w0cWzeDmZWWcVzbFWh9hVuNrndBEkltXlHPbg5v5fe0hrjl31LXKUceSRhzyNvopzk2jIDN6BsEDiQhrVlXy2Z++wW/fauRTF5Se+UVBUlXW7x5KFm/sjd5kEYz05EQ+uaSUTy4p5e0DbTyyeR+/fesAv3mzkbOmZ3HTsjKuObeY7FRrfYRae3cf9U0dfPyc8f+xX1lZQEVBBj9bvzemkoZN0YhDtb7WiG+6NFaXzilkQXE2975cR//A4JlfcAZDLYtmPvXjDdz8wCYajnbxvdXzeflvL+WWC2fGXMI41byibP7pmoVs+ubl/Ou1C0nyJPDtp3aw7K4X+NrjNdQ0tE6KstzRorbRGc8ozR33NRIShFuXz2RbQys1Da2hCSwCLGnEGX9nH3tbOoOqleMmEeHOy6rY29LJs7UHx30dVWV9XTPX/3jjScnila9dyi3Ly2M+WZwqIyWRG5aW8bsvV/O7O6u55twinvEeZPU9r3P1D9fx8KZ9HJ8kO8i5KVQ7Xl53fgkZyR5+vmFvCKKKDEsacebEJyQXy6EH68p505gzLZN7Xqobc6mOwGRx0wOb2H+0k+8OtywmYbIYycKSHP7l2kVs+ublfO+aBQwqfOvJ7Sy7ay3ffLKW7c7vghk7r89PaV4aeRNc8Z+VmsR155fwTM1Bmo/3hCi68LIxjTgzXA492runYKj5vuaySr762Daef/swVy2YfsbXqCob6lv4/tpdbN5zlGnZKXx39Xw+taQ0YtN3o01WahK3XDiTTy8rY1tDKw9v2s9v3vTxyKb9LC7J4aZlZXx0cRHpyfbnIFg1vtZRd+obq1uXl/PQhn08tnk/d66KjkoIp2MtjTjjbfAzMz89ZqZmfmThDMrz07n7pV1n7JNfv7uZ6+/fyE0/2cS+lg6+87H5vPK3l3Hr8vK4TRiBRIRzy6bwfz+5mE3fvIJ//Og8uvoG+Lsnall21wt8+6ntvHOoze0wo97Rjl58x7pCNmW9cmomK6sK+OXG/SEZvws3+2gRZ2ob/Zw3c4rbYQQt0ZPAly6t5GtPeHnlvSYunTv1A8/Z4MyG2uS0LL7zsflcf0H8tiyCkZOWxGcumsVtK8rZsu8Yj2zaz2NvNPDQhn2cV5bLzctm8pFFM+w9HIHXqdsWyinrty4v5/MPbeH5tw/z5wtnhOy64WAtjTjSfLyHxtauqCmHHqxrzi2mKCeVH75Yd1JrY8PuFq7/8QZu/MlG9ga0LG5bYS2LYIkIF5Tn8Z/Xn8Omb1zO//7I2bR29vHXv65h2T+/wHd+t4O6I+1uhxlVQjUIHmjVWVMpmZIWE9vBWksjjgwPgkfror7RJCcmcMels/n2UzvYWH8UEfj+2vfYWH+UqVkp/ONH53HD0jJLFBM0JSOZv1xZwV9Uz2Jj/VEe2byfX27cx09f38vSWXncvKyMqxZMj4tJBKdT4/NTUZhBVgjXv3ic6bf//Nw77DzYxtkzskN27VCzpBFHvA1+RGBBjLU0AD61pJQfvljH5x/awvGefksWYSQiLJ+dz/LZ+TQfn8fjW308unk/X31sG1PSk/jE+SXcuLSMisJMt0N1RW1jKytmF4T8up9aUsp//Ok9Htqwl3+5dlHIrx8qljTiSG1jK7MLM8l0seT4eKUmefibK+dw78u7+esr53CjJYuIKMhM4Y5LZnP7ygrW727h4U1DLY+fvLaHFbPzuWlZGVfOmx6WUi/R6HBbN4fbesIy+zA3PZlrzinmybca+burziI3PTo38Iq9vx5m3Lw+P9WVof+EFCnXX1DG9ReUuR1GXEpIEKqrCqiuKuBIeze/3jI0ZffOR96iIDOZB267gHMmsDo6VgzXbVscpsWxt60o57E3GvjVlgZuv3h2WO4xUaN+PBCRdhFpG+2IZJBm4g75uznS3hO1lW1N7Jialcqayyp59WuX8dPPXkBv/yC/3LjP7bAiwutrxZMgzJsRnv+Pzp6RzdJZefxi4z4GonTv+VGThqpmqWo28F/A14FioAT4O+D7E7mpiHxSRHaIyKCILAk4Xy4iXSKyzTl+FPDY+SJSKyJ1IvIDsRKeY/L+NMFcV+Mwk4cnQbhs7lRWVhWybldzXNS28vr8VE3NDOtWvbctL6fhaBcvvXMkbPeYiGA6Ij+mqveqaruqtqnqfcDqCd53O3At8OoIj+1W1XOc446A8/cBnweqnOOqCcYQV2ob/c4npOidlWFiU3VVAYfautnddNztUMJKVfGGcCX4aK6cP43p2alRW48qmKTRISI3i4hHRBJE5GagYyI3VdWdqvpusM8XkRlAtqpu1KGPMw8B10wkhnhT4/MzZ1pWWD8hmfg0PE722q5mlyMJL9+xLo519oV9ynqSJ4FPX1jGa7uaqTsSfYk4mKRxE/Ap4LBzfNI5Fy6zROQtEXlFRFY654oBX8BzfM65EYnI7SKyRUS2NDU1hTHU2KCq1PpaY25Rn4kNpXnpzMxP5/W6yZ00TgyCR6CL94alZSR7EvhFFLY2Tps0RMQD3Kmqq1W1QFULVfUaVd17pguLyFoR2T7CcbqurYNAmaqeC/wV8IiIjLk/RVXvV9UlqrqksLDwzC+Y5CL1CcnEr+rKAjbWH6UvBmonjZfX10qyJ4G507PCfq+CzBSuXjSDx7f6aO/uC/v9xuK0SUNVB4Dq8VxYVa9Q1QUjHE+d5jU9qtrifL0V2A3MARoZGoQfVuKcM0EY/oRkM6dMuFRXFnC8p59tMbSZ0Fh5fX7OnpEVsTUpt60op6N3gCe2+s785AgK5qd/S0SeFpFbROTa4SMcwYhIodO6QUQqGBrwrlfVg0CbiFzozJq6FRg1+ZiTeRsj9wnJxKcVswtIEFg3Scc1BgeV7Y3+iLbWF5fmsrg0l4c27BvzfjLhFEzSSAVagFXAR53j6oncVEQ+LiI+YDnwrIj80XnoYsArItuAx4E7VPWo89iXgAeAOoZaIL+fSAzxpNbn56wZWXFfM8iET056EgtLclk3Scc19rR00N7Tz6IIT1n/zIqZ1Dd3RNX7esYV4ar62VDfVFWfBJ4c4fwTwBOjvGYLsCDUsUx2g4NKrc/Px84pcjsUM8mtrCzgvld209bdR3YIi/lFg+F1TpHu4v3zhTO469md/Hz9Xi6eEx3js2dsaYhIqoisEZF7ReTB4SMSwZmJ2+t8QorEjA8T3y6qLGBgUNm4u8XtUELO6/OTluShMsJFGlMSPdy0tIwX3z3C/pbOiN57NMF0T/0CmA58CHiFoUFoK7AfI2K1HLqJPefNzCUtyTMpp956fX7mF2WT6Il8Ycabls3EI8IvNu6N+L1HEsw7UKmqfw90qOrPgY8Ay8IblgmVmgY/qUkJVE2NzzLWJnJSEj0sq8jjtUmWNPoHBtlxwB/x8Yxh03NS+dCC6fzPGw109va7EkOgYJLG8CThVhFZAOQAH9xz00Sl2sZW5hfluPIJycSf6soC6ps6ONDa5XYoIbPryHG6+wZdnbL+mRXltHX389u3DrgWw7Bg/pLcLyJTgL8HngbeBv5PWKMyITEwqGxvbAtL7X9jRlJdNVRSZDJNva2NgnVOS2ZO4ewZ2Ty0Ya/rhSHPmDRU9QFVPaaqr6hqhapOVdUfRyI4MzG7m47T1Tdgi/pMxMydlkVhVkpUTRGdqBpfK1mpiZTnZ7gWg4jwmRUzeedQO5v2HD3zC8IomNlTu0XkYRG5Q0TmRyIoExo1zupct/piTfwREaorC3i9rjmqFqRNRG2jn4XFOSQkuLsbw+pzislNT+Ln6/e6Gkcw3VPzgB8D+cC/O0nkA2ssTPSpbfSTkeyhosC9T0gm/lRXFtDS0cvOQ7G/V1tP/wA7D7ZFxQev1CQP1y8p5fm3D7s6ZhRM0hhgaDB8ABgEjjiHiXJen58FUfAJycSXiyonz7jGu4fa6RvQqOni/fSFM1FVHt7k3k6JwSSNNoZ26tsD3Kaqy1X1C2GNykxYb/8gbx9sY3Ec7Ntsosv0nFSqpmZOinGNmigYBA9UmpfO5WdP49HNDXT3DbgSQzBJ40aGdtj7EvCYiHxHRC4Pb1hmot473E5v/6DNnDKuqK4qYPOeo679YQsVb0MreRnJFOemuR3KCZ9ZUc7Rjl6e8R505f7BzJ56SlX/FvgC8BzwGeCZMMdlJmh4JXi0fEIy8WVlVQE9/YNs3XfM7VAmpLbRz6KSHIaKa0eHFbPzqZyayc/XuzP9NpjZU0+ISB3wX0A6Q2XJp4Q7MDMxXl8rOWlJlOWlux2KiUNLZ+WTmCAx3UXV2dvPe4fbo27HSxHhtuUzqW3085YL+5cE0z31L8BcVf2Qqt7lrNfoDndgbhscVHr7Y3cXMq8v+j4hmfiRmZLIeWVTYnow/O0DbQxqdE5Zv/a8ErJSEl2ZfhtM0ngb+IaI3A8gIlUiMqH9NKJdW3cfV/3Xq/xs/R63QxmX7r4B3j3UbuMZxlXVVQVsP+DnWEev26GMS7QNggfKSEnkuvNLeK72IEfaI/sZPpik8VOgF1jhfN8I/FPYIooC2alJTM1K5f5X99DVG3sDeTsPttE/GD3TBE18uqiyAFV4fXdstjZqfa1Mz05lanaq26GM6NblM+kbUB7d1BDR+waTNGar6r/hFC5U1U5g0vd5fOXyKpqP9/Do5v1uhzJm7w+C57obiIlri0tyyEpNjNlS6V5fZLd3HauKwkwumVPIw5v2RbQrPZik0SsiaYACiMhsoGciNxWRfxeRd0TEKyJPikhuwGPfEJE6EXlXRD4UcP4q51ydiHx9IvcPxtJZeVxYkcePXtkdc9MGvT4/BZnJzMiJzk9IJj4kehJYXpHPa7uaXS+yN1Zt3X3UN3ewOIqTBsBtK2ZypL2HP+w4FLF7BpM0/gH4A1AqIg8DLwBfm+B9/wQsUNVFwHvANwBEZB5wAzAfuAq4V0Q8IuIB7gE+zFBZkxud54bVV1ZVcaS9h19viWzzb6K8vlYWFtsguHHfyqoCfMe62Bclu84Fa7tvePOyXHcDOYNL50xlZn46D0VwQPy0SUNEEhiaXnstQ+szHgWWqOrLE7mpqj6vqsO7iWxkaDdAgNXAY6rao6p7gDpgqXPUqWq9qvYCjznPDavls/NZMnMK9768m57+2GhtdPT0U3fkuHVNmagwXFIk1jZm8g538Ub5ZJKEBOGWC2eyZd8xtjsxh/2ep3tQVQeBr6lqi6o+q6rPqGqo/+t/Dvi983UxEPix3uecG+18WIkIX7m8ioP+bp7Y2hju24XE2weHpwlG9y+7iQ+zCjIozk3j9Ribeuv1tVKWl86UjGS3QzmjTy4pJS3JE7Hpt8F0T60Vkb8RkVIRyRs+zvQiEVkrIttHOFYHPOdbQD/w8AR+hpHufbuIbBGRLU1NTRO61sqqAhaX5nLvy3X0DUT/uo3hcujRPIBn4sdwqfT1u5sZiKFS6dE+CB4oJy2Jj59XzFM1ByIyvTmYpHE9sIah+lNbnWPLmV6kqleo6oIRjqcAROQzwNXAzfr+KFkjUBpwmRLn3GjnR7v3/aq6RFWXFBYWBvEjjk5E+OrllfiOdfHkW9Hf2qht9DMjJ5WpWTYIbqJDdVUBbd39eH2tbocSlJbjPfiOdUX9IHig25aX09s/yGNvhH/8NZjaU7NGOComclMRuYqhwfSPOVN4hz0N3CAiKSIyC6gCNgNvAFUiMktEkhkaLH96IjGMxWVzp7KgOJt7XqqjP8pbG7U+vy3qM1Flxex8IHZKpQ+PZywsznU3kDGYOz2L5RX5/HLjvrD/jQqmpREOdwNZwJ9EZJuI/AhAVXcAv2JoFfofgDWqOuAMmt8J/BHYCfzKeW5EiAhfXlXFvpZOnq5xf2P30QxPE7TxDBNN8jNTmF+UHTN1qGp9fkRgQXG226GMyW0rZtLY2sXaneHd7siVpKGqlapaqqrnOMcdAY/dpaqzVXWuqv4+4PxzqjrHeeyuSMf8Z2dP46zpWdz9Ul3U9s1u99miPhOdqqsKeHP/MTp6+s/8ZJd5fa1UFGSQlZrkdihjcsXZ0yjKSeWhDXvDeh+3WhoxJyFhaCZVfVMHz9a6U8f+TN5vVltLw0SXlZWF9A0om/ccdTuUM/L6/CyOwQ9eiZ4EPr18Jut3t/De4faw3SeY0ugiIp8WkW8735eJyNKwRRTFrpo/naqpmfzwhV0MRmFro9bnpzQvLSamCZr4sqR8CsmJCVHfRXXI382R9p6YmTl1qhsuKCM5MSGs02+DaWncCyxnaAc/gHaGVmfHnYQE4c5Vlew6cjyiy/aDVeNrZVEMDd6Z+JGa5GFpeV7UD4YPz/CK1S7evIxkPra4iN+82Yi/qy8s9wgmaSxT1TVAN4CqHgPi9qPs1YuKqCjI4AdR1to42tGL71iXDYKbqFVdVcC7h9s50ha92/F4fX48CcK8GbE1CB7oMyvK6eob4PGtvrBcP5ik0efUfhouWFgIRPe80zDyOK2Ndw61s3bnYbfDOWG4sm2sNqvN5FftlBSJ5i4qb6OfOdOySEv2uB3KuC0ozuH8mVP4xYa9YflgG0zS+AHwJDBVRO4C1gH/HPJIYsjHFhcxMz+dH7y4K2qqd3qdleALbBDcRKl5M7LJy0iO2qShqnh9rVFfbyoYd66q5LMXzaI/DEkj8UxPUNWHRWQrcDlD+2hco6o7Qx5JDEn0JLDm0kq+9oSXl99t4rKzprodEt5GPxWFGWTH2DRBEz8SEoQVs/NZ55RKj7YqzL5jXbR29rGoNPaTxmVzw/c3KZjZU2VAJ/A7hlZhdzjn4trHzyumODeN/3ohOlobtT7/pPiEZCa3lVUFHGnvYdeR426H8gE1ziB4LE63jaRguqeeBZ5x/n0BqOf9qrRxK8mTwJrLKtnW0MprLs8IOdLWzaG27qiv/W9MddVQLTi3/58ZSa3PT7IngTnTstwOJaoFU3tqoaoucv6tYmhviw3hDy36XXd+MTNyUvmBy60Nr7MSPJYKrJn4VJybxqyCjKjcArbG18rZRdkkJ9qa59MZ87ujqm8Cy8IQS8xJSfTwxUtns2XfMTbUt7gWh7fRT4LAvKLYnSZo4kd1ZQEb61siuq/1mQwOKtsb26yLNwjBjGn8VcDxNyLyCBC9Vfsi7FNLSpmalcIPXtjlWgxeXytVU7NITz7jvAZjXFddVUBn7wBv7T/mdign1Dd3cLyn39Y5BSGYlkZWwJHC0NhG2LdajRWpSR6+cMlsNtYfdaWujqoODYLbL7uJERdW5JMg0bVeI9ZXgkfSmfYI9wBZqvod57hLVR9W1ehd0umCm5aWUZCZzA9fjHxr44C/m5aOXksaJmbkpCWxuDQ3ypKGn7QkD5VTM90OJeqNmjREJFFVB4CLIhhPTEpL9nD7xRW8tquZrfsi2+T2ntjeNTei9zVmIlZWFlDT0Bq2+khj5fW1sqA4G09CdK0diUana2lsdv7dJiJPi8gtInLt8BGJ4GLJzctmMiU9KeKtDW+jn8QE4azpNk3QxI7qqkIGFTbsdm8CybD+gUF2HGizrqkgBTOmkQq0AKsY2tP7o86/JkBGSiJ/ubKCl99tiuheyLU+P2fNyCI1KXZr5Zj4c05pLunJnqiYevve4eP09A9aF2+QTpc0porIXwHbgVrn3x3Ov9sjEFvMuXX5THLSkvjBC3URud9wrZxY2svYGIDkxAQurMiPinGN2sZWwAbBg3W6pOEBMp0jK+Dr4WPcROTfReQdEfGKyJMikuucLxeRLmff8BN7hzuPnS8itSJSJyI/kGgrXANkpSbxF9WzWLvzMNudqrPhtK+lk7ZumyZoYlN1ZQF7mjvwHet0NY4an5+s1ERm5qW7GkesOF3SOKiq3w2YORV4fHeC9/0TsEBVFwHvAd8IeGz3SHuHA/cBnweqnOOqCcYQFretKCcrJZG7Xwx/a2N4e1dLGiYWraxySqW7XFJkeMp6gg2CB+V0SSNs76CqPq+qwzvMbwRKTvd8EZkBZKvqRh2q1/EQcE244puInLQkPntROX/YcYh3D4Vvn16AWl8ryYlWK8fEpsqpmUzLTnG1i6qnf4B3Dtkg+FicLmlcHqEYPsfJBRBnichbIvKKiKx0zhUDgdtQ+ZxzIxKR20Vki4hsaWpqCn3EZ/C56llkJHvCPpOqxudn3oxskjxWK8fEHhHhosoC1u9ucW0XzHcOttM3oFY+ZAxG/WujqhNa3iwia0Vk+wjH6oDnfAvoBx52Th0EylT1XOCvgEdEZMwFlVT1flVdoqpLCgsLJ/JjjEtuejK3rijn2dqD1B0JT2tjYFDZ0ei3IoUmpq2sKuBoRy9vH2xz5f4nVoKX5rpy/1gUto+oqnqFqi4Y4XgKQEQ+w9DU3ZudLidUtUdVW5yvtwK7gTlAIyd3YZU456LWX1bPIjXRwz0v7Q7L9fc0H6ejd8AW9ZmYdpGzBaxbpdJrfH7yM5Ipykl15f6xyJV+DRG5Cvga8DFV7Qw4X+iULkFEKhga8K5X1YNAm4hc6MyauhV4yoXQg5afmcIty2fy1LZG9jR3hPz6NQ02CG5i39SsVOZOy3JtvcbwIHgUTsaMWm51ht/N0DTeP50ytfZiwCsi24DHgTsCusm+BDwA1DHUAon6jaA+v7KCJE8C97wU+plUtY1+0pM9zC60WjkmtlVXFbB571G6+wYiet/O3n52HWm31voYuVJLW1UrRzn/BPDEKI9tARaEM65QK8xK4aZlZTy0YR9fWVVFWX7o5oF7fa0sKMqxWjkm5lVXFfDf6/bwxt6jrKyK3BjkjgNtDKptXjZWNu0mzO64ZDaeBOG+V0LX2uhzauUstF92Mwksm5VHkkcivl6j5kSxT/v/aCwsaYTZtOxUbriglMe3+kK28nWX1coxk0h6ciLnlU2J+HqN2kY/M3JSmZplg+BjYUkjAu64ZDYAP3olNDOprFaOmWxWVhWw40AbLcd7InZPr8/PQlufMWaWNCKgKDeNT5xfyq/e8HHIP/H9q6xWjplsqp2xjNcjVCrd39XHnuYOFtv6jDGzpBEhX7p0NoOqIWlt1DqfkKxWjpksFhbnkJ2ayLpdkangMFxQ1FoaY2dJI0JK89L5+LnFPLp5P0fax9/asFo5ZjLyJAgrZhewblczzlrfsPL6bJ3TeFnSiKA1l1XSNzDIT16tH/c1TtTKsV92M8lUVxVwwN8dlsWwp/L6WinLSyc3PTns95psLGlEUHlBBtecU8wvN+6neZwDfl5rVptJ6kSp9AjMovI6K8HN2FnSiLA1qyrp7h/ggdf2jOv1tb5W8jKSKZmSFuLIjHFXWV46JVPSwr5eo+V4D42tXSy2Lt5xsaQRYbMLM7l6UREPbdjLsY7eMb9+eJqg1coxk42IsLKqgA27W+gfGAzbfYbHM2xR3/hY0nDBl1dV0tk7wIOvj6210dU7wHuH261ZbSat6spC2nv6qfGFb7tkr8+PCCywLt5xsaThgjnTsvjzhdP52et78Xf2Bf26tw/6GVRb1GcmrxWz8xEJ7xawXl8rswszyUxxpfRezLOk4ZI7L6uivaefn64PvrVh0wTNZDclI5kFRTlhK5WuqngbbRB8IixpuGReUTZ/Nm8aD67bQ3t3cK0Nr8/P1KwUpmVbrRwzeVVXFfDm/mMc7+kP+bUPtXXT1N5j27tOgCUNF31lVRVt3f08tGFfUM/3+lqta8pMeisrC+gfVDbVh76kyInWupUPGTdLGi5aWJLDqrOm8pPX6s/4qaq9u4/65g5rVptJ77yZU0hNSgjLFrBeXyuJCcK8Gdkhv3a8sKThsi+vqqS1s49fbjx9a2N7YxuqNk3QTH6pSR4uKM8Ly7iG1+dnzrQsUpM8Ib92vHAtaYjI90TE62z3+ryIFDnnRUR+ICJ1zuPnBbzmNhHZ5Ry3uRV7KJ1bNoWVVQX85NV6unpH3+7yRDl064s1cWBlVQG7jhwPSVXoYapKrQ2CT5ibLY1/V9VFqnoO8Azwbef8h4Eq57gduA9ARPKAfwCWAUuBfxCRKZEOOhy+enkVLR29PLxp9NaG1+enODeN/MyUCEZmjDuqK4dKpYeypEjD0S5aO/tsXHCCXEsaqtoW8G0GMFzacjXwkA7ZCOSKyAzgQ8CfVPWoqh4D/gRcFdGgw2RJeR7LK/L58av1dPeN3NqwWjkmnpw1PYuCzOSQlkqv8bUCNmV9olwd0xCRu0SkAbiZ91saxUBDwNN8zrnRzo903dtFZIuIbGlqikx9/on6yuVVNLX38D9vNHzgsdbOXvYf7bTxDBM3EoZLpde1hKxUem2jn+TEBOZOzwrJ9eJVWJOGiKwVke0jHKsBVPVbqloKPAzcGar7qur9qrpEVZcUFhaG6rJhdWFFHkvL87jv5d309J/c2qh1KttagTUTT6qrCmg+3sO7h9tDcr2ahlbmzcgmyWPzfyYirO+eql6hqgtGOJ465akPA9c5XzcCpQGPlTjnRjs/KYgIX768kkNt3fx6i++kx4bnli8ospaGiR/VlU6p9BBMvR0cVLbbIHhIuDl7qirg29XAO87XTwO3OrOoLgT8qnoQ+CNwpYhMcQbAr3TOTRrVlQWcW5bLfS/vprf//SqfXl8r5fnp5KQnuRidMZFVlJtGRWFGSAbD65uP09E7YIPgIeBmO+1fna4qL0MJ4KvO+eeAeqAO+AnwJQBVPQp8D3jDOb7rnJs0RISvXF5FY2sXT771fmuj1ue3X3YTl1ZWFrCp/ugHumzHqqbB6raFimtlHlX1ulHOK7BmlMceBB4MZ1xuu3ROIYtKcrj7pTquPa+E1s4+Dvi77ZfdxKXqqkJ+vmEfb+5rZfns/HFfp7bRT3qyh9mFmSGMLj7ZiFCUERG+vKqKhqNdPLXtwIlFfba9q4lHF1bk4UkQ1tVNbBZkja+VBUU5eBJs87KJsqQRha44eypnz8jmnpfq2La/1TaMMXErKzWJc0pzWVc3/uKFfQODvH2gzVrrIWJJIwqJCF+9vJI9zR38dP1eKgszybANY0ycqq4soNbXOqYNywK9d7idnv5BW+cUIpY0otSV86Yzd1oW7d399stu4trKqgIGFdbvHt8sqlqfrXMKJUsaUSohQbhzVSVgv+wmvi0uzSUzJZHXxjn1tsbnJzs1kZn56SGOLD5Zn0cU+8jCGfQPDnLlvOluh2KMa5I8CVxYMf5S6bWNQ5uXidggeChYSyOKJSQIHz+3xMYzTNyrrixgX0snDUc7x/S67r4B3jnYbl28IWRJwxgT9aqrhmrIjXU3v3cOtdM/qCy2pBEyljSMMVFvdmEGM3JSx7xew+uUQ19o44IhY0nDGBP1RISLKgtYv7uFgcHgS6V7fX4KMpMpykkNY3TxxZKGMSYmrKwqoLWzjx0H/EG/xuuzQfBQs6RhjIkJFzml0oMd1+jo6afuyHErwRNiljSMMTGhIDOFs2dkBz31dseBNgYVFpda0gglSxrGmJhRXZnPlr3H6Oo9c6n0E4PgxbnhDSrOWNIwxsSM6qpCegcG2bz3zFvpeH1+inJSKcxKiUBk8cOShjEmZiwtzyPZk8C6XWeeeuv1tdqivjCwpGGMiRlpyR7OnznljKXS/Z197G3ptB0vw8CVpCEi3xMRr4hsE5HnRaTIOX+piPid89tE5NsBr7lKRN4VkToR+bobcRtj3FddVcDOg200tfeM+pzaRtveNVzcamn8u6ouUtVzgGeAbwc89pqqnuMc3wUQEQ9wD/BhYB5wo4jMi3TQxhj3rawamnp7ulLpXmfHy0U2CB5yriQNVW0L+DYDONMSz6VAnarWq2ov8BiwOlzxGWOi1/yiHHLTk067XsPb4Gdmfjo56UkRjCw+uDamISJ3iUgDcDMntzSWi0iNiPxeROY754qBhoDn+Jxzxpg440kQVszO5/W6ZlRH/rxZ2+i38YwwCVvSEJG1IrJ9hGM1gKp+S1VLgYeBO52XvQnMVNXFwA+B347z3reLyBYR2dLUNLEN6Y0x0ae6spCD/m52N3V84LHm4z00tnaxyFaCh0XYkoaqXqGqC0Y4njrlqQ8D1zmvaVPV487XzwFJIlIANAKlAa8pcc6Ndu/7VXWJqi4pLCwM6c9ljHHf8LjGSFNvh7d3tUHw8HBr9lRVwLergXec89PFqSwmIksZiq8FeAOoEpFZIpIM3AA8HdmojTHRojQvnZn56awboaRIja8VEVhgLY2wcGtLuH8VkbnAILAPuMM5/wngiyLSD3QBN+hQp2W/iNwJ/BHwAA+q6g4X4jbGRImLKgt4etsB+gYGSfK8//nX6/NTWZhpO16GiSvvqqpeN8r5u4G7R3nsOeC5cMZljIkdKysLeGTTfmoaWllSngeAquL1+blkjnVLh4utCDfGxKQVswtIkJNLpR/0d9N8vMfGM8LIkoYxJiblpCexsCT3pFLpXhsEDztLGsaYmFVdmc9bDa20d/cBQ0UKExOEs2dkuxzZ5GVJwxgTs6orCxkYVDbWD5VKr230M3d6FqlJHpcjm7wsaRhjYtZ5M3NJS/KwblfTiUFw65oKL0saxpiYlZLoYVlFHuvqmtl/tBN/V5+VDwkzSxrGmJhWXVnA7qYO/rjjEAALbVFfWFnSMMbEtGqnpMgDr+0hOTGBudOzXI5ocrOkYYyJaXOnZVGYlcKR9h7mzcg+aXW4CT17d40xMU1EqK4cam0stkHwsLOkYYyJeRc5SWOhDYKHnVX0MsbEvKsWTGfnwTb+bN40t0OZ9CxpGGNiXmZKIn9/9Ty3w4gL1j1ljDEmaJY0jDHGBM2ShjHGmKBZ0jDGGBM0SxrGGGOCZknDGGNM0CxpGGOMCZolDWOMMUETVXU7hrASkSZg3zhfXgA0n/FZ8cHei5PZ+3Eyez/eNxnei5mqWjjSA5M+aUyEiGxR1SVuxxEN7L04mb0fJ7P3432T/b2w7iljjDFBs6RhjDEmaJY0Tu9+twOIIvZenMzej5PZ+/G+Sf1e2JiGMcaYoFlLwxhjTNAsaRhjjAmaJY0RiMhVIvKuiNSJyNfdjsdNIlIqIi+JyNsiskNEvup2TG4TEY+IvCUiz7gdi9tEJFdEHheRd0Rkp4gsdzsmN4nI/3L+P9kuIo+KSKrbMYWaJY1TiIgHuAf4MDAPuFFE4nlLsH7gr1V1HnAhsCbO3w+ArwI73Q4iSvwX8AdVPQtYTBy/LyJSDHwFWKKqCwAPcIO7UYWeJY0PWgrUqWq9qvYCjwGrXY7JNap6UFXfdL5uZ+iPQrG7UblHREqAjwAPuB2L20QkB7gY+G8AVe1V1VZXg3JfIpAmIolAOnDA5XhCzpLGBxUDDQHf+4jjP5KBRKQcOBfY5HIobvo+8DVg0OU4osEsoAn4qdNd94CIZLgdlFtUtRH4v8B+4CDgV9Xn3Y0q9CxpmKCISCbwBPD/qWqb2/G4QUSuBo6o6la3Y4kSicB5wH2qei7QAcTtGKCITGGoV2IWUARkiMin3Y0q9CxpfFAjUBrwfYlzLm6JSBJDCeNhVf2N2/G46CLgYyKyl6Fuy1Ui8kt3Q3KVD/Cp6nDL83GGkki8ugLYo6pNqtoH/AZY4XJMIWdJ44PeAKpEZJaIJDM0kPW0yzG5RkSEoT7rnar6H27H4yZV/YaqlqhqOUO/Fy+q6qT7JBksVT0ENIjIXOfU5cDbLobktv3AhSKS7vx/czmTcGJAotsBRBtV7ReRO4E/MjT74UFV3eFyWG66CLgFqBWRbc65b6rqc+6FZKLIl4GHnQ9Y9cBnXY7HNaq6SUQeB95kaNbhW0zCkiJWRsQYY0zQrHvKGGNM0CxpGGOMCZolDWOMMUGzpGGMMSZoljSMMcYEzZKGMWMgIgMisi3gOO0KaBG5Q0RuDcF994pIwUSvY8xE2ZRbY8ZARI6raqYL993LUPXU5kjf25hA1tIwJgSclsC/iUitiGwWkUrn/D+KyN84X3/F2ZfEKyKPOefyROS3zrmNIrLIOZ8vIs87ezM8AEjAvT7t3GObiPzYKedvTERY0jBmbNJO6Z66PuAxv6ouBO5mqBruqb4OnKuqi4A7nHPfAd5yzn0TeMg5/w/AOlWdDzwJlAGIyNnA9cBFqnoOMADcHMof0JjTsTIixoxNl/PHeiSPBvz7nyM87mWo5MZvgd8656qB6wBU9UWnhZHN0D4V1zrnnxWRY87zLwfOB94YKm9EGnBkAj+PMWNiScOY0NFRvh72EYaSwUeBb4nIwnHcQ4Cfq+o3xvFaYybMuqeMCZ3rA/7dEPiAiCQApar6EvB3QA6QCbyG070kIpcCzc5+Ja8CNznnPwxMcS71AvAJEZnqPJYnIjPD9yMZczJraRgzNmkB1X5haH/s4Wm3U0TEC/QAN57yOg/wS2eLVAF+oKqtIvKPwIPO6zqB25znfwd4VER2AOsZKruNqr4tIv8beN5JRH3AGmBfiH9OY0ZkU26NCQGbEmvihXVPGWOMCZq1NIwxxgTNWhrGGGOCZknDGGNM0CxpGGOMCZolDWOMMUGzpGGMMSZo/w8Ag/5gmwhbOgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4b7de82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m17\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(total_trials, total_episodes, buffer_capacity, batch_size, std_dev, critic_lr, render, actor_lr, gamma, tau, noise_mult, save_weights, directory, actor_name, critic_name, gamma_func, tau_func, critic_lr_func, actor_lr_func, noise_mult_func, std_dev_func, mean_number)\u001b[0m\n\u001b[0;32m     49\u001b[0m action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mpolicy(tf_prev_state, agent\u001b[38;5;241m.\u001b[39mou_noise, noise_mult\u001b[38;5;241m=\u001b[39mnoise_mult)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Recieve state and reward from environment.\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m state, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Add this before eventual reward modification\u001b[39;00m\n\u001b[0;32m     54\u001b[0m true_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\gym\\wrappers\\time_limit.py:49\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m        \"TimeLimit.truncated\"=False if the environment terminated\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     observation, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\gym\\wrappers\\env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpassive_env_step_check\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:254\u001b[0m, in \u001b[0;36mpassive_env_step_check\u001b[1;34m(env, action)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpassive_env_step_check\u001b[39m(env, action):\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;124;03m\"\"\"A passive check for the environment step, investigating the returning data then returning the data unchanged.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 254\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m    256\u001b[0m         obs, reward, done, info \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\gym\\envs\\box2d\\lunar_lander.py:496\u001b[0m, in \u001b[0;36mLunarLander.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlander\u001b[38;5;241m.\u001b[39mApplyLinearImpulse(\n\u001b[0;32m    490\u001b[0m         (\u001b[38;5;241m-\u001b[39mox \u001b[38;5;241m*\u001b[39m MAIN_ENGINE_POWER \u001b[38;5;241m*\u001b[39m m_power, \u001b[38;5;241m-\u001b[39moy \u001b[38;5;241m*\u001b[39m MAIN_ENGINE_POWER \u001b[38;5;241m*\u001b[39m m_power),\n\u001b[0;32m    491\u001b[0m         impulse_pos,\n\u001b[0;32m    492\u001b[0m         \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    493\u001b[0m     )\n\u001b[0;32m    495\u001b[0m s_power \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m--> 496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mabs(\u001b[43maction\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous \u001b[38;5;129;01mand\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m    498\u001b[0m ):\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;66;03m# Orientation engines\u001b[39;00m\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous:\n\u001b[0;32m    501\u001b[0m         direction \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msign(action[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "run(total_trials=1, total_episodes=17, save_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88080b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(render=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
