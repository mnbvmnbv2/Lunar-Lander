{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7764110b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\flatbuffers\\compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:36: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  'nearest': pil_image.NEAREST,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:37: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  'bilinear': pil_image.BILINEAR,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:38: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  'bicubic': pil_image.BICUBIC,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:39: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "  'hamming': pil_image.HAMMING,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:40: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "  'box': pil_image.BOX,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:41: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  'lanczos': pil_image.LANCZOS,\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593313f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of State Space ->  2\n",
      "Size of Action Space ->  1\n",
      "Max Value of Action ->  1.0\n",
      "Min Value of Action ->  -1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set seed\n",
    "seed = 1453\n",
    "\n",
    "problem = \"LunarLander\"\n",
    "env = gym.make(problem)\n",
    "\n",
    "# This is needed to get the input size for the NN\n",
    "num_states = env.observation_space.shape[0]\n",
    "print(\"Size of State Space ->  {}\".format(num_states))\n",
    "num_actions = env.action_space.shape[0]\n",
    "print(\"Size of Action Space ->  {}\".format(num_actions))\n",
    "\n",
    "# This is needed to clip the actions within the legal boundaries\n",
    "upper_bound = env.action_space.high[0]\n",
    "lower_bound = env.action_space.low[0]\n",
    "\n",
    "print(\"Max Value of Action ->  {}\".format(upper_bound))\n",
    "print(\"Min Value of Action ->  {}\".format(lower_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a25ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using OU Noise\n",
    "class OUActionNoise:\n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None):\n",
    "        self.theta = theta\n",
    "        self.mean = mean\n",
    "        self.std_dev = std_deviation\n",
    "        self.dt = dt\n",
    "        self.x_initial = x_initial\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        x = (\n",
    "            self.x_prev\n",
    "            + self.theta * (self.mean - self.x_prev) * self.dt\n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
    "        )\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        if self.x_initial is not None:\n",
    "            self.x_prev = self.x_initial\n",
    "        else:\n",
    "            self.x_prev = np.zeros_like(self.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f235a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(layer1=400, layer2=300):\n",
    "    # Initialize weights between -3e-3 and 3-e3\n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "\n",
    "    inputs = layers.Input(shape=(num_states,))\n",
    "    out = layers.Dense(layer1, activation=\"relu\")(inputs)\n",
    "    out = layers.Dense(layer2, activation=\"relu\")(out)\n",
    "    outputs = layers.Dense(1, activation=\"tanh\", kernel_initializer=last_init)(out)\n",
    "\n",
    "    # Multiply to fill the whole action space which should be equal around 0\n",
    "    outputs = outputs * upper_bound\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def get_critic(layer1=400, layer2=300):\n",
    "    # State as input\n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "\n",
    "    # Action as input\n",
    "    action_input = layers.Input(shape=(num_actions))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "\n",
    "    concat = layers.Concatenate()([state_out, action_out])\n",
    "\n",
    "    out = layers.Dense(layer1, activation=\"relu\")(concat)\n",
    "    out = layers.Dense(layer2, activation=\"relu\")(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "\n",
    "    # Make it into a keras model\n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "# This updates the weights in a slow manner which keeps stability\n",
    "@tf.function\n",
    "def update_target(target_weights, weights, tau):\n",
    "    for (a, b) in zip(target_weights, weights):\n",
    "        a.assign(b * tau + a * (1 - tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d09a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, buffer_capacity=50000, batch_size=64, std_dev=0.2, critic_lr=0.002,\n",
    "            actor_lr=0.001, gamma=0.99, tau=0.005):\n",
    "        \n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # This is used to make sure we only sample from used buffer space\n",
    "        self.buffer_counter = 0\n",
    "\n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        \n",
    "        self.std_dev = std_dev\n",
    "        self.critic_lr = critic_lr\n",
    "        self.actor_lr = actor_lr\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        \n",
    "        self.actor_model = get_actor(layer1=400, layer2=300)\n",
    "        self.critic_model = get_critic(layer1=400, layer2=300)\n",
    "\n",
    "        self.target_actor = get_actor(layer1=400, layer2=300)\n",
    "        self.target_critic = get_critic(layer1=400, layer2=300)\n",
    "        \n",
    "        self.critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "        self.actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "        \n",
    "        # Making the weights equal initially\n",
    "        self.target_actor.set_weights(self.actor_model.get_weights())\n",
    "        self.target_critic.set_weights(self.critic_model.get_weights())\n",
    "        \n",
    "        self.ou_noise = OUActionNoise(mean=np.zeros(1), std_deviation=float(std_dev) * np.ones(1))\n",
    "    \n",
    "    # Makes a record of the outputted (s,a,r,s') obervation tuple\n",
    "    def record(self, obs_tuple):\n",
    "        # Reuse the same buffer replacing old entries\n",
    "        index = self.buffer_counter % self.buffer_capacity\n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "\n",
    "        self.buffer_counter += 1\n",
    "    \n",
    "    # Move the update and learn function from buffer to Agent to \"decrease\" scope\n",
    "    @tf.function\n",
    "    def update(\n",
    "        self, state_batch, action_batch, reward_batch, next_state_batch,\n",
    "    ):\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = self.target_actor(next_state_batch, training=True)\n",
    "            y = reward_batch + self.gamma * self.target_critic(\n",
    "                [next_state_batch, target_actions], training=True\n",
    "            )\n",
    "            critic_value = self.critic_model([state_batch, action_batch], training=True)\n",
    "            critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n",
    "\n",
    "        critic_grad = tape.gradient(critic_loss, self.critic_model.trainable_variables)\n",
    "        self.critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, self.critic_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions = self.actor_model(state_batch, training=True)\n",
    "            critic_value = self.critic_model([state_batch, actions], training=True)\n",
    "\n",
    "            actor_loss = -tf.math.reduce_mean(critic_value)\n",
    "\n",
    "        actor_grad = tape.gradient(actor_loss, self.actor_model.trainable_variables)\n",
    "        self.actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, self.actor_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "    # We compute the loss and update parameters\n",
    "    def learn(self):\n",
    "        # Sample only valid data\n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        # Randomly sample indices\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "\n",
    "        self.update(state_batch, action_batch, reward_batch, next_state_batch)\n",
    "        \n",
    "    def policy(self, state, noise_object, use_noise=True, noise_mult=1):\n",
    "        # For doing actions without added noise\n",
    "        if not use_noise:     \n",
    "            sampled_actions = tf.squeeze(self.actor_model(state)).numpy()\n",
    "            legal_action = np.clip(sampled_actions, lower_bound, upper_bound)\n",
    "\n",
    "            return [np.squeeze(legal_action)]\n",
    "        else:\n",
    "            sampled_actions = tf.squeeze(self.actor_model(state))\n",
    "            noise = noise_object()\n",
    "            # Adding noise to action\n",
    "            sampled_actions = sampled_actions.numpy() + noise * noise_mult\n",
    "\n",
    "            # We make sure action is within bounds\n",
    "            legal_action = np.clip(sampled_actions, lower_bound, upper_bound)\n",
    "\n",
    "            return [np.squeeze(legal_action)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f522c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed(x, episode):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42f9f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(total_trials=3, total_episodes=100, \n",
    "            buffer_capacity=50000, batch_size=64, std_dev=0.2, critic_lr=0.002, render=False,\n",
    "            actor_lr=0.001, gamma=0.99, tau=0.005, noise_mult=1, save_weights=False, \n",
    "            directory='Weights/', actor_name='actor', critic_name='critic',\n",
    "            gamma_func=fixed, tau_func=fixed, critic_lr_func=fixed, actor_lr_func=fixed,\n",
    "            noise_mult_func=fixed, std_dev_func=fixed, mean_number=40):\n",
    "    # To store reward history of each episode\n",
    "    ep_reward_list = []\n",
    "    # To store average reward history of last few episodes\n",
    "    avg_reward_list = []\n",
    "    # To separate assisted reward structures from the \"true\"\n",
    "    true_reward_list = []\n",
    "    true_avg_reward_list = []\n",
    "    \n",
    "    for trial in range(total_trials):\n",
    "\n",
    "        # add sublists for each trial\n",
    "        avg_reward_list.append([])\n",
    "        ep_reward_list.append([])\n",
    "        \n",
    "        true_reward_list.append([])\n",
    "        true_avg_reward_list.append([])\n",
    "        \n",
    "        agent = Agent(buffer_capacity=buffer_capacity, batch_size=batch_size, std_dev=std_dev, \n",
    "                critic_lr=critic_lr, actor_lr=actor_lr, gamma=gamma, tau=tau)\n",
    "\n",
    "        for ep in range(total_episodes):\n",
    "            # functions for different parameters\n",
    "            agent.gamma = gamma_func(gamma, ep)\n",
    "            agent.tau = tau_func(tau, ep)\n",
    "            agent.critic_lr = critic_lr_func(critic_lr, ep)\n",
    "            agent.actor_lr = actor_lr_func(actor_lr, ep)\n",
    "            agent.noise_mult = noise_mult_func(noise_mult, ep)\n",
    "            agent.std_dev = std_dev_func(std_dev, ep)\n",
    "            \n",
    "            # Used for time benchmarking\n",
    "            before = time.time()\n",
    "\n",
    "            prev_state = env.reset()\n",
    "            episodic_reward = 0\n",
    "            true_reward = 0\n",
    "\n",
    "            while True:\n",
    "                if render:\n",
    "                    env.render()\n",
    "                \n",
    "                tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
    "\n",
    "                action = agent.policy(tf_prev_state, agent.ou_noise, noise_mult=noise_mult)\n",
    "                # Recieve state and reward from environment.\n",
    "                state, reward, done, info = env.step(action)\n",
    "                \n",
    "                # Add this before eventual reward modification\n",
    "                true_reward += reward\n",
    "                \n",
    "                # Eventual reward modification goes here\n",
    "\n",
    "                agent.record((prev_state, action, reward, state))\n",
    "                episodic_reward += reward\n",
    "\n",
    "                agent.learn()\n",
    "                update_target(agent.target_actor.variables, agent.actor_model.variables, agent.tau)\n",
    "                update_target(agent.target_critic.variables, agent.critic_model.variables, agent.tau)\n",
    "\n",
    "                # End this episode if en episode is done\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "                prev_state = state\n",
    "\n",
    "            ep_reward_list[trial].append(episodic_reward)\n",
    "            \n",
    "            true_reward_list[trial].append(true_reward)\n",
    "            \n",
    "            true_avg_reward = np.mean(true_reward_list[trial][-mean_number:])\n",
    "            true_avg_reward_list[trial].append(true_avg_reward)\n",
    "\n",
    "            # Mean of last x episodes\n",
    "            avg_reward = np.mean(ep_reward_list[trial][-mean_number:])\n",
    "            print(\"Episode * {} * Avg Reward is ==> {} * true_avg_reward: {} * time used: {}\"\n",
    "                  .format(ep, avg_reward, true_avg_reward, (time.time() - before)))\n",
    "            avg_reward_list[trial].append(avg_reward)\n",
    "\n",
    "        if save_weights:\n",
    "            agent.actor_model.save_weights(directory + actor_name + '-trial' + str(trial) + '.h5')\n",
    "            agent.critic_model.save_weights(directory + critic_name + '-trial' + str(trial) + '.h5')\n",
    "    \n",
    "    # Plotting graph\n",
    "    for idx, p in enumerate(true_avg_reward_list):\n",
    "        plt.plot(p, label=str(idx))\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"True Avg. Epsiodic Reward (\" + str(mean_number) + \")\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return to be able to make graphs etc. later, or use the data for other stuff\n",
    "    return true_reward_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a57bcf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(total_episodes=10, actor_weights='Weights/actor-trial0.h5', render=False):\n",
    "    rewards = []\n",
    "    \n",
    "    for ep in range(total_episodes):\n",
    "        ep_reward = 0\n",
    "        \n",
    "        # Used for time benchmarking\n",
    "        before = time.time()\n",
    "        \n",
    "        prev_state = env.reset()\n",
    "        agent = Agent(buffer_capacity=0, batch_size=0, std_dev=0, \n",
    "                critic_lr=0, actor_lr=0, gamma=0, tau=0)\n",
    "        agent.actor_model.load_weights(actor_weights)\n",
    "        \n",
    "        while True:\n",
    "            if render:\n",
    "                env.render()\n",
    "\n",
    "            tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
    "\n",
    "            action = agent.policy(tf_prev_state, 0, use_noise=False)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            ep_reward += reward\n",
    "\n",
    "            if done:\n",
    "                print(str(time.time() - before) + 's')\n",
    "                rewards.append(ep_reward)\n",
    "                break\n",
    "\n",
    "            prev_state = state\n",
    "            \n",
    "    plt.plot(rewards)\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"True reward\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83b8ba",
   "metadata": {},
   "source": [
    "---\n",
    "# Runs and tests\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4b7de82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 0 * Avg Reward is ==> -328.45340457699234 * true_avg_reward: -89.47156586124068 * time used: 17.442039012908936\n",
      "Episode * 1 * Avg Reward is ==> -351.83872617569796 * true_avg_reward: -94.4296718989897 * time used: 16.264806985855103\n",
      "Episode * 2 * Avg Reward is ==> -363.35338943648867 * true_avg_reward: -90.67604618276641 * time used: 16.552767992019653\n",
      "Episode * 3 * Avg Reward is ==> -354.31400185407824 * true_avg_reward: -83.37572148488451 * time used: 16.442849159240723\n",
      "Episode * 4 * Avg Reward is ==> -286.47939015583484 * true_avg_reward: -53.21806769293978 * time used: 9.539589166641235\n",
      "Episode * 5 * Avg Reward is ==> -313.4166598089058 * true_avg_reward: -58.42528156642607 * time used: 16.314786672592163\n",
      "Episode * 6 * Avg Reward is ==> -364.1361902118514 * true_avg_reward: -54.32148770136901 * time used: 16.215938329696655\n",
      "Episode * 7 * Avg Reward is ==> -387.967407969512 * true_avg_reward: -57.473442851172486 * time used: 16.160759687423706\n",
      "Episode * 8 * Avg Reward is ==> -391.3989656517417 * true_avg_reward: -62.02439400597388 * time used: 16.17119002342224\n",
      "Episode * 9 * Avg Reward is ==> -427.26625745296815 * true_avg_reward: -60.06524026429521 * time used: 16.207573652267456\n",
      "Episode * 10 * Avg Reward is ==> -424.3768020382311 * true_avg_reward: -63.28522556726587 * time used: 16.17828059196472\n",
      "Episode * 11 * Avg Reward is ==> -438.5288415608773 * true_avg_reward: -64.06264085652502 * time used: 16.279139518737793\n",
      "Episode * 12 * Avg Reward is ==> -441.38598827042887 * true_avg_reward: -66.69593505988944 * time used: 16.22098684310913\n",
      "Episode * 13 * Avg Reward is ==> -442.96765381894056 * true_avg_reward: -69.06429349901778 * time used: 16.220749616622925\n",
      "Episode * 14 * Avg Reward is ==> -445.4749011393391 * true_avg_reward: -70.47728044781974 * time used: 16.29005193710327\n",
      "Episode * 15 * Avg Reward is ==> -447.5575763568442 * true_avg_reward: -70.08531133876457 * time used: 16.136805772781372\n",
      "Episode * 16 * Avg Reward is ==> -448.0727569989618 * true_avg_reward: -71.24292186218977 * time used: 16.276922702789307\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[-89.47156586124068,\n",
       "  -99.38777793673871,\n",
       "  -83.16879475031986,\n",
       "  -61.474747391238765,\n",
       "  67.4125474748391,\n",
       "  -84.46135093385756,\n",
       "  -29.698724511026604,\n",
       "  -79.53712889979677,\n",
       "  -98.43200324438502,\n",
       "  -42.432856589187146,\n",
       "  -95.4850785969725,\n",
       "  -72.61420903837578,\n",
       "  -98.29546550026234,\n",
       "  -99.8529532076863,\n",
       "  -90.25909773104704,\n",
       "  -64.2057747029372,\n",
       "  -89.76469023699308]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(total_trials=1, total_episodes=17, save_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88080b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(render=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
