{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7764110b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.math import argmax\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "from gym import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e4ab220",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(358)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0662e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdd14b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_actions_num = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6470ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.gymlibrary.ml/environments/box2d/lunar_lander/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f235a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using OU Noise\n",
    "class OUActionNoise:\n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None):\n",
    "        self.theta = theta\n",
    "        self.mean = mean\n",
    "        self.std_dev = std_deviation\n",
    "        self.dt = dt\n",
    "        self.x_initial = x_initial\n",
    "        self.reset()\n",
    "    def __call__(self):\n",
    "        x = (\n",
    "            self.x_prev\n",
    "            + self.theta * (self.mean - self.x_prev) * self.dt\n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
    "        )\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "    def reset(self):\n",
    "        if self.x_initial is not None:\n",
    "            self.x_prev = self.x_initial\n",
    "        else:\n",
    "            self.x_prev = np.zeros_like(self.mean)\n",
    "\n",
    "def get_actor(num_states, num_actions=1, upper_bound=1, continuous=True, layer1=400, layer2=300, \n",
    "              init_weights_min=-0.003, init_weights_max=0.003):\n",
    "    last_init = tf.random_uniform_initializer(minval=init_weights_min, maxval=init_weights_max)\n",
    "\n",
    "    inputs = layers.Input(shape=(num_states,))\n",
    "    out = layers.Dense(layer1, activation=\"relu\")(inputs)\n",
    "    out = layers.LayerNormalization(axis=1)(out)\n",
    "    out = layers.Dense(layer2, activation=\"relu\")(out)\n",
    "    out = layers.LayerNormalization(axis=1)(out)\n",
    "    \n",
    "    # Different output activation based on discrete or continous version\n",
    "    if continuous:\n",
    "        outputs = layers.Dense(num_actions, activation=\"tanh\", kernel_initializer=last_init)(out)\n",
    "    else:\n",
    "        outputs = layers.Dense(disc_actions_num, activation=\"softmax\", kernel_initializer=last_init)(out)\n",
    "\n",
    "    # Multiply to fill the whole action space which should be equal around 0\n",
    "    outputs = outputs * upper_bound\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "def get_critic(num_states, num_actions=1, continuous=True, layer1=400, layer2=300):\n",
    "    state_input = layers.Input(shape=(num_states,))\n",
    "    state_out = layers.Dense(64, activation=\"relu\")(state_input)\n",
    "\n",
    "    if continuous:\n",
    "        action_input = layers.Input(shape=(num_actions,))\n",
    "    else:\n",
    "        action_input = layers.Input(shape=(disc_actions_num,))\n",
    "    action_out = layers.Dense(64, activation=\"relu\")(action_input)\n",
    "\n",
    "    concat = layers.Concatenate()([state_out, action_out])\n",
    "\n",
    "    out = layers.Dense(layer1, activation=\"relu\")(concat)\n",
    "    out = layers.LayerNormalization(axis=1)(out)\n",
    "    out = layers.Dense(layer2, activation=\"relu\")(out)\n",
    "    out = layers.LayerNormalization(axis=1)(out)\n",
    "    outputs = layers.Dense(num_actions)(out)\n",
    "\n",
    "    return tf.keras.Model([state_input, action_input], outputs)\n",
    "\n",
    "# This updates the weights in a slow manner which keeps stability\n",
    "@tf.function\n",
    "def update_target(target_weights, weights, tau):\n",
    "    for (a, b) in zip(target_weights, weights):\n",
    "        a.assign(b * tau + a * (1 - tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d09a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, num_states, num_actions=1, lower_bound=-1, upper_bound=1, continuous=True,\n",
    "            buffer_capacity=50000, batch_size=64, std_dev=0.2, critic_lr=0.002,\n",
    "            actor_lr=0.001, gamma=0.99, tau=0.005, epsilon=0.2, adam_critic_eps=1e-07,\n",
    "            adam_actor_eps=1e-07, actor_amsgrad=False, critic_amsgrad=False, actor_layer_1=256, \n",
    "            actor_layer_2=256, critic_layer_1=256, critic_layer_2=256):\n",
    "        \n",
    "        self.continuous = continuous\n",
    "        \n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # For methods\n",
    "        self.lower_bound = lower_bound\n",
    "        self.upper_bound = upper_bound\n",
    "\n",
    "        # This is used to make sure we only sample from used buffer space\n",
    "        self.buffer_counter = 0\n",
    "\n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        if self.continuous:\n",
    "            self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
    "        else:\n",
    "            self.action_buffer = np.zeros((self.buffer_capacity, disc_actions_num))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        \n",
    "        # Also keep track if it is in terminal state (legs on ground)\n",
    "        self.done_buffer = np.zeros((self.buffer_capacity, 1)).astype(np.float32)\n",
    "        \n",
    "        self.std_dev = std_dev\n",
    "        self.critic_lr = critic_lr\n",
    "        self.actor_lr = actor_lr\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        \n",
    "        # Epsilon in epsilon-greedy\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        self.actor_model = get_actor(\n",
    "            num_states, num_actions, upper_bound, continuous=continuous, layer1=actor_layer_1, layer2=actor_layer_2\n",
    "        )\n",
    "        self.critic_model = get_critic(\n",
    "            num_states, num_actions, continuous=continuous, layer1=critic_layer_1, layer2=critic_layer_2\n",
    "        )\n",
    "        \n",
    "        self.target_actor = get_actor(\n",
    "            num_states, num_actions, upper_bound, continuous=continuous, layer1=actor_layer_1, layer2=actor_layer_2\n",
    "        )\n",
    "        self.target_critic = get_critic(\n",
    "            num_states, num_actions, continuous=continuous, layer1=critic_layer_1, layer2=critic_layer_2\n",
    "        )\n",
    "        \n",
    "        self.actor_optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=actor_lr, beta_1=0.9, beta_2=0.999, epsilon=adam_actor_eps, amsgrad=actor_amsgrad,\n",
    "        )\n",
    "        self.critic_optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=critic_lr, beta_1=0.9, beta_2=0.999, epsilon=adam_critic_eps, amsgrad=critic_amsgrad,\n",
    "        )\n",
    "        # Making the weights equal initially\n",
    "        self.target_actor.set_weights(self.actor_model.get_weights())\n",
    "        self.target_critic.set_weights(self.critic_model.get_weights())\n",
    "        \n",
    "        self.ou_noise = OUActionNoise(mean=np.zeros(1), std_deviation=float(std_dev) * np.ones(1))\n",
    "    \n",
    "    # Makes a record of the outputted (s,a,r,s') obervation tuple + terminal state\n",
    "    def record(self, obs_tuple):\n",
    "        # Reuse the same buffer replacing old entries\n",
    "        index = self.buffer_counter % self.buffer_capacity\n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "        self.done_buffer[index] = obs_tuple[4]\n",
    "\n",
    "        self.buffer_counter += 1\n",
    "    \n",
    "    # Calculation of loss and gradients\n",
    "    @tf.function\n",
    "    def update(self, state_batch, action_batch, reward_batch, next_state_batch, done_batch):\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = self.target_actor(next_state_batch, training=True)\n",
    "            # Add done_batch to y function for terminal state\n",
    "            y = reward_batch + done_batch * self.gamma * self.target_critic(\n",
    "                [next_state_batch, target_actions], training=True\n",
    "            )\n",
    "            critic_value = self.critic_model([state_batch, action_batch], training=True)\n",
    "            l = losses.MeanAbsoluteError()\n",
    "            critic_loss = l(y, critic_value)\n",
    "\n",
    "        critic_grad = tape.gradient(critic_loss, self.critic_model.trainable_variables)\n",
    "        \n",
    "        # Gradient clipping to avoid exploding and vanishing gradients\n",
    "        critic_gvd = zip(critic_grad, self.critic_model.trainable_variables)\n",
    "        critic_capped_grad = [(tf.clip_by_value(grad, clip_value_min=-1, clip_value_max=1), var) for grad, var in critic_gvd]\n",
    "        \n",
    "        self.critic_optimizer.apply_gradients(critic_capped_grad)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions = self.actor_model(state_batch, training=True)\n",
    "            critic_value = self.critic_model([state_batch, actions], training=True)\n",
    "            actor_loss = -tf.math.reduce_mean(critic_value)\n",
    "\n",
    "        actor_grad = tape.gradient(actor_loss, self.actor_model.trainable_variables)\n",
    "        # clip actor too\n",
    "        actor_gvd = zip(actor_grad, self.actor_model.trainable_variables)\n",
    "        actor_capped_grad = [(tf.clip_by_value(grad, clip_value_min=-1, clip_value_max=1), var) for grad, var in actor_gvd]\n",
    "        \n",
    "        self.actor_optimizer.apply_gradients(actor_capped_grad)\n",
    "\n",
    "    def learn(self):\n",
    "        # Sample only valid data\n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        # Randomly sample indices\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "        done_batch = tf.convert_to_tensor(self.done_buffer[batch_indices])\n",
    "\n",
    "        self.update(state_batch, action_batch, reward_batch, next_state_batch, done_batch)\n",
    "        \n",
    "    def policy(self, state, noise_object=0, use_noise=True, noise_mult=1):\n",
    "        # Default noise_object to 0 for when it is not needed\n",
    "        # For doing actions without added noise\n",
    "        if not use_noise:    \n",
    "            if self.continuous:\n",
    "                sampled_actions = tf.squeeze(self.actor_model(state)).numpy()\n",
    "                legal_action = np.clip(sampled_actions, self.lower_bound, self.upper_bound)\n",
    "                return [np.squeeze(legal_action)][0]\n",
    "            else:\n",
    "                return self.actor_model(state)\n",
    "        else:\n",
    "            if self.continuous:\n",
    "                sampled_actions = tf.squeeze(self.actor_model(state))\n",
    "                \n",
    "                noise = noise_object()\n",
    "                # Adding noise to action\n",
    "                sampled_actions = sampled_actions.numpy() + noise * noise_mult\n",
    "\n",
    "                # We make sure action is within bounds\n",
    "                legal_action = np.clip(sampled_actions, self.lower_bound, self.upper_bound)\n",
    "                return [np.squeeze(legal_action)][0]\n",
    "            else:\n",
    "                if (rng.random() < self.epsilon):\n",
    "                    #random move\n",
    "                    action = np.zeros(disc_actions_num)\n",
    "                    action[np.random.randint(0, disc_actions_num, 1)[0]] = 1\n",
    "                    return action\n",
    "                else:\n",
    "                    return self.actor_model(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3f522c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed(x, episode):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42f9f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(total_trials=1, total_episodes=100, \n",
    "            buffer_capacity=50000, batch_size=64, std_dev=0.3, critic_lr=0.003, render=False,\n",
    "            actor_lr=0.002, gamma=0.99, tau=0.005, noise_mult=1, save_weights=True, \n",
    "            directory='Weights/', actor_name='actor', critic_name='critic',\n",
    "            gamma_func=fixed, tau_func=fixed, critic_lr_func=fixed, actor_lr_func=fixed,\n",
    "            noise_mult_func=fixed, std_dev_func=fixed, mean_number=20, output=True,\n",
    "            return_rewards=False, total_time=True, use_guide=False, solved=200,\n",
    "            continuous=True, environment='LunarLander-v2', seed=1453, start_steps=0,\n",
    "            gravity=-10.0, enable_wind=False, wind_power=15.0, turbulence_power=1.5,\n",
    "            epsilon=0.2, epsilon_func=fixed, adam_critic_eps=1e-07, adam_actor_eps=1e-07,\n",
    "            actor_amsgrad=False, critic_amsgrad=False, actor_layer_1=256, actor_layer_2=256,\n",
    "            critic_layer_1=256, critic_layer_2=256):\n",
    "    tot_time = time.time()\n",
    "    \n",
    "    if environment == 'LunarLander-v2':\n",
    "        env = gym.make(\n",
    "            \"LunarLander-v2\",\n",
    "            continuous=continuous,\n",
    "            gravity=gravity,\n",
    "            enable_wind=enable_wind,\n",
    "            wind_power=wind_power,\n",
    "            turbulence_power=turbulence_power\n",
    "        )\n",
    "    else:\n",
    "        env = gym.make(environment)\n",
    "        \n",
    "    # Apply the seed\n",
    "    _ = env.reset(seed=seed)\n",
    "        \n",
    "    # This is needed to get the input size for the NN\n",
    "    num_states = env.observation_space.low.shape[0]\n",
    "    if continuous:\n",
    "        num_actions = env.action_space.shape[0]\n",
    "    else:\n",
    "        num_actions = 1\n",
    "\n",
    "    # Normalize action space according to https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
    "    action_space = spaces.Box(low=-1, high=1, shape=(num_actions,), dtype='float32')\n",
    "\n",
    "    # This is needed to clip the actions within the legal boundaries\n",
    "    upper_bound = action_space.high[0]\n",
    "    lower_bound = action_space.low[0]\n",
    "    \n",
    "    ep_reward_list = []\n",
    "    # To store average reward history of last few episodes\n",
    "    avg_reward_list = []\n",
    "    # To separate assisted reward structures from the \"true\"\n",
    "    true_reward_list = []\n",
    "    true_avg_reward_list = []\n",
    "    \n",
    "    for trial in range(total_trials):\n",
    "        # Stepcount used for random start\n",
    "        step = 0\n",
    "\n",
    "        # Add sublists for each trial\n",
    "        avg_reward_list.append([])\n",
    "        ep_reward_list.append([])\n",
    "        true_reward_list.append([])\n",
    "        true_avg_reward_list.append([])\n",
    "        \n",
    "        agent = Agent(num_states=num_states, num_actions=num_actions, lower_bound=lower_bound, \n",
    "                upper_bound=upper_bound, continuous=continuous, buffer_capacity=buffer_capacity, \n",
    "                batch_size=batch_size, std_dev=std_dev, critic_lr=critic_lr, actor_lr=actor_lr, \n",
    "                gamma=gamma, tau=tau, epsilon=epsilon, adam_critic_eps=adam_critic_eps, adam_actor_eps=adam_actor_eps,\n",
    "                actor_amsgrad=actor_amsgrad, critic_amsgrad=critic_amsgrad, actor_layer_1=actor_layer_1, \n",
    "                actor_layer_2=actor_layer_2, critic_layer_1=critic_layer_1, critic_layer_2=critic_layer_2)\n",
    "\n",
    "        for ep in range(total_episodes):\n",
    "            # functions for different parameters\n",
    "            agent.gamma = gamma_func(gamma, ep)\n",
    "            agent.tau = tau_func(tau, ep)\n",
    "            agent.critic_lr = critic_lr_func(critic_lr, ep)\n",
    "            agent.actor_lr = actor_lr_func(actor_lr, ep)\n",
    "            agent.noise_mult = noise_mult_func(noise_mult, ep)\n",
    "            agent.std_dev = std_dev_func(std_dev, ep)\n",
    "            agent.epsilon = epsilon_func(epsilon, ep)\n",
    "            \n",
    "            # Used for time benchmarking\n",
    "            before = time.time()\n",
    "\n",
    "            prev_state = env.reset()\n",
    "            episodic_reward = 0\n",
    "            true_reward = 0\n",
    "\n",
    "            while True:\n",
    "                if render:\n",
    "                    env.render()\n",
    "                \n",
    "                tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
    "\n",
    "                if step >= start_steps:\n",
    "                    action = agent.policy(state=tf_prev_state, noise_object=agent.ou_noise, noise_mult=noise_mult)\n",
    "                else:\n",
    "                    action = env.action_space.sample()\n",
    "                \n",
    "                step += 1\n",
    "                \n",
    "                # Recieve state and reward from environment.\n",
    "                if continuous:\n",
    "                    state, reward, done, info = env.step(action)\n",
    "                else:\n",
    "                    state, reward, done, info = env.step(np.argmax(action))\n",
    "                \n",
    "                # Add this before eventual reward modification\n",
    "                true_reward += reward\n",
    "                \n",
    "                # Reward modification\n",
    "                if use_guide:\n",
    "                    reward -= abs(state[2]/2) + abs(state[3]) + (abs(state[0])) + (abs(state[1])/2)\n",
    "\n",
    "                # Add terminal state\n",
    "                terminal_state = int(not done)\n",
    "                agent.record((prev_state, action, reward, state, terminal_state))\n",
    "                episodic_reward += reward\n",
    "\n",
    "                agent.learn()\n",
    "                update_target(agent.target_actor.variables, agent.actor_model.variables, agent.tau)\n",
    "                update_target(agent.target_critic.variables, agent.critic_model.variables, agent.tau)\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "                prev_state = state\n",
    "\n",
    "            ep_reward_list[trial].append(episodic_reward)\n",
    "            true_reward_list[trial].append(true_reward)\n",
    "            \n",
    "            avg_reward = np.mean(ep_reward_list[trial][-mean_number:])\n",
    "            avg_reward_list[trial].append(avg_reward)\n",
    "            true_avg_reward = np.mean(true_reward_list[trial][-mean_number:])\n",
    "            true_avg_reward_list[trial].append(true_avg_reward)\n",
    "            \n",
    "            if output:\n",
    "                print(\"Ep {} * AvgReward {:.2f} * true AvgReward {:.2f} * Reward {:.2f} * True Reward {:.2f} * time {:.2f} * step {}\"\n",
    "                  .format(ep, avg_reward, true_avg_reward, episodic_reward, \n",
    "                          true_reward, (time.time() - before), step))\n",
    "            \n",
    "            # Stop if avg is above 'solved'\n",
    "            if true_avg_reward >= solved:\n",
    "                break\n",
    "\n",
    "        # Save weights\n",
    "        now = datetime.datetime.now()\n",
    "        timestamp = \"{}.{}.{}.{}.{}.{}\".format(now.year, now.month, now.day, now.hour, now.minute, now.second)\n",
    "        save_name = \"{}_{}_{}\".format(\n",
    "            environment, continuous, \n",
    "            timestamp,\n",
    "        )\n",
    "        if save_weights:\n",
    "            try:\n",
    "                agent.actor_model.save_weights(directory + actor_name + '-trial' + str(trial) + '_' + save_name + '.h5')\n",
    "            except:\n",
    "                print('actor save fail')\n",
    "            try:\n",
    "                agent.critic_model.save_weights(directory + critic_name + '-trial' + str(trial) + '_' + save_name + '.h5')\n",
    "            except:\n",
    "                print('critic save fail')\n",
    "    \n",
    "    # Plotting graph\n",
    "    for idx, p in enumerate(true_avg_reward_list):\n",
    "        plt.plot(p, label=str(idx))\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"True Avg. Epsiodic Reward (\" + str(mean_number) + \")\")\n",
    "    plt.legend()\n",
    "    try:\n",
    "        plt.savefig('Graphs/' + save_name + '.png')\n",
    "    except:\n",
    "        print('save fig fail')\n",
    "    plt.show()\n",
    "    \n",
    "    print('total time:', time.time() - tot_time, 's')\n",
    "    \n",
    "    # Return to be able to make graphs etc. later, or use the data for other stuff\n",
    "    if return_rewards:\n",
    "        return true_reward_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a57bcf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(total_episodes=10, actor_weights='Weights/actor-trial0.h5', render=False,\n",
    "        environment=\"LunarLander-v2\", continuous=True, gravity=-10.0, enable_wind=False,\n",
    "        wind_power=15.0, turbulence_power=1.5, seed=1453):\n",
    "    rewards = []\n",
    "    \n",
    "    env = gym.make(\n",
    "        environment,\n",
    "        continuous=continuous,\n",
    "        gravity=gravity,\n",
    "        enable_wind=enable_wind,\n",
    "        wind_power=wind_power,\n",
    "        turbulence_power=turbulence_power\n",
    "    )\n",
    "    \n",
    "    # This is needed to get the input size for the NN\n",
    "    num_states = env.observation_space.low.shape[0]\n",
    "    if continuous:\n",
    "        num_actions = env.action_space.shape[0]\n",
    "    else:\n",
    "        num_actions = 1\n",
    "\n",
    "    # Normalize action space according to https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
    "    action_space = spaces.Box(low=-1, high=1, shape=(num_actions,), dtype='float32')\n",
    "\n",
    "    # This is needed to clip the actions within the legal boundaries\n",
    "    upper_bound = action_space.high[0]\n",
    "    lower_bound = action_space.low[0]\n",
    "    \n",
    "    # Apply the seed\n",
    "    _ = env.reset(seed=seed)\n",
    "    \n",
    "    for ep in range(total_episodes):\n",
    "        ep_reward = 0\n",
    "        \n",
    "        # Used for time benchmarking\n",
    "        before = time.time()\n",
    "        \n",
    "        prev_state = env.reset()\n",
    "        agent = Agent(num_states=num_states, num_actions=num_actions, lower_bound=lower_bound, \n",
    "                upper_bound=upper_bound, continuous=continuous, buffer_capacity=0, batch_size=0, \n",
    "                std_dev=0, critic_lr=0, actor_lr=0, gamma=0, tau=0, epsilon=0)\n",
    "        agent.actor_model.load_weights(actor_weights)\n",
    "        \n",
    "        while True:\n",
    "            if render:\n",
    "                env.render()\n",
    "\n",
    "            tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
    "\n",
    "            action = agent.policy(state=tf_prev_state, use_noise=False)\n",
    "\n",
    "            if continuous:\n",
    "                state, reward, done, info = env.step(action)\n",
    "            else:\n",
    "                state, reward, done, info = env.step(np.argmax(action))\n",
    "            \n",
    "            ep_reward += reward\n",
    "\n",
    "            if done:\n",
    "                print(str(time.time() - before) + 's')\n",
    "                rewards.append(ep_reward)\n",
    "                break\n",
    "\n",
    "            prev_state = state\n",
    "            \n",
    "    plt.plot(rewards)\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"True reward\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a90fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random(total_episodes=10, render=False, environment=\"LunarLander-v2\", continuous=True,\n",
    "        gravity=-10.0, enable_wind=False, wind_power=15.0, turbulence_power=1.5, seed=1453):\n",
    "    \n",
    "    rewards = []\n",
    "    \n",
    "    env = gym.make(\n",
    "        environment,\n",
    "        continuous=continuous,\n",
    "        gravity=gravity,\n",
    "        enable_wind=enable_wind,\n",
    "        wind_power=wind_power,\n",
    "        turbulence_power=turbulence_power,\n",
    "    )\n",
    "    \n",
    "    # Apply the seed\n",
    "    _ = env.reset(seed=seed)\n",
    "    \n",
    "    for ep in range(total_episodes):\n",
    "        ep_reward = 0\n",
    "        \n",
    "        before = time.time()\n",
    "        \n",
    "        prev_state = env.reset()\n",
    "        \n",
    "        while True:\n",
    "            if render:\n",
    "                env.render()\n",
    "            action = env.action_space.sample()\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            ep_reward += reward\n",
    "\n",
    "            if done:\n",
    "                print(str(time.time() - before) + 's')\n",
    "                rewards.append(ep_reward)\n",
    "                break\n",
    "\n",
    "            prev_state = state\n",
    "            \n",
    "    plt.plot(rewards)\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"True reward\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83b8ba",
   "metadata": {},
   "source": [
    "---\n",
    "# Runs and tests\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9580415b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 0 * AvgReward -386.01 * true AvgReward -386.01 * Reward -386.01 * True Reward -386.01 * time 2.20 * step 119\n",
      "Ep 1 * AvgReward -213.52 * true AvgReward -213.52 * Reward -41.02 * True Reward -41.02 * time 0.70 * step 204\n",
      "Ep 2 * AvgReward -259.11 * true AvgReward -259.11 * Reward -350.28 * True Reward -350.28 * time 0.99 * step 324\n",
      "Ep 3 * AvgReward -241.78 * true AvgReward -241.78 * Reward -189.82 * True Reward -189.82 * time 1.29 * step 480\n",
      "Ep 4 * AvgReward -198.69 * true AvgReward -198.69 * Reward -26.33 * True Reward -26.33 * time 0.70 * step 565\n",
      "Ep 5 * AvgReward -171.30 * true AvgReward -171.30 * Reward -34.36 * True Reward -34.36 * time 1.49 * step 744\n",
      "Ep 6 * AvgReward -165.62 * true AvgReward -165.62 * Reward -131.53 * True Reward -131.53 * time 1.03 * step 868\n",
      "Ep 7 * AvgReward -178.63 * true AvgReward -178.63 * Reward -269.71 * True Reward -269.71 * time 0.84 * step 970\n",
      "Ep 8 * AvgReward -192.93 * true AvgReward -192.93 * Reward -307.26 * True Reward -307.26 * time 0.99 * step 1089\n",
      "Ep 9 * AvgReward -187.87 * true AvgReward -187.87 * Reward -142.40 * True Reward -142.40 * time 0.92 * step 1200\n",
      "Ep 10 * AvgReward -192.84 * true AvgReward -192.84 * Reward -242.49 * True Reward -242.49 * time 0.88 * step 1306\n",
      "Ep 11 * AvgReward -211.67 * true AvgReward -211.67 * Reward -418.80 * True Reward -418.80 * time 0.80 * step 1402\n",
      "Ep 12 * AvgReward -201.88 * true AvgReward -201.88 * Reward -84.38 * True Reward -84.38 * time 0.59 * step 1474\n",
      "Ep 13 * AvgReward -214.47 * true AvgReward -214.47 * Reward -378.21 * True Reward -378.21 * time 0.95 * step 1589\n",
      "Ep 14 * AvgReward -203.16 * true AvgReward -203.16 * Reward -44.86 * True Reward -44.86 * time 0.54 * step 1655\n",
      "Ep 15 * AvgReward -210.93 * true AvgReward -210.93 * Reward -327.42 * True Reward -327.42 * time 0.78 * step 1749\n",
      "Ep 16 * AvgReward -218.30 * true AvgReward -218.30 * Reward -336.29 * True Reward -336.29 * time 0.79 * step 1846\n",
      "Ep 17 * AvgReward -209.32 * true AvgReward -209.32 * Reward -56.65 * True Reward -56.65 * time 1.54 * step 2031\n",
      "Ep 18 * AvgReward -217.34 * true AvgReward -217.34 * Reward -361.60 * True Reward -361.60 * time 0.76 * step 2123\n",
      "Ep 19 * AvgReward -209.51 * true AvgReward -209.51 * Reward -60.80 * True Reward -60.80 * time 1.00 * step 2245\n",
      "Ep 20 * AvgReward -203.55 * true AvgReward -203.55 * Reward -266.70 * True Reward -266.70 * time 0.76 * step 2338\n",
      "Ep 21 * AvgReward -216.30 * true AvgReward -216.30 * Reward -296.07 * True Reward -296.07 * time 1.04 * step 2465\n",
      "Ep 22 * AvgReward -201.56 * true AvgReward -201.56 * Reward -55.56 * True Reward -55.56 * time 0.98 * step 2584\n",
      "Ep 23 * AvgReward -208.13 * true AvgReward -208.13 * Reward -321.15 * True Reward -321.15 * time 0.72 * step 2671\n",
      "Ep 24 * AvgReward -209.26 * true AvgReward -209.26 * Reward -48.91 * True Reward -48.91 * time 0.53 * step 2736\n",
      "Ep 25 * AvgReward -223.70 * true AvgReward -223.70 * Reward -323.18 * True Reward -323.18 * time 0.75 * step 2827\n",
      "Ep 26 * AvgReward -229.74 * true AvgReward -229.74 * Reward -252.38 * True Reward -252.38 * time 0.90 * step 2935\n",
      "Ep 27 * AvgReward -217.69 * true AvgReward -217.69 * Reward -28.65 * True Reward -28.65 * time 0.65 * step 3014\n",
      "Ep 28 * AvgReward -207.56 * true AvgReward -207.56 * Reward -104.72 * True Reward -104.72 * time 0.63 * step 3090\n",
      "Ep 29 * AvgReward -204.88 * true AvgReward -204.88 * Reward -88.70 * True Reward -88.70 * time 0.70 * step 3174\n",
      "Ep 30 * AvgReward -211.69 * true AvgReward -211.69 * Reward -378.78 * True Reward -378.78 * time 0.75 * step 3265\n",
      "Ep 31 * AvgReward -198.02 * true AvgReward -198.02 * Reward -145.35 * True Reward -145.35 * time 0.88 * step 3372\n",
      "Ep 32 * AvgReward -198.87 * true AvgReward -198.87 * Reward -101.48 * True Reward -101.48 * time 1.10 * step 3505\n",
      "Ep 33 * AvgReward -205.79 * true AvgReward -205.79 * Reward -516.49 * True Reward -516.49 * time 1.04 * step 3632\n",
      "Ep 34 * AvgReward -215.25 * true AvgReward -215.25 * Reward -234.15 * True Reward -234.15 * time 0.82 * step 3731\n",
      "Ep 35 * AvgReward -215.85 * true AvgReward -215.85 * Reward -339.31 * True Reward -339.31 * time 0.94 * step 3845\n",
      "Ep 36 * AvgReward -215.74 * true AvgReward -215.74 * Reward -334.13 * True Reward -334.13 * time 1.21 * step 3992\n",
      "Ep 37 * AvgReward -222.33 * true AvgReward -222.33 * Reward -188.42 * True Reward -188.42 * time 0.81 * step 4090\n",
      "Ep 38 * AvgReward -210.12 * true AvgReward -210.12 * Reward -117.40 * True Reward -117.40 * time 0.57 * step 4160\n",
      "Ep 39 * AvgReward -219.33 * true AvgReward -219.33 * Reward -245.10 * True Reward -245.10 * time 0.78 * step 4254\n",
      "Ep 40 * AvgReward -215.99 * true AvgReward -215.99 * Reward -199.97 * True Reward -199.97 * time 0.84 * step 4355\n",
      "Ep 41 * AvgReward -219.59 * true AvgReward -219.59 * Reward -368.02 * True Reward -368.02 * time 0.81 * step 4453\n",
      "Ep 42 * AvgReward -225.53 * true AvgReward -225.53 * Reward -174.27 * True Reward -174.27 * time 0.77 * step 4546\n",
      "Ep 43 * AvgReward -224.13 * true AvgReward -224.13 * Reward -293.20 * True Reward -293.20 * time 0.75 * step 4637\n",
      "Ep 44 * AvgReward -223.50 * true AvgReward -223.50 * Reward -36.36 * True Reward -36.36 * time 0.73 * step 4725\n",
      "Ep 45 * AvgReward -209.17 * true AvgReward -209.17 * Reward -36.54 * True Reward -36.54 * time 0.78 * step 4819\n",
      "Ep 46 * AvgReward -214.67 * true AvgReward -214.67 * Reward -362.37 * True Reward -362.37 * time 0.94 * step 4933\n",
      "Ep 47 * AvgReward -216.58 * true AvgReward -216.58 * Reward -66.77 * True Reward -66.77 * time 0.88 * step 5040\n",
      "Ep 48 * AvgReward -233.23 * true AvgReward -233.23 * Reward -437.75 * True Reward -437.75 * time 0.71 * step 5127\n",
      "Ep 49 * AvgReward -240.44 * true AvgReward -240.44 * Reward -233.04 * True Reward -233.04 * time 0.98 * step 5245\n",
      "Ep 50 * AvgReward -226.38 * true AvgReward -226.38 * Reward -97.50 * True Reward -97.50 * time 1.72 * step 5451\n",
      "Ep 51 * AvgReward -236.77 * true AvgReward -236.77 * Reward -353.08 * True Reward -353.08 * time 0.74 * step 5541\n",
      "Ep 52 * AvgReward -236.98 * true AvgReward -236.98 * Reward -105.75 * True Reward -105.75 * time 0.67 * step 5623\n",
      "Ep 53 * AvgReward -213.65 * true AvgReward -213.65 * Reward -49.88 * True Reward -49.88 * time 0.72 * step 5710\n",
      "Ep 54 * AvgReward -221.02 * true AvgReward -221.02 * Reward -381.53 * True Reward -381.53 * time 1.11 * step 5843\n",
      "Ep 55 * AvgReward -206.82 * true AvgReward -206.82 * Reward -55.29 * True Reward -55.29 * time 0.66 * step 5922\n",
      "Ep 56 * AvgReward -198.27 * true AvgReward -198.27 * Reward -163.16 * True Reward -163.16 * time 0.72 * step 6009\n",
      "Ep 57 * AvgReward -192.59 * true AvgReward -192.59 * Reward -74.90 * True Reward -74.90 * time 0.80 * step 6105\n",
      "Ep 58 * AvgReward -189.80 * true AvgReward -189.80 * Reward -61.47 * True Reward -61.47 * time 0.82 * step 6204\n",
      "Ep 59 * AvgReward -188.34 * true AvgReward -188.34 * Reward -215.95 * True Reward -215.95 * time 0.73 * step 6292\n",
      "Ep 60 * AvgReward -182.61 * true AvgReward -182.61 * Reward -85.29 * True Reward -85.29 * time 0.62 * step 6367\n",
      "Ep 61 * AvgReward -165.30 * true AvgReward -165.30 * Reward -21.85 * True Reward -21.85 * time 0.88 * step 6473\n",
      "Ep 62 * AvgReward -176.44 * true AvgReward -176.44 * Reward -397.07 * True Reward -397.07 * time 0.76 * step 6564\n",
      "Ep 63 * AvgReward -165.22 * true AvgReward -165.22 * Reward -68.77 * True Reward -68.77 * time 1.03 * step 6689\n",
      "Ep 64 * AvgReward -170.00 * true AvgReward -170.00 * Reward -132.06 * True Reward -132.06 * time 0.66 * step 6769\n",
      "Ep 65 * AvgReward -169.86 * true AvgReward -169.86 * Reward -33.78 * True Reward -33.78 * time 0.60 * step 6842\n",
      "Ep 66 * AvgReward -168.19 * true AvgReward -168.19 * Reward -328.81 * True Reward -328.81 * time 0.78 * step 6936\n",
      "Ep 67 * AvgReward -168.86 * true AvgReward -168.86 * Reward -80.33 * True Reward -80.33 * time 1.16 * step 7076\n",
      "Ep 68 * AvgReward -153.40 * true AvgReward -153.40 * Reward -128.39 * True Reward -128.39 * time 0.74 * step 7166\n",
      "Ep 69 * AvgReward -154.35 * true AvgReward -154.35 * Reward -252.17 * True Reward -252.17 * time 1.08 * step 7297\n",
      "Ep 70 * AvgReward -164.10 * true AvgReward -164.10 * Reward -292.38 * True Reward -292.38 * time 0.80 * step 7394\n",
      "Ep 71 * AvgReward -154.19 * true AvgReward -154.19 * Reward -155.03 * True Reward -155.03 * time 0.83 * step 7495\n",
      "Ep 72 * AvgReward -173.23 * true AvgReward -173.23 * Reward -486.50 * True Reward -486.50 * time 0.94 * step 7607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 73 * AvgReward -180.94 * true AvgReward -180.94 * Reward -203.97 * True Reward -203.97 * time 1.25 * step 7756\n",
      "Ep 74 * AvgReward -166.48 * true AvgReward -166.48 * Reward -92.39 * True Reward -92.39 * time 0.57 * step 7825\n",
      "Ep 75 * AvgReward -169.33 * true AvgReward -169.33 * Reward -112.40 * True Reward -112.40 * time 0.70 * step 7909\n",
      "Ep 76 * AvgReward -165.35 * true AvgReward -165.35 * Reward -83.52 * True Reward -83.52 * time 0.59 * step 7981\n",
      "Ep 77 * AvgReward -183.49 * true AvgReward -183.49 * Reward -437.76 * True Reward -437.76 * time 1.51 * step 8162\n",
      "Ep 78 * AvgReward -185.51 * true AvgReward -185.51 * Reward -101.85 * True Reward -101.85 * time 0.66 * step 8243\n",
      "Ep 79 * AvgReward -185.00 * true AvgReward -185.00 * Reward -205.70 * True Reward -205.70 * time 0.94 * step 8358\n",
      "Ep 80 * AvgReward -186.04 * true AvgReward -186.04 * Reward -106.05 * True Reward -106.05 * time 0.83 * step 8460\n",
      "Ep 81 * AvgReward -193.85 * true AvgReward -193.85 * Reward -177.99 * True Reward -177.99 * time 0.93 * step 8573\n",
      "Ep 82 * AvgReward -183.84 * true AvgReward -183.84 * Reward -196.90 * True Reward -196.90 * time 0.85 * step 8677\n",
      "Ep 83 * AvgReward -187.26 * true AvgReward -187.26 * Reward -137.15 * True Reward -137.15 * time 1.17 * step 8819\n",
      "Ep 84 * AvgReward -198.58 * true AvgReward -198.58 * Reward -358.45 * True Reward -358.45 * time 0.75 * step 8909\n",
      "Ep 85 * AvgReward -198.77 * true AvgReward -198.77 * Reward -37.57 * True Reward -37.57 * time 0.59 * step 8980\n",
      "Ep 86 * AvgReward -197.09 * true AvgReward -197.09 * Reward -295.40 * True Reward -295.40 * time 0.70 * step 9065\n",
      "Ep 87 * AvgReward -204.10 * true AvgReward -204.10 * Reward -220.41 * True Reward -220.41 * time 0.86 * step 9168\n",
      "Ep 88 * AvgReward -204.68 * true AvgReward -204.68 * Reward -140.10 * True Reward -140.10 * time 1.01 * step 9289\n",
      "Ep 89 * AvgReward -209.11 * true AvgReward -209.11 * Reward -340.60 * True Reward -340.60 * time 0.71 * step 9375\n",
      "Ep 90 * AvgReward -197.64 * true AvgReward -197.64 * Reward -63.07 * True Reward -63.07 * time 0.77 * step 9467\n",
      "Ep 91 * AvgReward -204.60 * true AvgReward -204.60 * Reward -294.22 * True Reward -294.22 * time 1.10 * step 9599\n",
      "Ep 92 * AvgReward -208.75 * true AvgReward -208.75 * Reward -569.53 * True Reward -569.53 * time 0.75 * step 9690\n",
      "Ep 93 * AvgReward -201.96 * true AvgReward -201.96 * Reward -68.11 * True Reward -68.11 * time 1.31 * step 9847\n",
      "Ep 94 * AvgReward -216.02 * true AvgReward -216.02 * Reward -373.58 * True Reward -373.58 * time 0.92 * step 9959\n",
      "Ep 95 * AvgReward -212.93 * true AvgReward -212.93 * Reward -50.64 * True Reward -50.64 * time 0.66 * step 10039\n",
      "Ep 96 * AvgReward -235.85 * true AvgReward -235.85 * Reward -542.00 * True Reward -542.00 * time 1.21 * step 10182\n",
      "Ep 97 * AvgReward -214.01 * true AvgReward -214.01 * Reward -0.83 * True Reward -0.83 * time 0.60 * step 10254\n",
      "Ep 98 * AvgReward -213.79 * true AvgReward -213.79 * Reward -97.54 * True Reward -97.54 * time 0.70 * step 10339\n",
      "Ep 99 * AvgReward -207.39 * true AvgReward -207.39 * Reward -77.67 * True Reward -77.67 * time 0.58 * step 10409\n",
      "Ep 100 * AvgReward -218.20 * true AvgReward -218.20 * Reward -322.24 * True Reward -322.24 * time 1.32 * step 10567\n",
      "Ep 101 * AvgReward -225.97 * true AvgReward -225.97 * Reward -333.37 * True Reward -333.37 * time 0.99 * step 10688\n",
      "Ep 102 * AvgReward -219.18 * true AvgReward -219.18 * Reward -61.17 * True Reward -61.17 * time 0.86 * step 10792\n",
      "Ep 103 * AvgReward -230.39 * true AvgReward -230.39 * Reward -361.21 * True Reward -361.21 * time 1.13 * step 10929\n",
      "Ep 104 * AvgReward -221.84 * true AvgReward -221.84 * Reward -187.60 * True Reward -187.60 * time 0.80 * step 11026\n",
      "Ep 105 * AvgReward -231.59 * true AvgReward -231.59 * Reward -232.49 * True Reward -232.49 * time 0.71 * step 11112\n",
      "Ep 106 * AvgReward -227.08 * true AvgReward -227.08 * Reward -205.26 * True Reward -205.26 * time 0.90 * step 11220\n",
      "Ep 107 * AvgReward -219.55 * true AvgReward -219.55 * Reward -69.79 * True Reward -69.79 * time 0.64 * step 11297\n",
      "Ep 108 * AvgReward -218.37 * true AvgReward -218.37 * Reward -116.51 * True Reward -116.51 * time 1.00 * step 11418\n",
      "Ep 109 * AvgReward -218.41 * true AvgReward -218.41 * Reward -341.35 * True Reward -341.35 * time 1.23 * step 11566\n",
      "Ep 110 * AvgReward -227.57 * true AvgReward -227.57 * Reward -246.23 * True Reward -246.23 * time 0.97 * step 11683\n",
      "Ep 111 * AvgReward -214.02 * true AvgReward -214.02 * Reward -23.28 * True Reward -23.28 * time 0.66 * step 11763\n",
      "Ep 112 * AvgReward -190.07 * true AvgReward -190.07 * Reward -90.45 * True Reward -90.45 * time 0.96 * step 11879\n",
      "Ep 113 * AvgReward -191.23 * true AvgReward -191.23 * Reward -91.39 * True Reward -91.39 * time 0.65 * step 11957\n",
      "Ep 114 * AvgReward -177.01 * true AvgReward -177.01 * Reward -89.12 * True Reward -89.12 * time 0.67 * step 12038\n",
      "Ep 115 * AvgReward -176.46 * true AvgReward -176.46 * Reward -39.72 * True Reward -39.72 * time 0.67 * step 12119\n",
      "Ep 116 * AvgReward -164.61 * true AvgReward -164.61 * Reward -305.04 * True Reward -305.04 * time 0.95 * step 12233\n",
      "Ep 117 * AvgReward -184.38 * true AvgReward -184.38 * Reward -396.11 * True Reward -396.11 * time 1.15 * step 12372\n",
      "Ep 118 * AvgReward -182.35 * true AvgReward -182.35 * Reward -57.07 * True Reward -57.07 * time 0.61 * step 12445\n",
      "Ep 119 * AvgReward -192.35 * true AvgReward -192.35 * Reward -277.55 * True Reward -277.55 * time 0.86 * step 12548\n",
      "Ep 120 * AvgReward -182.41 * true AvgReward -182.41 * Reward -123.50 * True Reward -123.50 * time 0.59 * step 12619\n",
      "Ep 121 * AvgReward -187.41 * true AvgReward -187.41 * Reward -433.33 * True Reward -433.33 * time 1.26 * step 12770\n",
      "Ep 122 * AvgReward -195.66 * true AvgReward -195.66 * Reward -226.28 * True Reward -226.28 * time 0.57 * step 12839\n",
      "Ep 123 * AvgReward -196.06 * true AvgReward -196.06 * Reward -369.20 * True Reward -369.20 * time 0.78 * step 12933\n",
      "Ep 124 * AvgReward -210.30 * true AvgReward -210.30 * Reward -472.27 * True Reward -472.27 * time 0.80 * step 13029\n",
      "Ep 125 * AvgReward -204.14 * true AvgReward -204.14 * Reward -109.40 * True Reward -109.40 * time 0.63 * step 13105\n",
      "Ep 126 * AvgReward -195.07 * true AvgReward -195.07 * Reward -23.74 * True Reward -23.74 * time 0.59 * step 13176\n",
      "Ep 127 * AvgReward -194.62 * true AvgReward -194.62 * Reward -60.94 * True Reward -60.94 * time 0.82 * step 13274\n",
      "Ep 128 * AvgReward -198.02 * true AvgReward -198.02 * Reward -184.34 * True Reward -184.34 * time 1.04 * step 13398\n",
      "Ep 129 * AvgReward -189.74 * true AvgReward -189.74 * Reward -175.81 * True Reward -175.81 * time 1.27 * step 13551\n",
      "Ep 130 * AvgReward -192.21 * true AvgReward -192.21 * Reward -295.60 * True Reward -295.60 * time 0.71 * step 13637\n",
      "Ep 131 * AvgReward -198.97 * true AvgReward -198.97 * Reward -158.48 * True Reward -158.48 * time 0.75 * step 13728\n",
      "Ep 132 * AvgReward -199.08 * true AvgReward -199.08 * Reward -92.72 * True Reward -92.72 * time 0.75 * step 13819\n",
      "Ep 133 * AvgReward -205.93 * true AvgReward -205.93 * Reward -228.30 * True Reward -228.30 * time 0.83 * step 13920\n",
      "Ep 134 * AvgReward -217.70 * true AvgReward -217.70 * Reward -324.51 * True Reward -324.51 * time 0.83 * step 14020\n",
      "Ep 135 * AvgReward -219.29 * true AvgReward -219.29 * Reward -71.69 * True Reward -71.69 * time 0.70 * step 14103\n",
      "Ep 136 * AvgReward -212.46 * true AvgReward -212.46 * Reward -168.33 * True Reward -168.33 * time 1.25 * step 14254\n",
      "Ep 137 * AvgReward -206.51 * true AvgReward -206.51 * Reward -277.23 * True Reward -277.23 * time 0.90 * step 14363\n",
      "Ep 138 * AvgReward -230.39 * true AvgReward -230.39 * Reward -534.50 * True Reward -534.50 * time 0.93 * step 14475\n",
      "Ep 139 * AvgReward -228.10 * true AvgReward -228.10 * Reward -231.82 * True Reward -231.82 * time 1.21 * step 14619\n",
      "Ep 140 * AvgReward -234.66 * true AvgReward -234.66 * Reward -254.72 * True Reward -254.72 * time 0.65 * step 14697\n",
      "Ep 141 * AvgReward -231.22 * true AvgReward -231.22 * Reward -364.48 * True Reward -364.48 * time 1.03 * step 14820\n",
      "Ep 142 * AvgReward -229.92 * true AvgReward -229.92 * Reward -200.25 * True Reward -200.25 * time 0.71 * step 14906\n",
      "Ep 143 * AvgReward -214.01 * true AvgReward -214.01 * Reward -50.99 * True Reward -50.99 * time 0.98 * step 15024\n",
      "Ep 144 * AvgReward -201.22 * true AvgReward -201.22 * Reward -216.57 * True Reward -216.57 * time 1.14 * step 15160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 145 * AvgReward -199.38 * true AvgReward -199.38 * Reward -72.58 * True Reward -72.58 * time 0.88 * step 15265\n",
      "Ep 146 * AvgReward -203.82 * true AvgReward -203.82 * Reward -112.59 * True Reward -112.59 * time 0.91 * step 15373\n",
      "Ep 147 * AvgReward -203.24 * true AvgReward -203.24 * Reward -49.39 * True Reward -49.39 * time 0.65 * step 15451\n",
      "Ep 148 * AvgReward -199.62 * true AvgReward -199.62 * Reward -111.80 * True Reward -111.80 * time 1.02 * step 15573\n",
      "Ep 149 * AvgReward -196.52 * true AvgReward -196.52 * Reward -113.90 * True Reward -113.90 * time 1.01 * step 15694\n",
      "Ep 150 * AvgReward -192.04 * true AvgReward -192.04 * Reward -205.99 * True Reward -205.99 * time 1.03 * step 15818\n",
      "Ep 151 * AvgReward -187.17 * true AvgReward -187.17 * Reward -61.14 * True Reward -61.14 * time 0.62 * step 15893\n",
      "Ep 152 * AvgReward -187.26 * true AvgReward -187.26 * Reward -94.51 * True Reward -94.51 * time 0.56 * step 15961\n",
      "Ep 153 * AvgReward -187.77 * true AvgReward -187.77 * Reward -238.33 * True Reward -238.33 * time 0.96 * step 16077\n",
      "Ep 154 * AvgReward -188.32 * true AvgReward -188.32 * Reward -335.54 * True Reward -335.54 * time 0.70 * step 16162\n",
      "Ep 155 * AvgReward -185.85 * true AvgReward -185.85 * Reward -22.34 * True Reward -22.34 * time 0.66 * step 16242\n",
      "Ep 156 * AvgReward -188.12 * true AvgReward -188.12 * Reward -213.72 * True Reward -213.72 * time 1.19 * step 16386\n",
      "Ep 157 * AvgReward -178.56 * true AvgReward -178.56 * Reward -86.11 * True Reward -86.11 * time 0.63 * step 16463\n",
      "Ep 158 * AvgReward -163.37 * true AvgReward -163.37 * Reward -230.53 * True Reward -230.53 * time 0.89 * step 16571\n",
      "Ep 159 * AvgReward -167.67 * true AvgReward -167.67 * Reward -317.98 * True Reward -317.98 * time 0.75 * step 16662\n",
      "Ep 160 * AvgReward -168.81 * true AvgReward -168.81 * Reward -277.48 * True Reward -277.48 * time 0.66 * step 16741\n",
      "Ep 161 * AvgReward -160.81 * true AvgReward -160.81 * Reward -204.44 * True Reward -204.44 * time 1.11 * step 16873\n",
      "Ep 162 * AvgReward -160.18 * true AvgReward -160.18 * Reward -187.63 * True Reward -187.63 * time 1.46 * step 17046\n",
      "Ep 163 * AvgReward -165.75 * true AvgReward -165.75 * Reward -162.40 * True Reward -162.40 * time 1.07 * step 17174\n",
      "Ep 164 * AvgReward -158.31 * true AvgReward -158.31 * Reward -67.70 * True Reward -67.70 * time 0.75 * step 17264\n",
      "Ep 165 * AvgReward -163.94 * true AvgReward -163.94 * Reward -185.18 * True Reward -185.18 * time 0.96 * step 17379\n",
      "Ep 166 * AvgReward -167.64 * true AvgReward -167.64 * Reward -186.75 * True Reward -186.75 * time 1.29 * step 17533\n",
      "Ep 167 * AvgReward -169.43 * true AvgReward -169.43 * Reward -85.14 * True Reward -85.14 * time 0.61 * step 17607\n",
      "Ep 168 * AvgReward -187.33 * true AvgReward -187.33 * Reward -469.70 * True Reward -469.70 * time 0.97 * step 17724\n",
      "Ep 169 * AvgReward -187.22 * true AvgReward -187.22 * Reward -111.84 * True Reward -111.84 * time 0.89 * step 17832\n",
      "Ep 170 * AvgReward -185.74 * true AvgReward -185.74 * Reward -176.30 * True Reward -176.30 * time 0.65 * step 17910\n",
      "Ep 171 * AvgReward -185.83 * true AvgReward -185.83 * Reward -62.97 * True Reward -62.97 * time 0.65 * step 17989\n",
      "Ep 172 * AvgReward -191.42 * true AvgReward -191.42 * Reward -206.28 * True Reward -206.28 * time 0.84 * step 18091\n",
      "Ep 173 * AvgReward -196.81 * true AvgReward -196.81 * Reward -346.24 * True Reward -346.24 * time 0.84 * step 18193\n",
      "Ep 174 * AvgReward -179.74 * true AvgReward -179.74 * Reward 5.86 * True Reward 5.86 * time 0.68 * step 18275\n",
      "Ep 175 * AvgReward -201.46 * true AvgReward -201.46 * Reward -456.75 * True Reward -456.75 * time 0.98 * step 18394\n",
      "Ep 176 * AvgReward -203.89 * true AvgReward -203.89 * Reward -262.19 * True Reward -262.19 * time 0.99 * step 18514\n",
      "Ep 177 * AvgReward -201.88 * true AvgReward -201.88 * Reward -46.00 * True Reward -46.00 * time 0.66 * step 18594\n",
      "Ep 178 * AvgReward -213.31 * true AvgReward -213.31 * Reward -459.03 * True Reward -459.03 * time 0.89 * step 18701\n",
      "Ep 179 * AvgReward -202.01 * true AvgReward -202.01 * Reward -91.95 * True Reward -91.95 * time 0.77 * step 18794\n",
      "Ep 180 * AvgReward -212.73 * true AvgReward -212.73 * Reward -492.04 * True Reward -492.04 * time 0.97 * step 18911\n",
      "Ep 181 * AvgReward -207.69 * true AvgReward -207.69 * Reward -103.56 * True Reward -103.56 * time 1.20 * step 19055\n",
      "Ep 182 * AvgReward -203.64 * true AvgReward -203.64 * Reward -106.68 * True Reward -106.68 * time 1.23 * step 19200\n",
      "Ep 183 * AvgReward -215.36 * true AvgReward -215.36 * Reward -396.82 * True Reward -396.82 * time 1.16 * step 19339\n",
      "Ep 184 * AvgReward -217.27 * true AvgReward -217.27 * Reward -105.92 * True Reward -105.92 * time 0.66 * step 19418\n",
      "Ep 185 * AvgReward -224.58 * true AvgReward -224.58 * Reward -331.23 * True Reward -331.23 * time 1.35 * step 19579\n",
      "Ep 186 * AvgReward -221.86 * true AvgReward -221.86 * Reward -132.34 * True Reward -132.34 * time 0.75 * step 19669\n",
      "Ep 187 * AvgReward -234.79 * true AvgReward -234.79 * Reward -343.86 * True Reward -343.86 * time 0.62 * step 19743\n",
      "Ep 188 * AvgReward -215.84 * true AvgReward -215.84 * Reward -90.65 * True Reward -90.65 * time 1.15 * step 19876\n",
      "Ep 189 * AvgReward -232.57 * true AvgReward -232.57 * Reward -446.38 * True Reward -446.38 * time 1.31 * step 20017\n",
      "Ep 190 * AvgReward -236.58 * true AvgReward -236.58 * Reward -256.59 * True Reward -256.59 * time 8.45 * step 20662\n",
      "Ep 191 * AvgReward -243.25 * true AvgReward -243.25 * Reward -196.28 * True Reward -196.28 * time 2.91 * step 20906\n",
      "Ep 192 * AvgReward -238.40 * true AvgReward -238.40 * Reward -109.27 * True Reward -109.27 * time 0.99 * step 20990\n",
      "Ep 193 * AvgReward -221.58 * true AvgReward -221.58 * Reward -10.01 * True Reward -10.01 * time 0.96 * step 21071\n",
      "Ep 194 * AvgReward -223.31 * true AvgReward -223.31 * Reward -28.54 * True Reward -28.54 * time 1.17 * step 21170\n",
      "Ep 195 * AvgReward -198.94 * true AvgReward -198.94 * Reward 30.58 * True Reward 30.58 * time 12.83 * step 22170\n",
      "Ep 196 * AvgReward -190.98 * true AvgReward -190.98 * Reward -102.94 * True Reward -102.94 * time 2.53 * step 22384\n",
      "Ep 197 * AvgReward -192.46 * true AvgReward -192.46 * Reward -75.77 * True Reward -75.77 * time 13.07 * step 23384\n",
      "Ep 198 * AvgReward -186.29 * true AvgReward -186.29 * Reward -335.58 * True Reward -335.58 * time 1.21 * step 23487\n",
      "Ep 199 * AvgReward -185.07 * true AvgReward -185.07 * Reward -67.43 * True Reward -67.43 * time 1.57 * step 23621\n",
      "Ep 200 * AvgReward -169.27 * true AvgReward -169.27 * Reward -176.20 * True Reward -176.20 * time 1.50 * step 23749\n",
      "Ep 201 * AvgReward -177.32 * true AvgReward -177.32 * Reward -264.42 * True Reward -264.42 * time 11.35 * step 24602\n",
      "Ep 202 * AvgReward -179.67 * true AvgReward -179.67 * Reward -153.82 * True Reward -153.82 * time 2.99 * step 24852\n",
      "Ep 203 * AvgReward -170.88 * true AvgReward -170.88 * Reward -220.88 * True Reward -220.88 * time 3.95 * step 25167\n",
      "Ep 204 * AvgReward -174.67 * true AvgReward -174.67 * Reward -181.86 * True Reward -181.86 * time 5.29 * step 25573\n",
      "Ep 205 * AvgReward -159.36 * true AvgReward -159.36 * Reward -24.95 * True Reward -24.95 * time 1.29 * step 25674\n",
      "Ep 206 * AvgReward -159.84 * true AvgReward -159.84 * Reward -141.88 * True Reward -141.88 * time 0.79 * step 25737\n",
      "Ep 207 * AvgReward -148.53 * true AvgReward -148.53 * Reward -117.77 * True Reward -117.77 * time 0.81 * step 25801\n",
      "Ep 208 * AvgReward -151.65 * true AvgReward -151.65 * Reward -153.00 * True Reward -153.00 * time 1.30 * step 25901\n",
      "Ep 209 * AvgReward -135.36 * true AvgReward -135.36 * Reward -120.68 * True Reward -120.68 * time 0.73 * step 25959\n",
      "Ep 210 * AvgReward -125.53 * true AvgReward -125.53 * Reward -59.83 * True Reward -59.83 * time 1.06 * step 26046\n",
      "Ep 211 * AvgReward -119.87 * true AvgReward -119.87 * Reward -83.18 * True Reward -83.18 * time 2.20 * step 26230\n",
      "Ep 212 * AvgReward -124.04 * true AvgReward -124.04 * Reward -192.60 * True Reward -192.60 * time 4.46 * step 26586\n",
      "Ep 213 * AvgReward -134.51 * true AvgReward -134.51 * Reward -219.36 * True Reward -219.36 * time 4.27 * step 26925\n",
      "Ep 214 * AvgReward -138.48 * true AvgReward -138.48 * Reward -107.98 * True Reward -107.98 * time 3.52 * step 27210\n",
      "Ep 215 * AvgReward -145.67 * true AvgReward -145.67 * Reward -113.35 * True Reward -113.35 * time 3.96 * step 27533\n",
      "Ep 216 * AvgReward -146.02 * true AvgReward -146.02 * Reward -109.94 * True Reward -109.94 * time 3.23 * step 27796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 217 * AvgReward -148.19 * true AvgReward -148.19 * Reward -119.01 * True Reward -119.01 * time 5.04 * step 28202\n",
      "Ep 218 * AvgReward -139.52 * true AvgReward -139.52 * Reward -162.25 * True Reward -162.25 * time 9.30 * step 28922\n",
      "Ep 219 * AvgReward -137.49 * true AvgReward -137.49 * Reward -26.83 * True Reward -26.83 * time 13.09 * step 29922\n",
      "Ep 220 * AvgReward -135.64 * true AvgReward -135.64 * Reward -139.18 * True Reward -139.18 * time 9.85 * step 30694\n",
      "Ep 221 * AvgReward -132.80 * true AvgReward -132.80 * Reward -207.58 * True Reward -207.58 * time 8.20 * step 31329\n",
      "Ep 222 * AvgReward -126.90 * true AvgReward -126.90 * Reward -35.85 * True Reward -35.85 * time 1.05 * step 31416\n",
      "Ep 223 * AvgReward -116.73 * true AvgReward -116.73 * Reward -17.42 * True Reward -17.42 * time 0.85 * step 31487\n",
      "Ep 224 * AvgReward -110.23 * true AvgReward -110.23 * Reward -51.87 * True Reward -51.87 * time 1.19 * step 31586\n",
      "Ep 225 * AvgReward -109.39 * true AvgReward -109.39 * Reward -8.28 * True Reward -8.28 * time 1.20 * step 31685\n",
      "Ep 226 * AvgReward -111.36 * true AvgReward -111.36 * Reward -181.19 * True Reward -181.19 * time 9.50 * step 32438\n",
      "Ep 227 * AvgReward -121.40 * true AvgReward -121.40 * Reward -318.52 * True Reward -318.52 * time 13.01 * step 33436\n",
      "Ep 228 * AvgReward -119.72 * true AvgReward -119.72 * Reward -119.49 * True Reward -119.49 * time 8.47 * step 34101\n",
      "Ep 229 * AvgReward -157.51 * true AvgReward -157.51 * Reward -876.46 * True Reward -876.46 * time 9.01 * step 34802\n",
      "Ep 230 * AvgReward -196.06 * true AvgReward -196.06 * Reward -830.79 * True Reward -830.79 * time 1.22 * step 34905\n",
      "Ep 231 * AvgReward -226.57 * true AvgReward -226.57 * Reward -693.51 * True Reward -693.51 * time 0.81 * step 34974\n",
      "Ep 232 * AvgReward -238.84 * true AvgReward -238.84 * Reward -437.90 * True Reward -437.90 * time 1.48 * step 35099\n",
      "Ep 233 * AvgReward -230.65 * true AvgReward -230.65 * Reward -55.53 * True Reward -55.53 * time 12.91 * step 36099\n",
      "Ep 234 * AvgReward -238.03 * true AvgReward -238.03 * Reward -255.55 * True Reward -255.55 * time 1.79 * step 36252\n",
      "Ep 235 * AvgReward -239.80 * true AvgReward -239.80 * Reward -148.78 * True Reward -148.78 * time 1.16 * step 36350\n",
      "Ep 236 * AvgReward -253.14 * true AvgReward -253.14 * Reward -376.76 * True Reward -376.76 * time 12.07 * step 37283\n",
      "Ep 237 * AvgReward -273.52 * true AvgReward -273.52 * Reward -526.55 * True Reward -526.55 * time 0.92 * step 37360\n",
      "Ep 238 * AvgReward -282.07 * true AvgReward -282.07 * Reward -333.29 * True Reward -333.29 * time 1.56 * step 37492\n",
      "Ep 239 * AvgReward -292.17 * true AvgReward -292.17 * Reward -228.93 * True Reward -228.93 * time 1.13 * step 37589\n",
      "Ep 240 * AvgReward -296.69 * true AvgReward -296.69 * Reward -229.52 * True Reward -229.52 * time 1.19 * step 37688\n",
      "Ep 241 * AvgReward -287.44 * true AvgReward -287.44 * Reward -22.68 * True Reward -22.68 * time 12.98 * step 38688\n",
      "Ep 242 * AvgReward -288.20 * true AvgReward -288.20 * Reward -50.99 * True Reward -50.99 * time 12.71 * step 39688\n",
      "Ep 243 * AvgReward -294.41 * true AvgReward -294.41 * Reward -141.70 * True Reward -141.70 * time 13.63 * step 40688\n",
      "Ep 244 * AvgReward -293.69 * true AvgReward -293.69 * Reward -37.37 * True Reward -37.37 * time 12.64 * step 41688\n",
      "Ep 245 * AvgReward -296.12 * true AvgReward -296.12 * Reward -56.92 * True Reward -56.92 * time 12.97 * step 42688\n",
      "Ep 246 * AvgReward -287.86 * true AvgReward -287.86 * Reward -15.96 * True Reward -15.96 * time 13.23 * step 43688\n",
      "Ep 247 * AvgReward -272.93 * true AvgReward -272.93 * Reward -19.95 * True Reward -19.95 * time 13.31 * step 44688\n",
      "Ep 248 * AvgReward -267.84 * true AvgReward -267.84 * Reward -17.66 * True Reward -17.66 * time 13.41 * step 45688\n",
      "Ep 249 * AvgReward -225.80 * true AvgReward -225.80 * Reward -35.59 * True Reward -35.59 * time 13.49 * step 46688\n",
      "Ep 250 * AvgReward -192.67 * true AvgReward -192.67 * Reward -168.32 * True Reward -168.32 * time 4.16 * step 47030\n",
      "Ep 251 * AvgReward -161.42 * true AvgReward -161.42 * Reward -68.36 * True Reward -68.36 * time 13.54 * step 48030\n",
      "Ep 252 * AvgReward -140.20 * true AvgReward -140.20 * Reward -13.60 * True Reward -13.60 * time 13.16 * step 49030\n",
      "Ep 253 * AvgReward -136.06 * true AvgReward -136.06 * Reward 27.27 * True Reward 27.27 * time 14.13 * step 50030\n",
      "Ep 254 * AvgReward -134.07 * true AvgReward -134.07 * Reward -215.80 * True Reward -215.80 * time 7.83 * step 50650\n",
      "Ep 255 * AvgReward -139.60 * true AvgReward -139.60 * Reward -259.32 * True Reward -259.32 * time 1.77 * step 50801\n",
      "Ep 256 * AvgReward -136.07 * true AvgReward -136.07 * Reward -306.07 * True Reward -306.07 * time 5.85 * step 51264\n",
      "Ep 257 * AvgReward -123.43 * true AvgReward -123.43 * Reward -273.85 * True Reward -273.85 * time 1.28 * step 51371\n",
      "Ep 258 * AvgReward -119.65 * true AvgReward -119.65 * Reward -257.74 * True Reward -257.74 * time 1.36 * step 51486\n",
      "Ep 259 * AvgReward -117.58 * true AvgReward -117.58 * Reward -187.46 * True Reward -187.46 * time 5.09 * step 51898\n",
      "Ep 260 * AvgReward -113.31 * true AvgReward -113.31 * Reward -144.18 * True Reward -144.18 * time 4.32 * step 52251\n",
      "Ep 261 * AvgReward -112.37 * true AvgReward -112.37 * Reward -3.79 * True Reward -3.79 * time 0.98 * step 52334\n",
      "Ep 262 * AvgReward -118.73 * true AvgReward -118.73 * Reward -178.13 * True Reward -178.13 * time 0.99 * step 52419\n",
      "Ep 263 * AvgReward -119.29 * true AvgReward -119.29 * Reward -153.09 * True Reward -153.09 * time 2.73 * step 52647\n",
      "Ep 264 * AvgReward -127.27 * true AvgReward -127.27 * Reward -196.85 * True Reward -196.85 * time 1.63 * step 52786\n",
      "Ep 265 * AvgReward -138.66 * true AvgReward -138.66 * Reward -284.80 * True Reward -284.80 * time 5.24 * step 53209\n",
      "Ep 266 * AvgReward -166.07 * true AvgReward -166.07 * Reward -564.15 * True Reward -564.15 * time 1.36 * step 53324\n",
      "Ep 267 * AvgReward -192.23 * true AvgReward -192.23 * Reward -543.16 * True Reward -543.16 * time 1.29 * step 53432\n",
      "Ep 268 * AvgReward -206.04 * true AvgReward -206.04 * Reward -293.87 * True Reward -293.87 * time 1.33 * step 53546\n",
      "Ep 269 * AvgReward -216.58 * true AvgReward -216.58 * Reward -246.41 * True Reward -246.41 * time 3.31 * step 53823\n",
      "Ep 270 * AvgReward -213.33 * true AvgReward -213.33 * Reward -103.33 * True Reward -103.33 * time 1.47 * step 53948\n",
      "Ep 271 * AvgReward -218.49 * true AvgReward -218.49 * Reward -171.43 * True Reward -171.43 * time 7.74 * step 54568\n",
      "Ep 272 * AvgReward -222.57 * true AvgReward -222.57 * Reward -95.16 * True Reward -95.16 * time 1.21 * step 54670\n",
      "Ep 273 * AvgReward -227.99 * true AvgReward -227.99 * Reward -81.22 * True Reward -81.22 * time 1.17 * step 54769\n",
      "Ep 274 * AvgReward -219.57 * true AvgReward -219.57 * Reward -47.30 * True Reward -47.30 * time 1.17 * step 54868\n",
      "Ep 275 * AvgReward -194.14 * true AvgReward -194.14 * Reward 249.11 * True Reward 249.11 * time 3.93 * step 55192\n",
      "Ep 276 * AvgReward -187.68 * true AvgReward -187.68 * Reward -176.74 * True Reward -176.74 * time 6.75 * step 55733\n",
      "Ep 277 * AvgReward -194.70 * true AvgReward -194.70 * Reward -414.37 * True Reward -414.37 * time 1.40 * step 55851\n",
      "Ep 278 * AvgReward -189.79 * true AvgReward -189.79 * Reward -159.54 * True Reward -159.54 * time 1.27 * step 55958\n",
      "Ep 279 * AvgReward -187.60 * true AvgReward -187.60 * Reward -143.54 * True Reward -143.54 * time 5.05 * step 56366\n",
      "Ep 280 * AvgReward -185.67 * true AvgReward -185.67 * Reward -105.55 * True Reward -105.55 * time 1.02 * step 56453\n",
      "Ep 281 * AvgReward -207.77 * true AvgReward -207.77 * Reward -445.82 * True Reward -445.82 * time 1.86 * step 56609\n",
      "Ep 282 * AvgReward -208.47 * true AvgReward -208.47 * Reward -192.16 * True Reward -192.16 * time 7.93 * step 57230\n",
      "Ep 283 * AvgReward -210.24 * true AvgReward -210.24 * Reward -188.52 * True Reward -188.52 * time 8.41 * step 57884\n",
      "Ep 284 * AvgReward -188.34 * true AvgReward -188.34 * Reward 241.23 * True Reward 241.23 * time 2.63 * step 58103\n",
      "Ep 285 * AvgReward -183.68 * true AvgReward -183.68 * Reward -191.70 * True Reward -191.70 * time 1.08 * step 58195\n",
      "Ep 286 * AvgReward -167.81 * true AvgReward -167.81 * Reward -246.78 * True Reward -246.78 * time 1.69 * step 58338\n",
      "Ep 287 * AvgReward -150.16 * true AvgReward -150.16 * Reward -190.16 * True Reward -190.16 * time 2.96 * step 58583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 288 * AvgReward -143.28 * true AvgReward -143.28 * Reward -156.17 * True Reward -156.17 * time 0.99 * step 58667\n",
      "Ep 289 * AvgReward -148.11 * true AvgReward -148.11 * Reward -343.11 * True Reward -343.11 * time 1.26 * step 58773\n",
      "Ep 290 * AvgReward -165.45 * true AvgReward -165.45 * Reward -450.07 * True Reward -450.07 * time 1.50 * step 58901\n",
      "Ep 291 * AvgReward -169.39 * true AvgReward -169.39 * Reward -250.30 * True Reward -250.30 * time 8.16 * step 59532\n",
      "Ep 292 * AvgReward -175.33 * true AvgReward -175.33 * Reward -213.94 * True Reward -213.94 * time 10.25 * step 60327\n",
      "Ep 293 * AvgReward -179.45 * true AvgReward -179.45 * Reward -163.64 * True Reward -163.64 * time 3.68 * step 60636\n",
      "Ep 294 * AvgReward -178.86 * true AvgReward -178.86 * Reward -35.37 * True Reward -35.37 * time 5.90 * step 61108\n",
      "Ep 295 * AvgReward -180.84 * true AvgReward -180.84 * Reward 209.53 * True Reward 209.53 * time 3.36 * step 61386\n",
      "Ep 296 * AvgReward -178.98 * true AvgReward -178.98 * Reward -139.54 * True Reward -139.54 * time 1.31 * step 61496\n",
      "Ep 297 * AvgReward -171.33 * true AvgReward -171.33 * Reward -261.43 * True Reward -261.43 * time 1.24 * step 61602\n",
      "Ep 298 * AvgReward -177.79 * true AvgReward -177.79 * Reward -288.68 * True Reward -288.68 * time 1.04 * step 61690\n",
      "Ep 299 * AvgReward -182.50 * true AvgReward -182.50 * Reward -237.83 * True Reward -237.83 * time 1.02 * step 61775\n",
      "Ep 300 * AvgReward -177.03 * true AvgReward -177.03 * Reward 3.85 * True Reward 3.85 * time 2.46 * step 61978\n",
      "Ep 301 * AvgReward -142.69 * true AvgReward -142.69 * Reward 241.08 * True Reward 241.08 * time 2.01 * step 62146\n",
      "Ep 302 * AvgReward -119.93 * true AvgReward -119.93 * Reward 263.04 * True Reward 263.04 * time 3.51 * step 62436\n",
      "Ep 303 * AvgReward -117.43 * true AvgReward -117.43 * Reward -138.59 * True Reward -138.59 * time 3.21 * step 62702\n",
      "Ep 304 * AvgReward -130.05 * true AvgReward -130.05 * Reward -11.20 * True Reward -11.20 * time 13.01 * step 63702\n",
      "Ep 305 * AvgReward -109.21 * true AvgReward -109.21 * Reward 225.17 * True Reward 225.17 * time 2.72 * step 63928\n",
      "Ep 306 * AvgReward -85.52 * true AvgReward -85.52 * Reward 227.01 * True Reward 227.01 * time 7.13 * step 64496\n",
      "Ep 307 * AvgReward -79.52 * true AvgReward -79.52 * Reward -70.17 * True Reward -70.17 * time 1.06 * step 64586\n",
      "Ep 308 * AvgReward -77.32 * true AvgReward -77.32 * Reward -112.22 * True Reward -112.22 * time 1.80 * step 64740\n",
      "Ep 309 * AvgReward -61.44 * true AvgReward -61.44 * Reward -25.50 * True Reward -25.50 * time 1.04 * step 64828\n",
      "Ep 310 * AvgReward -38.41 * true AvgReward -38.41 * Reward 10.56 * True Reward 10.56 * time 1.22 * step 64931\n",
      "Ep 311 * AvgReward -24.51 * true AvgReward -24.51 * Reward 27.73 * True Reward 27.73 * time 1.32 * step 65041\n",
      "Ep 312 * AvgReward -25.91 * true AvgReward -25.91 * Reward -241.99 * True Reward -241.99 * time 10.91 * step 65902\n",
      "Ep 313 * AvgReward -7.40 * true AvgReward -7.40 * Reward 206.57 * True Reward 206.57 * time 5.22 * step 66326\n",
      "Ep 314 * AvgReward 7.45 * true AvgReward 7.45 * Reward 261.56 * True Reward 261.56 * time 1.75 * step 66472\n",
      "Ep 315 * AvgReward -2.98 * true AvgReward -2.98 * Reward 0.91 * True Reward 0.91 * time 1.32 * step 66584\n",
      "Ep 316 * AvgReward 4.11 * true AvgReward 4.11 * Reward 2.38 * True Reward 2.38 * time 1.18 * step 66683\n",
      "Ep 317 * AvgReward 14.74 * true AvgReward 14.74 * Reward -48.80 * True Reward -48.80 * time 0.87 * step 66756\n",
      "Ep 318 * AvgReward 36.20 * true AvgReward 36.20 * Reward 140.46 * True Reward 140.46 * time 12.69 * step 67756\n",
      "Ep 319 * AvgReward 60.42 * true AvgReward 60.42 * Reward 246.49 * True Reward 246.49 * time 6.32 * step 68276\n",
      "Ep 320 * AvgReward 61.24 * true AvgReward 61.24 * Reward 20.29 * True Reward 20.29 * time 1.45 * step 68399\n",
      "Ep 321 * AvgReward 50.20 * true AvgReward 50.20 * Reward 20.28 * True Reward 20.28 * time 1.31 * step 68511\n",
      "Ep 322 * AvgReward 36.86 * true AvgReward 36.86 * Reward -3.84 * True Reward -3.84 * time 1.75 * step 68658\n",
      "Ep 323 * AvgReward 54.48 * true AvgReward 54.48 * Reward 213.87 * True Reward 213.87 * time 9.51 * step 69422\n",
      "Ep 324 * AvgReward 49.70 * true AvgReward 49.70 * Reward -106.68 * True Reward -106.68 * time 0.77 * step 69488\n",
      "Ep 325 * AvgReward 50.34 * true AvgReward 50.34 * Reward 237.80 * True Reward 237.80 * time 2.02 * step 69657\n",
      "Ep 326 * AvgReward 26.27 * true AvgReward 26.27 * Reward -254.37 * True Reward -254.37 * time 3.92 * step 69977\n",
      "Ep 327 * AvgReward 30.97 * true AvgReward 30.97 * Reward 23.88 * True Reward 23.88 * time 1.21 * step 70078\n",
      "Ep 328 * AvgReward 29.88 * true AvgReward 29.88 * Reward -134.02 * True Reward -134.02 * time 1.00 * step 70163\n",
      "Ep 329 * AvgReward 25.52 * true AvgReward 25.52 * Reward -112.69 * True Reward -112.69 * time 1.04 * step 70251\n",
      "Ep 330 * AvgReward 19.33 * true AvgReward 19.33 * Reward -113.34 * True Reward -113.34 * time 0.93 * step 70330\n",
      "Ep 331 * AvgReward 12.81 * true AvgReward 12.81 * Reward -102.54 * True Reward -102.54 * time 0.97 * step 70412\n",
      "Ep 332 * AvgReward 14.22 * true AvgReward 14.22 * Reward -213.74 * True Reward -213.74 * time 0.87 * step 70486\n",
      "Ep 333 * AvgReward -2.53 * true AvgReward -2.53 * Reward -128.41 * True Reward -128.41 * time 0.93 * step 70566\n",
      "Ep 334 * AvgReward -19.01 * true AvgReward -19.01 * Reward -68.22 * True Reward -68.22 * time 0.84 * step 70637\n",
      "Ep 335 * AvgReward -16.88 * true AvgReward -16.88 * Reward 43.62 * True Reward 43.62 * time 1.30 * step 70748\n",
      "Ep 336 * AvgReward -16.38 * true AvgReward -16.38 * Reward 12.41 * True Reward 12.41 * time 1.44 * step 70870\n",
      "Ep 337 * AvgReward -11.87 * true AvgReward -11.87 * Reward 41.31 * True Reward 41.31 * time 1.27 * step 70976\n",
      "Ep 338 * AvgReward -17.39 * true AvgReward -17.39 * Reward 30.02 * True Reward 30.02 * time 1.63 * step 71112\n",
      "Ep 339 * AvgReward -19.81 * true AvgReward -19.81 * Reward 198.09 * True Reward 198.09 * time 2.38 * step 71309\n",
      "Ep 340 * AvgReward -21.55 * true AvgReward -21.55 * Reward -14.50 * True Reward -14.50 * time 1.29 * step 71418\n",
      "Ep 341 * AvgReward -20.12 * true AvgReward -20.12 * Reward 48.86 * True Reward 48.86 * time 1.38 * step 71535\n",
      "Ep 342 * AvgReward -19.38 * true AvgReward -19.38 * Reward 11.07 * True Reward 11.07 * time 2.90 * step 71775\n",
      "Ep 343 * AvgReward -37.22 * true AvgReward -37.22 * Reward -143.01 * True Reward -143.01 * time 1.16 * step 71871\n",
      "Ep 344 * AvgReward -33.39 * true AvgReward -33.39 * Reward -30.09 * True Reward -30.09 * time 0.81 * step 71939\n",
      "Ep 345 * AvgReward -44.57 * true AvgReward -44.57 * Reward 14.20 * True Reward 14.20 * time 1.51 * step 72066\n",
      "Ep 346 * AvgReward -34.52 * true AvgReward -34.52 * Reward -53.30 * True Reward -53.30 * time 1.33 * step 72178\n",
      "Ep 347 * AvgReward -24.55 * true AvgReward -24.55 * Reward 223.25 * True Reward 223.25 * time 4.41 * step 72537\n",
      "Ep 348 * AvgReward -19.38 * true AvgReward -19.38 * Reward -30.67 * True Reward -30.67 * time 1.26 * step 72643\n",
      "Ep 349 * AvgReward -21.99 * true AvgReward -21.99 * Reward -164.87 * True Reward -164.87 * time 0.98 * step 72726\n",
      "Ep 350 * AvgReward -17.38 * true AvgReward -17.38 * Reward -21.10 * True Reward -21.10 * time 0.82 * step 72795\n",
      "Ep 351 * AvgReward -16.26 * true AvgReward -16.26 * Reward -80.14 * True Reward -80.14 * time 0.90 * step 72871\n",
      "Ep 352 * AvgReward -5.23 * true AvgReward -5.23 * Reward 6.91 * True Reward 6.91 * time 1.35 * step 72984\n",
      "Ep 353 * AvgReward -7.42 * true AvgReward -7.42 * Reward -172.31 * True Reward -172.31 * time 11.35 * step 73845\n",
      "Ep 354 * AvgReward 7.34 * true AvgReward 7.34 * Reward 227.14 * True Reward 227.14 * time 3.94 * step 74164\n",
      "Ep 355 * AvgReward 9.55 * true AvgReward 9.55 * Reward 87.65 * True Reward 87.65 * time 12.11 * step 75099\n",
      "Ep 356 * AvgReward 10.54 * true AvgReward 10.54 * Reward 32.33 * True Reward 32.33 * time 1.44 * step 75220\n",
      "Ep 357 * AvgReward 10.09 * true AvgReward 10.09 * Reward 32.20 * True Reward 32.20 * time 1.52 * step 75347\n",
      "Ep 358 * AvgReward 18.08 * true AvgReward 18.08 * Reward 189.97 * True Reward 189.97 * time 11.18 * step 76230\n",
      "Ep 359 * AvgReward 19.84 * true AvgReward 19.84 * Reward 233.19 * True Reward 233.19 * time 5.98 * step 76718\n",
      "Ep 360 * AvgReward 31.58 * true AvgReward 31.58 * Reward 220.30 * True Reward 220.30 * time 4.58 * step 77092\n",
      "Ep 361 * AvgReward 42.01 * true AvgReward 42.01 * Reward 257.42 * True Reward 257.42 * time 3.23 * step 77361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 362 * AvgReward 49.76 * true AvgReward 49.76 * Reward 166.04 * True Reward 166.04 * time 6.18 * step 77860\n",
      "Ep 363 * AvgReward 58.00 * true AvgReward 58.00 * Reward 21.88 * True Reward 21.88 * time 1.23 * step 77964\n",
      "Ep 364 * AvgReward 57.48 * true AvgReward 57.48 * Reward -40.55 * True Reward -40.55 * time 1.23 * step 78068\n",
      "Ep 365 * AvgReward 55.83 * true AvgReward 55.83 * Reward -18.76 * True Reward -18.76 * time 0.84 * step 78139\n",
      "Ep 366 * AvgReward 57.46 * true AvgReward 57.46 * Reward -20.67 * True Reward -20.67 * time 1.12 * step 78234\n",
      "Ep 367 * AvgReward 59.63 * true AvgReward 59.63 * Reward 266.57 * True Reward 266.57 * time 2.28 * step 78425\n",
      "Ep 368 * AvgReward 62.49 * true AvgReward 62.49 * Reward 26.60 * True Reward 26.60 * time 1.44 * step 78547\n",
      "Ep 369 * AvgReward 68.19 * true AvgReward 68.19 * Reward -50.96 * True Reward -50.96 * time 0.85 * step 78619\n",
      "Ep 370 * AvgReward 71.20 * true AvgReward 71.20 * Reward 39.15 * True Reward 39.15 * time 0.85 * step 78691\n",
      "Ep 371 * AvgReward 85.38 * true AvgReward 85.38 * Reward 203.42 * True Reward 203.42 * time 9.69 * step 79442\n",
      "Ep 372 * AvgReward 98.13 * true AvgReward 98.13 * Reward 261.98 * True Reward 261.98 * time 5.27 * step 79868\n",
      "Ep 373 * AvgReward 120.13 * true AvgReward 120.13 * Reward 267.68 * True Reward 267.68 * time 7.89 * step 80495\n",
      "Ep 374 * AvgReward 120.18 * true AvgReward 120.18 * Reward 228.17 * True Reward 228.17 * time 3.47 * step 80780\n",
      "Ep 375 * AvgReward 127.20 * true AvgReward 127.20 * Reward 227.95 * True Reward 227.95 * time 7.44 * step 81368\n",
      "Ep 376 * AvgReward 117.72 * true AvgReward 117.72 * Reward -157.15 * True Reward -157.15 * time 0.70 * step 81427\n",
      "Ep 377 * AvgReward 109.28 * true AvgReward 109.28 * Reward -136.61 * True Reward -136.61 * time 0.60 * step 81478\n",
      "Ep 378 * AvgReward 91.48 * true AvgReward 91.48 * Reward -166.12 * True Reward -166.12 * time 1.06 * step 81567\n",
      "Ep 379 * AvgReward 72.93 * true AvgReward 72.93 * Reward -137.82 * True Reward -137.82 * time 1.23 * step 81671\n",
      "Ep 380 * AvgReward 62.26 * true AvgReward 62.26 * Reward 6.89 * True Reward 6.89 * time 13.75 * step 82671\n",
      "Ep 381 * AvgReward 57.46 * true AvgReward 57.46 * Reward 161.51 * True Reward 161.51 * time 8.10 * step 83302\n",
      "Ep 382 * AvgReward 59.66 * true AvgReward 59.66 * Reward 210.13 * True Reward 210.13 * time 8.01 * step 83943\n",
      "Ep 383 * AvgReward 71.34 * true AvgReward 71.34 * Reward 255.48 * True Reward 255.48 * time 4.06 * step 84275\n",
      "Ep 384 * AvgReward 58.59 * true AvgReward 58.59 * Reward -295.69 * True Reward -295.69 * time 1.43 * step 84396\n",
      "Ep 385 * AvgReward 54.31 * true AvgReward 54.31 * Reward -104.41 * True Reward -104.41 * time 1.70 * step 84540\n",
      "Ep 386 * AvgReward 47.91 * true AvgReward 47.91 * Reward -148.49 * True Reward -148.49 * time 1.42 * step 84661\n",
      "Ep 387 * AvgReward 21.51 * true AvgReward 21.51 * Reward -261.43 * True Reward -261.43 * time 1.13 * step 84755\n",
      "Ep 388 * AvgReward 31.66 * true AvgReward 31.66 * Reward 229.46 * True Reward 229.46 * time 6.03 * step 85246\n",
      "Ep 389 * AvgReward 33.80 * true AvgReward 33.80 * Reward -8.15 * True Reward -8.15 * time 1.19 * step 85346\n",
      "Ep 390 * AvgReward 24.45 * true AvgReward 24.45 * Reward -147.87 * True Reward -147.87 * time 0.89 * step 85422\n",
      "Ep 391 * AvgReward 13.65 * true AvgReward 13.65 * Reward -12.60 * True Reward -12.60 * time 1.16 * step 85520\n",
      "Ep 392 * AvgReward -6.25 * true AvgReward -6.25 * Reward -135.92 * True Reward -135.92 * time 0.82 * step 85590\n",
      "Ep 393 * AvgReward -23.88 * true AvgReward -23.88 * Reward -84.97 * True Reward -84.97 * time 0.93 * step 85667\n",
      "Ep 394 * AvgReward -21.30 * true AvgReward -21.30 * Reward 279.73 * True Reward 279.73 * time 2.54 * step 85875\n",
      "Ep 395 * AvgReward -21.84 * true AvgReward -21.84 * Reward 217.27 * True Reward 217.27 * time 7.59 * step 86489\n",
      "Ep 396 * AvgReward -1.53 * true AvgReward -1.53 * Reward 249.01 * True Reward 249.01 * time 4.50 * step 86860\n",
      "Ep 397 * AvgReward 18.25 * true AvgReward 18.25 * Reward 258.89 * True Reward 258.89 * time 3.90 * step 87172\n",
      "Ep 398 * AvgReward 35.79 * true AvgReward 35.79 * Reward 184.77 * True Reward 184.77 * time 12.80 * step 88172\n",
      "Ep 399 * AvgReward 53.81 * true AvgReward 53.81 * Reward 222.67 * True Reward 222.67 * time 4.02 * step 88490\n",
      "Ep 400 * AvgReward 39.29 * true AvgReward 39.29 * Reward -283.57 * True Reward -283.57 * time 1.11 * step 88578\n",
      "Ep 401 * AvgReward 22.58 * true AvgReward 22.58 * Reward -172.74 * True Reward -172.74 * time 2.25 * step 88759\n",
      "Ep 402 * AvgReward -2.22 * true AvgReward -2.22 * Reward -285.75 * True Reward -285.75 * time 2.25 * step 88942\n",
      "Ep 403 * AvgReward -28.18 * true AvgReward -28.18 * Reward -263.74 * True Reward -263.74 * time 1.41 * step 89058\n",
      "Ep 404 * AvgReward -27.99 * true AvgReward -27.99 * Reward -291.88 * True Reward -291.88 * time 1.22 * step 89158\n",
      "Ep 405 * AvgReward -36.99 * true AvgReward -36.99 * Reward -284.42 * True Reward -284.42 * time 1.05 * step 89246\n",
      "Ep 406 * AvgReward -41.14 * true AvgReward -41.14 * Reward -231.51 * True Reward -231.51 * time 1.54 * step 89371\n",
      "Ep 407 * AvgReward -37.12 * true AvgReward -37.12 * Reward -181.16 * True Reward -181.16 * time 0.87 * step 89442\n",
      "Ep 408 * AvgReward -61.60 * true AvgReward -61.60 * Reward -260.12 * True Reward -260.12 * time 3.38 * step 89722\n",
      "Ep 409 * AvgReward -58.11 * true AvgReward -58.11 * Reward 61.77 * True Reward 61.77 * time 12.80 * step 90722\n",
      "Ep 410 * AvgReward -50.31 * true AvgReward -50.31 * Reward 8.06 * True Reward 8.06 * time 1.94 * step 90877\n",
      "Ep 411 * AvgReward -59.61 * true AvgReward -59.61 * Reward -198.56 * True Reward -198.56 * time 0.96 * step 90959\n",
      "Ep 412 * AvgReward -54.37 * true AvgReward -54.37 * Reward -31.14 * True Reward -31.14 * time 1.70 * step 91100\n",
      "Ep 413 * AvgReward -42.40 * true AvgReward -42.40 * Reward 154.38 * True Reward 154.38 * time 12.50 * step 92100\n",
      "Ep 414 * AvgReward -49.44 * true AvgReward -49.44 * Reward 139.04 * True Reward 139.04 * time 9.21 * step 92821\n",
      "Ep 415 * AvgReward -66.41 * true AvgReward -66.41 * Reward -122.28 * True Reward -122.28 * time 2.19 * step 93004\n",
      "Ep 416 * AvgReward -82.49 * true AvgReward -82.49 * Reward -72.58 * True Reward -72.58 * time 1.49 * step 93130\n",
      "Ep 417 * AvgReward -100.76 * true AvgReward -100.76 * Reward -106.35 * True Reward -106.35 * time 3.55 * step 93424\n",
      "Ep 418 * AvgReward -118.52 * true AvgReward -118.52 * Reward -170.62 * True Reward -170.62 * time 9.11 * step 94117\n",
      "Ep 419 * AvgReward -136.73 * true AvgReward -136.73 * Reward -141.47 * True Reward -141.47 * time 3.73 * step 94423\n",
      "Ep 420 * AvgReward -111.68 * true AvgReward -111.68 * Reward 217.45 * True Reward 217.45 * time 7.43 * step 95017\n",
      "Ep 421 * AvgReward -107.51 * true AvgReward -107.51 * Reward -89.39 * True Reward -89.39 * time 1.60 * step 95150\n",
      "Ep 422 * AvgReward -96.80 * true AvgReward -96.80 * Reward -71.48 * True Reward -71.48 * time 13.71 * step 96150\n",
      "Ep 423 * AvgReward -87.11 * true AvgReward -87.11 * Reward -70.02 * True Reward -70.02 * time 2.33 * step 96343\n",
      "Ep 424 * AvgReward -58.16 * true AvgReward -58.16 * Reward 287.26 * True Reward 287.26 * time 4.73 * step 96733\n",
      "Ep 425 * AvgReward -49.68 * true AvgReward -49.68 * Reward -114.91 * True Reward -114.91 * time 1.21 * step 96833\n",
      "Ep 426 * AvgReward -29.38 * true AvgReward -29.38 * Reward 174.51 * True Reward 174.51 * time 2.99 * step 97077\n",
      "Ep 427 * AvgReward -24.35 * true AvgReward -24.35 * Reward -80.51 * True Reward -80.51 * time 2.06 * step 97250\n",
      "Ep 428 * AvgReward -13.95 * true AvgReward -13.95 * Reward -52.22 * True Reward -52.22 * time 2.19 * step 97433\n",
      "Ep 429 * AvgReward -8.47 * true AvgReward -8.47 * Reward 171.51 * True Reward 171.51 * time 7.46 * step 98025\n",
      "Ep 430 * AvgReward -1.46 * true AvgReward -1.46 * Reward 148.18 * True Reward 148.18 * time 6.23 * step 98517\n",
      "Ep 431 * AvgReward 7.45 * true AvgReward 7.45 * Reward -20.27 * True Reward -20.27 * time 1.09 * step 98607\n",
      "Ep 432 * AvgReward 9.41 * true AvgReward 9.41 * Reward 7.92 * True Reward 7.92 * time 1.11 * step 98698\n",
      "Ep 433 * AvgReward 3.32 * true AvgReward 3.32 * Reward 32.64 * True Reward 32.64 * time 1.19 * step 98797\n",
      "Ep 434 * AvgReward 9.31 * true AvgReward 9.31 * Reward 258.83 * True Reward 258.83 * time 3.97 * step 99126\n",
      "Ep 435 * AvgReward 7.52 * true AvgReward 7.52 * Reward -158.09 * True Reward -158.09 * time 0.91 * step 99203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 436 * AvgReward 8.29 * true AvgReward 8.29 * Reward -57.23 * True Reward -57.23 * time 0.92 * step 99280\n",
      "Ep 437 * AvgReward 10.00 * true AvgReward 10.00 * Reward -72.19 * True Reward -72.19 * time 1.09 * step 99372\n",
      "Ep 438 * AvgReward 19.54 * true AvgReward 19.54 * Reward 20.28 * True Reward 20.28 * time 1.25 * step 99477\n",
      "Ep 439 * AvgReward 27.40 * true AvgReward 27.40 * Reward 15.82 * True Reward 15.82 * time 4.12 * step 99814\n",
      "Ep 440 * AvgReward 16.33 * true AvgReward 16.33 * Reward -4.01 * True Reward -4.01 * time 2.39 * step 100010\n",
      "Ep 441 * AvgReward 14.15 * true AvgReward 14.15 * Reward -133.07 * True Reward -133.07 * time 0.79 * step 100076\n",
      "Ep 442 * AvgReward 14.74 * true AvgReward 14.74 * Reward -59.64 * True Reward -59.64 * time 0.92 * step 100153\n",
      "Ep 443 * AvgReward 20.17 * true AvgReward 20.17 * Reward 38.64 * True Reward 38.64 * time 1.21 * step 100254\n",
      "Ep 444 * AvgReward -2.08 * true AvgReward -2.08 * Reward -157.83 * True Reward -157.83 * time 1.51 * step 100381\n",
      "Ep 445 * AvgReward -7.72 * true AvgReward -7.72 * Reward -227.57 * True Reward -227.57 * time 1.25 * step 100486\n",
      "Ep 446 * AvgReward -22.36 * true AvgReward -22.36 * Reward -118.37 * True Reward -118.37 * time 1.03 * step 100573\n",
      "Ep 447 * AvgReward -22.13 * true AvgReward -22.13 * Reward -75.85 * True Reward -75.85 * time 1.13 * step 100668\n",
      "Ep 448 * AvgReward -24.61 * true AvgReward -24.61 * Reward -101.98 * True Reward -101.98 * time 0.71 * step 100727\n",
      "Ep 449 * AvgReward -43.92 * true AvgReward -43.92 * Reward -214.57 * True Reward -214.57 * time 0.99 * step 100810\n",
      "Ep 450 * AvgReward -52.39 * true AvgReward -52.39 * Reward -21.34 * True Reward -21.34 * time 1.04 * step 100897\n",
      "Ep 451 * AvgReward -54.66 * true AvgReward -54.66 * Reward -65.59 * True Reward -65.59 * time 3.55 * step 101186\n",
      "Ep 452 * AvgReward -54.32 * true AvgReward -54.32 * Reward 14.79 * True Reward 14.79 * time 1.36 * step 101299\n",
      "Ep 453 * AvgReward -55.50 * true AvgReward -55.50 * Reward 9.06 * True Reward 9.06 * time 1.81 * step 101449\n",
      "Ep 454 * AvgReward -71.75 * true AvgReward -71.75 * Reward -66.22 * True Reward -66.22 * time 13.26 * step 102449\n",
      "Ep 455 * AvgReward -66.37 * true AvgReward -66.37 * Reward -50.61 * True Reward -50.61 * time 1.36 * step 102561\n",
      "Ep 456 * AvgReward -66.87 * true AvgReward -66.87 * Reward -67.06 * True Reward -67.06 * time 1.02 * step 102646\n",
      "Ep 457 * AvgReward -51.87 * true AvgReward -51.87 * Reward 227.80 * True Reward 227.80 * time 7.31 * step 103225\n",
      "Ep 458 * AvgReward -54.70 * true AvgReward -54.70 * Reward -36.38 * True Reward -36.38 * time 1.60 * step 103357\n",
      "Ep 459 * AvgReward -53.68 * true AvgReward -53.68 * Reward 36.20 * True Reward 36.20 * time 1.13 * step 103450\n",
      "Ep 460 * AvgReward -66.01 * true AvgReward -66.01 * Reward -250.58 * True Reward -250.58 * time 1.13 * step 103543\n",
      "Ep 461 * AvgReward -62.47 * true AvgReward -62.47 * Reward -62.33 * True Reward -62.33 * time 1.03 * step 103629\n",
      "Ep 462 * AvgReward -57.69 * true AvgReward -57.69 * Reward 36.04 * True Reward 36.04 * time 1.35 * step 103741\n",
      "Ep 463 * AvgReward -45.91 * true AvgReward -45.91 * Reward 274.26 * True Reward 274.26 * time 4.02 * step 104068\n",
      "Ep 464 * AvgReward -41.31 * true AvgReward -41.31 * Reward -65.95 * True Reward -65.95 * time 0.98 * step 104150\n",
      "Ep 465 * AvgReward -32.54 * true AvgReward -32.54 * Reward -52.14 * True Reward -52.14 * time 0.91 * step 104227\n",
      "Ep 466 * AvgReward -30.17 * true AvgReward -30.17 * Reward -70.89 * True Reward -70.89 * time 1.06 * step 104314\n",
      "Ep 467 * AvgReward -17.82 * true AvgReward -17.82 * Reward 171.16 * True Reward 171.16 * time 3.37 * step 104589\n",
      "Ep 468 * AvgReward -0.21 * true AvgReward -0.21 * Reward 250.18 * True Reward 250.18 * time 2.58 * step 104800\n",
      "Ep 469 * AvgReward 23.75 * true AvgReward 23.75 * Reward 264.62 * True Reward 264.62 * time 3.12 * step 105053\n",
      "Ep 470 * AvgReward 27.01 * true AvgReward 27.01 * Reward 43.80 * True Reward 43.80 * time 1.61 * step 105187\n",
      "Ep 471 * AvgReward 42.76 * true AvgReward 42.76 * Reward 249.40 * True Reward 249.40 * time 1.95 * step 105349\n",
      "Ep 472 * AvgReward 54.59 * true AvgReward 54.59 * Reward 251.37 * True Reward 251.37 * time 12.35 * step 106332\n",
      "Ep 473 * AvgReward 41.59 * true AvgReward 41.59 * Reward -250.92 * True Reward -250.92 * time 1.14 * step 106428\n",
      "Ep 474 * AvgReward 55.30 * true AvgReward 55.30 * Reward 208.11 * True Reward 208.11 * time 9.68 * step 107202\n",
      "Ep 475 * AvgReward 69.47 * true AvgReward 69.47 * Reward 232.80 * True Reward 232.80 * time 4.19 * step 107541\n",
      "Ep 476 * AvgReward 86.35 * true AvgReward 86.35 * Reward 270.41 * True Reward 270.41 * time 3.61 * step 107831\n",
      "Ep 477 * AvgReward 86.88 * true AvgReward 86.88 * Reward 238.47 * True Reward 238.47 * time 4.14 * step 108168\n",
      "Ep 478 * AvgReward 86.45 * true AvgReward 86.45 * Reward -45.11 * True Reward -45.11 * time 3.63 * step 108463\n",
      "Ep 479 * AvgReward 78.39 * true AvgReward 78.39 * Reward -124.96 * True Reward -124.96 * time 7.31 * step 109037\n",
      "Ep 480 * AvgReward 84.58 * true AvgReward 84.58 * Reward -126.80 * True Reward -126.80 * time 8.53 * step 109714\n",
      "Ep 481 * AvgReward 100.15 * true AvgReward 100.15 * Reward 249.16 * True Reward 249.16 * time 5.06 * step 110117\n",
      "Ep 482 * AvgReward 95.16 * true AvgReward 95.16 * Reward -63.72 * True Reward -63.72 * time 1.23 * step 110217\n",
      "Ep 483 * AvgReward 93.74 * true AvgReward 93.74 * Reward 245.71 * True Reward 245.71 * time 5.92 * step 110692\n",
      "Ep 484 * AvgReward 95.66 * true AvgReward 95.66 * Reward -27.38 * True Reward -27.38 * time 1.26 * step 110797\n",
      "Ep 485 * AvgReward 112.96 * true AvgReward 112.96 * Reward 293.81 * True Reward 293.81 * time 5.18 * step 111208\n",
      "Ep 486 * AvgReward 101.32 * true AvgReward 101.32 * Reward -303.65 * True Reward -303.65 * time 1.32 * step 111318\n",
      "Ep 487 * AvgReward 91.98 * true AvgReward 91.98 * Reward -15.71 * True Reward -15.71 * time 1.22 * step 111419\n",
      "Ep 488 * AvgReward 72.11 * true AvgReward 72.11 * Reward -147.29 * True Reward -147.29 * time 0.82 * step 111487\n",
      "Ep 489 * AvgReward 52.10 * true AvgReward 52.10 * Reward -135.56 * True Reward -135.56 * time 0.87 * step 111560\n",
      "Ep 490 * AvgReward 46.09 * true AvgReward 46.09 * Reward -76.37 * True Reward -76.37 * time 1.15 * step 111657\n",
      "Ep 491 * AvgReward 42.92 * true AvgReward 42.92 * Reward 186.12 * True Reward 186.12 * time 4.30 * step 112003\n",
      "Ep 492 * AvgReward 24.11 * true AvgReward 24.11 * Reward -124.96 * True Reward -124.96 * time 8.18 * step 112652\n",
      "Ep 493 * AvgReward 31.49 * true AvgReward 31.49 * Reward -103.25 * True Reward -103.25 * time 6.26 * step 113141\n",
      "Ep 494 * AvgReward 19.21 * true AvgReward 19.21 * Reward -37.47 * True Reward -37.47 * time 1.26 * step 113247\n",
      "Ep 495 * AvgReward 4.00 * true AvgReward 4.00 * Reward -71.39 * True Reward -71.39 * time 0.69 * step 113305\n",
      "Ep 496 * AvgReward -18.38 * true AvgReward -18.38 * Reward -177.25 * True Reward -177.25 * time 1.06 * step 113394\n",
      "Ep 497 * AvgReward -36.17 * true AvgReward -36.17 * Reward -117.29 * True Reward -117.29 * time 1.36 * step 113508\n",
      "Ep 498 * AvgReward -36.20 * true AvgReward -36.20 * Reward -45.78 * True Reward -45.78 * time 1.36 * step 113621\n",
      "Ep 499 * AvgReward -30.48 * true AvgReward -30.48 * Reward -10.53 * True Reward -10.53 * time 2.85 * step 113854\n",
      "Ep 500 * AvgReward -25.17 * true AvgReward -25.17 * Reward -20.65 * True Reward -20.65 * time 1.05 * step 113942\n",
      "Ep 501 * AvgReward -46.58 * true AvgReward -46.58 * Reward -178.93 * True Reward -178.93 * time 1.89 * step 114099\n",
      "Ep 502 * AvgReward -30.43 * true AvgReward -30.43 * Reward 259.29 * True Reward 259.29 * time 2.52 * step 114305\n",
      "Ep 503 * AvgReward -34.46 * true AvgReward -34.46 * Reward 165.05 * True Reward 165.05 * time 4.68 * step 114676\n",
      "Ep 504 * AvgReward -42.61 * true AvgReward -42.61 * Reward -190.42 * True Reward -190.42 * time 1.64 * step 114814\n",
      "Ep 505 * AvgReward -61.45 * true AvgReward -61.45 * Reward -82.89 * True Reward -82.89 * time 1.20 * step 114914\n",
      "Ep 506 * AvgReward -63.48 * true AvgReward -63.48 * Reward -344.34 * True Reward -344.34 * time 1.12 * step 115007\n",
      "Ep 507 * AvgReward -71.00 * true AvgReward -71.00 * Reward -166.13 * True Reward -166.13 * time 0.93 * step 115084\n",
      "Ep 508 * AvgReward -63.90 * true AvgReward -63.90 * Reward -5.24 * True Reward -5.24 * time 1.72 * step 115226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 509 * AvgReward -66.47 * true AvgReward -66.47 * Reward -186.92 * True Reward -186.92 * time 0.90 * step 115302\n",
      "Ep 510 * AvgReward -72.28 * true AvgReward -72.28 * Reward -192.55 * True Reward -192.55 * time 1.01 * step 115387\n",
      "Ep 511 * AvgReward -89.06 * true AvgReward -89.06 * Reward -149.58 * True Reward -149.58 * time 0.77 * step 115450\n",
      "Ep 512 * AvgReward -90.51 * true AvgReward -90.51 * Reward -154.03 * True Reward -154.03 * time 1.07 * step 115539\n",
      "Ep 513 * AvgReward -95.94 * true AvgReward -95.94 * Reward -211.68 * True Reward -211.68 * time 1.37 * step 115653\n",
      "Ep 514 * AvgReward -98.36 * true AvgReward -98.36 * Reward -85.89 * True Reward -85.89 * time 0.99 * step 115736\n",
      "Ep 515 * AvgReward -104.58 * true AvgReward -104.58 * Reward -195.76 * True Reward -195.76 * time 1.20 * step 115836\n",
      "Ep 516 * AvgReward -107.71 * true AvgReward -107.71 * Reward -239.88 * True Reward -239.88 * time 1.20 * step 115936\n",
      "Ep 517 * AvgReward -113.56 * true AvgReward -113.56 * Reward -234.26 * True Reward -234.26 * time 1.17 * step 116033\n",
      "Ep 518 * AvgReward -124.33 * true AvgReward -124.33 * Reward -261.35 * True Reward -261.35 * time 1.14 * step 116128\n",
      "Ep 519 * AvgReward -125.59 * true AvgReward -125.59 * Reward -35.72 * True Reward -35.72 * time 1.07 * step 116216\n",
      "Ep 520 * AvgReward -111.72 * true AvgReward -111.72 * Reward 256.85 * True Reward 256.85 * time 4.63 * step 116588\n",
      "Ep 521 * AvgReward -89.54 * true AvgReward -89.54 * Reward 264.73 * True Reward 264.73 * time 5.96 * step 117066\n",
      "Ep 522 * AvgReward -92.50 * true AvgReward -92.50 * Reward 199.97 * True Reward 199.97 * time 3.79 * step 117372\n",
      "Ep 523 * AvgReward -88.82 * true AvgReward -88.82 * Reward 238.65 * True Reward 238.65 * time 4.01 * step 117698\n",
      "Ep 524 * AvgReward -82.13 * true AvgReward -82.13 * Reward -56.62 * True Reward -56.62 * time 13.70 * step 118698\n",
      "Ep 525 * AvgReward -80.05 * true AvgReward -80.05 * Reward -41.28 * True Reward -41.28 * time 13.21 * step 119698\n",
      "Ep 526 * AvgReward -63.60 * true AvgReward -63.60 * Reward -15.20 * True Reward -15.20 * time 2.88 * step 119934\n",
      "Ep 527 * AvgReward -66.58 * true AvgReward -66.58 * Reward -225.78 * True Reward -225.78 * time 1.22 * step 120035\n",
      "Ep 528 * AvgReward -70.51 * true AvgReward -70.51 * Reward -83.90 * True Reward -83.90 * time 1.25 * step 120139\n",
      "Ep 529 * AvgReward -71.63 * true AvgReward -71.63 * Reward -209.35 * True Reward -209.35 * time 0.92 * step 120216\n",
      "Ep 530 * AvgReward -62.43 * true AvgReward -62.43 * Reward -8.58 * True Reward -8.58 * time 1.89 * step 120374\n",
      "Ep 531 * AvgReward -54.07 * true AvgReward -54.07 * Reward 17.63 * True Reward 17.63 * time 3.76 * step 120678\n",
      "Ep 532 * AvgReward -51.07 * true AvgReward -51.07 * Reward -93.97 * True Reward -93.97 * time 1.23 * step 120780\n",
      "Ep 533 * AvgReward -50.70 * true AvgReward -50.70 * Reward -204.29 * True Reward -204.29 * time 1.02 * step 120866\n",
      "Ep 534 * AvgReward -48.65 * true AvgReward -48.65 * Reward -44.98 * True Reward -44.98 * time 1.43 * step 120984\n",
      "Ep 535 * AvgReward -46.95 * true AvgReward -46.95 * Reward -161.75 * True Reward -161.75 * time 1.06 * step 121072\n",
      "Ep 536 * AvgReward -37.91 * true AvgReward -37.91 * Reward -58.93 * True Reward -58.93 * time 0.93 * step 121150\n",
      "Ep 537 * AvgReward -24.14 * true AvgReward -24.14 * Reward 41.12 * True Reward 41.12 * time 1.79 * step 121298\n",
      "Ep 538 * AvgReward 0.22 * true AvgReward 0.22 * Reward 225.83 * True Reward 225.83 * time 11.71 * step 122186\n",
      "Ep 539 * AvgReward 16.37 * true AvgReward 16.37 * Reward 287.23 * True Reward 287.23 * time 2.00 * step 122351\n",
      "Ep 540 * AvgReward -9.37 * true AvgReward -9.37 * Reward -257.90 * True Reward -257.90 * time 1.07 * step 122441\n",
      "Ep 541 * AvgReward -9.92 * true AvgReward -9.92 * Reward 253.78 * True Reward 253.78 * time 8.29 * step 123081\n",
      "Ep 542 * AvgReward -8.43 * true AvgReward -8.43 * Reward 229.74 * True Reward 229.74 * time 4.86 * step 123468\n",
      "Ep 543 * AvgReward -26.87 * true AvgReward -26.87 * Reward -130.19 * True Reward -130.19 * time 0.63 * step 123520\n",
      "Ep 544 * AvgReward -27.30 * true AvgReward -27.30 * Reward -65.30 * True Reward -65.30 * time 0.81 * step 123587\n",
      "Ep 545 * AvgReward -30.82 * true AvgReward -30.82 * Reward -111.60 * True Reward -111.60 * time 0.92 * step 123662\n",
      "Ep 546 * AvgReward -24.96 * true AvgReward -24.96 * Reward 102.04 * True Reward 102.04 * time 12.77 * step 124583\n",
      "Ep 547 * AvgReward -1.27 * true AvgReward -1.27 * Reward 247.94 * True Reward 247.94 * time 4.75 * step 124966\n",
      "Ep 548 * AvgReward 16.39 * true AvgReward 16.39 * Reward 269.32 * True Reward 269.32 * time 2.85 * step 125198\n",
      "Ep 549 * AvgReward 27.96 * true AvgReward 27.96 * Reward 21.96 * True Reward 21.96 * time 3.01 * step 125445\n",
      "Ep 550 * AvgReward 29.13 * true AvgReward 29.13 * Reward 14.93 * True Reward 14.93 * time 4.45 * step 125808\n",
      "Ep 551 * AvgReward 31.18 * true AvgReward 31.18 * Reward 58.63 * True Reward 58.63 * time 1.00 * step 125890\n",
      "Ep 552 * AvgReward 36.46 * true AvgReward 36.46 * Reward 11.56 * True Reward 11.56 * time 4.39 * step 126244\n",
      "Ep 553 * AvgReward 59.90 * true AvgReward 59.90 * Reward 264.58 * True Reward 264.58 * time 5.66 * step 126699\n",
      "Ep 554 * AvgReward 58.70 * true AvgReward 58.70 * Reward -69.06 * True Reward -69.06 * time 4.90 * step 127091\n",
      "Ep 555 * AvgReward 57.40 * true AvgReward 57.40 * Reward -187.68 * True Reward -187.68 * time 0.71 * step 127150\n",
      "Ep 556 * AvgReward 53.51 * true AvgReward 53.51 * Reward -136.81 * True Reward -136.81 * time 0.67 * step 127206\n",
      "Ep 557 * AvgReward 37.44 * true AvgReward 37.44 * Reward -280.26 * True Reward -280.26 * time 1.36 * step 127318\n",
      "Ep 558 * AvgReward 21.11 * true AvgReward 21.11 * Reward -100.62 * True Reward -100.62 * time 0.77 * step 127380\n",
      "Ep 559 * AvgReward -12.08 * true AvgReward -12.08 * Reward -376.58 * True Reward -376.58 * time 0.96 * step 127456\n",
      "Ep 560 * AvgReward -7.45 * true AvgReward -7.45 * Reward -165.30 * True Reward -165.30 * time 1.38 * step 127569\n",
      "Ep 561 * AvgReward -27.14 * true AvgReward -27.14 * Reward -140.19 * True Reward -140.19 * time 0.63 * step 127622\n",
      "Ep 562 * AvgReward -38.38 * true AvgReward -38.38 * Reward 5.02 * True Reward 5.02 * time 1.01 * step 127707\n",
      "Ep 563 * AvgReward -41.10 * true AvgReward -41.10 * Reward -184.57 * True Reward -184.57 * time 1.38 * step 127822\n",
      "Ep 564 * AvgReward -40.43 * true AvgReward -40.43 * Reward -51.90 * True Reward -51.90 * time 0.76 * step 127886\n",
      "Ep 565 * AvgReward -45.49 * true AvgReward -45.49 * Reward -212.72 * True Reward -212.72 * time 1.01 * step 127971\n",
      "Ep 566 * AvgReward -53.39 * true AvgReward -53.39 * Reward -55.96 * True Reward -55.96 * time 1.53 * step 128099\n",
      "Ep 567 * AvgReward -77.90 * true AvgReward -77.90 * Reward -242.34 * True Reward -242.34 * time 1.03 * step 128186\n",
      "Ep 568 * AvgReward -100.28 * true AvgReward -100.28 * Reward -178.34 * True Reward -178.34 * time 1.02 * step 128271\n",
      "Ep 569 * AvgReward -109.64 * true AvgReward -109.64 * Reward -165.28 * True Reward -165.28 * time 0.65 * step 128326\n",
      "Ep 570 * AvgReward -118.87 * true AvgReward -118.87 * Reward -169.61 * True Reward -169.61 * time 0.81 * step 128394\n",
      "Ep 571 * AvgReward -132.19 * true AvgReward -132.19 * Reward -207.72 * True Reward -207.72 * time 1.35 * step 128507\n",
      "Ep 572 * AvgReward -144.85 * true AvgReward -144.85 * Reward -241.63 * True Reward -241.63 * time 1.09 * step 128597\n",
      "Ep 573 * AvgReward -161.25 * true AvgReward -161.25 * Reward -63.53 * True Reward -63.53 * time 4.66 * step 128969\n",
      "Ep 574 * AvgReward -154.78 * true AvgReward -154.78 * Reward 60.37 * True Reward 60.37 * time 2.10 * step 129142\n",
      "Ep 575 * AvgReward -163.60 * true AvgReward -163.60 * Reward -364.08 * True Reward -364.08 * time 2.28 * step 129327\n",
      "Ep 576 * AvgReward -170.45 * true AvgReward -170.45 * Reward -273.69 * True Reward -273.69 * time 1.33 * step 129439\n",
      "Ep 577 * AvgReward -142.08 * true AvgReward -142.08 * Reward 287.17 * True Reward 287.17 * time 3.03 * step 129690\n",
      "Ep 578 * AvgReward -137.15 * true AvgReward -137.15 * Reward -2.02 * True Reward -2.02 * time 1.21 * step 129788\n",
      "Ep 579 * AvgReward -119.72 * true AvgReward -119.72 * Reward -28.17 * True Reward -28.17 * time 4.96 * step 130176\n",
      "Ep 580 * AvgReward -110.78 * true AvgReward -110.78 * Reward 13.50 * True Reward 13.50 * time 1.25 * step 130279\n",
      "Ep 581 * AvgReward -103.29 * true AvgReward -103.29 * Reward 9.68 * True Reward 9.68 * time 1.21 * step 130377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 582 * AvgReward -91.68 * true AvgReward -91.68 * Reward 237.22 * True Reward 237.22 * time 2.24 * step 130559\n",
      "Ep 583 * AvgReward -69.63 * true AvgReward -69.63 * Reward 256.53 * True Reward 256.53 * time 2.55 * step 130769\n",
      "Ep 584 * AvgReward -76.84 * true AvgReward -76.84 * Reward -196.23 * True Reward -196.23 * time 10.74 * step 131596\n",
      "Ep 585 * AvgReward -81.91 * true AvgReward -81.91 * Reward -314.03 * True Reward -314.03 * time 4.80 * step 131984\n",
      "Ep 586 * AvgReward -91.43 * true AvgReward -91.43 * Reward -246.30 * True Reward -246.30 * time 1.68 * step 132123\n",
      "Ep 587 * AvgReward -66.94 * true AvgReward -66.94 * Reward 247.29 * True Reward 247.29 * time 3.85 * step 132434\n",
      "Ep 588 * AvgReward -58.06 * true AvgReward -58.06 * Reward -0.63 * True Reward -0.63 * time 2.33 * step 132626\n",
      "Ep 589 * AvgReward -37.12 * true AvgReward -37.12 * Reward 253.49 * True Reward 253.49 * time 2.96 * step 132866\n",
      "Ep 590 * AvgReward -36.89 * true AvgReward -36.89 * Reward -165.08 * True Reward -165.08 * time 1.09 * step 132954\n",
      "Ep 591 * AvgReward -26.59 * true AvgReward -26.59 * Reward -1.64 * True Reward -1.64 * time 1.37 * step 133066\n",
      "Ep 592 * AvgReward -3.57 * true AvgReward -3.57 * Reward 218.68 * True Reward 218.68 * time 2.35 * step 133257\n",
      "Ep 593 * AvgReward 13.26 * true AvgReward 13.26 * Reward 273.22 * True Reward 273.22 * time 3.28 * step 133524\n",
      "Ep 594 * AvgReward 22.26 * true AvgReward 22.26 * Reward 240.39 * True Reward 240.39 * time 1.89 * step 133680\n",
      "Ep 595 * AvgReward 51.28 * true AvgReward 51.28 * Reward 216.19 * True Reward 216.19 * time 5.80 * step 134140\n",
      "Ep 596 * AvgReward 76.95 * true AvgReward 76.95 * Reward 239.81 * True Reward 239.81 * time 3.54 * step 134428\n",
      "Ep 597 * AvgReward 60.50 * true AvgReward 60.50 * Reward -41.94 * True Reward -41.94 * time 1.17 * step 134524\n",
      "Ep 598 * AvgReward 48.53 * true AvgReward 48.53 * Reward -241.41 * True Reward -241.41 * time 1.38 * step 134637\n",
      "Ep 599 * AvgReward 63.93 * true AvgReward 63.93 * Reward 279.82 * True Reward 279.82 * time 3.97 * step 134961\n",
      "Ep 600 * AvgReward 76.70 * true AvgReward 76.70 * Reward 268.89 * True Reward 268.89 * time 2.13 * step 135138\n",
      "Ep 601 * AvgReward 75.84 * true AvgReward 75.84 * Reward -7.53 * True Reward -7.53 * time 1.52 * step 135262\n",
      "Ep 602 * AvgReward 76.57 * true AvgReward 76.57 * Reward 251.92 * True Reward 251.92 * time 3.07 * step 135511\n",
      "Ep 603 * AvgReward 65.24 * true AvgReward 65.24 * Reward 30.00 * True Reward 30.00 * time 1.25 * step 135615\n",
      "Ep 604 * AvgReward 77.21 * true AvgReward 77.21 * Reward 43.11 * True Reward 43.11 * time 1.09 * step 135706\n",
      "Ep 605 * AvgReward 94.86 * true AvgReward 94.86 * Reward 38.90 * True Reward 38.90 * time 1.33 * step 135817\n",
      "Ep 606 * AvgReward 119.89 * true AvgReward 119.89 * Reward 254.27 * True Reward 254.27 * time 10.67 * step 136649\n",
      "Ep 607 * AvgReward 100.01 * true AvgReward 100.01 * Reward -150.26 * True Reward -150.26 * time 0.88 * step 136722\n",
      "Ep 608 * AvgReward 86.14 * true AvgReward 86.14 * Reward -278.04 * True Reward -278.04 * time 1.77 * step 136869\n",
      "Ep 609 * AvgReward 59.76 * true AvgReward 59.76 * Reward -274.12 * True Reward -274.12 * time 1.61 * step 137002\n",
      "Ep 610 * AvgReward 80.22 * true AvgReward 80.22 * Reward 244.12 * True Reward 244.12 * time 3.43 * step 137279\n",
      "Ep 611 * AvgReward 91.77 * true AvgReward 91.77 * Reward 229.31 * True Reward 229.31 * time 2.41 * step 137476\n",
      "Ep 612 * AvgReward 92.72 * true AvgReward 92.72 * Reward 237.66 * True Reward 237.66 * time 2.12 * step 137649\n",
      "Ep 613 * AvgReward 89.73 * true AvgReward 89.73 * Reward 213.53 * True Reward 213.53 * time 4.58 * step 138017\n",
      "Ep 614 * AvgReward 89.32 * true AvgReward 89.32 * Reward 232.15 * True Reward 232.15 * time 2.05 * step 138185\n",
      "Ep 615 * AvgReward 80.69 * true AvgReward 80.69 * Reward 43.63 * True Reward 43.63 * time 1.62 * step 138315\n",
      "Ep 616 * AvgReward 69.29 * true AvgReward 69.29 * Reward 11.83 * True Reward 11.83 * time 1.33 * step 138425\n",
      "Ep 617 * AvgReward 65.13 * true AvgReward 65.13 * Reward -125.25 * True Reward -125.25 * time 0.81 * step 138491\n",
      "Ep 618 * AvgReward 69.52 * true AvgReward 69.52 * Reward -153.60 * True Reward -153.60 * time 0.81 * step 138558\n",
      "Ep 619 * AvgReward 43.62 * true AvgReward 43.62 * Reward -238.07 * True Reward -238.07 * time 1.19 * step 138657\n",
      "Ep 620 * AvgReward 20.52 * true AvgReward 20.52 * Reward -193.18 * True Reward -193.18 * time 0.86 * step 138729\n",
      "Ep 621 * AvgReward 8.36 * true AvgReward 8.36 * Reward -250.75 * True Reward -250.75 * time 1.44 * step 138849\n",
      "Ep 622 * AvgReward 9.62 * true AvgReward 9.62 * Reward 277.13 * True Reward 277.13 * time 3.04 * step 139098\n",
      "Ep 623 * AvgReward 18.01 * true AvgReward 18.01 * Reward 197.89 * True Reward 197.89 * time 4.18 * step 139437\n",
      "Ep 624 * AvgReward 16.36 * true AvgReward 16.36 * Reward 9.94 * True Reward 9.94 * time 1.37 * step 139551\n",
      "Ep 625 * AvgReward 5.00 * true AvgReward 5.00 * Reward -188.28 * True Reward -188.28 * time 4.07 * step 139880\n",
      "Ep 626 * AvgReward -20.46 * true AvgReward -20.46 * Reward -254.79 * True Reward -254.79 * time 1.55 * step 140010\n",
      "Ep 627 * AvgReward -19.34 * true AvgReward -19.34 * Reward -127.99 * True Reward -127.99 * time 0.97 * step 140090\n",
      "Ep 628 * AvgReward -14.79 * true AvgReward -14.79 * Reward -186.99 * True Reward -186.99 * time 1.19 * step 140188\n",
      "Ep 629 * AvgReward -4.24 * true AvgReward -4.24 * Reward -63.11 * True Reward -63.11 * time 2.46 * step 140389\n",
      "Ep 630 * AvgReward -18.68 * true AvgReward -18.68 * Reward -44.57 * True Reward -44.57 * time 1.24 * step 140493\n",
      "Ep 631 * AvgReward -28.06 * true AvgReward -28.06 * Reward 41.55 * True Reward 41.55 * time 1.36 * step 140606\n",
      "Ep 632 * AvgReward -24.70 * true AvgReward -24.70 * Reward 305.00 * True Reward 305.00 * time 3.36 * step 140881\n",
      "Ep 633 * AvgReward -22.29 * true AvgReward -22.29 * Reward 261.66 * True Reward 261.66 * time 9.04 * step 141588\n",
      "Ep 634 * AvgReward -19.81 * true AvgReward -19.81 * Reward 281.71 * True Reward 281.71 * time 7.18 * step 142161\n",
      "Ep 635 * AvgReward -10.58 * true AvgReward -10.58 * Reward 228.17 * True Reward 228.17 * time 10.63 * step 143005\n",
      "Ep 636 * AvgReward 1.34 * true AvgReward 1.34 * Reward 250.29 * True Reward 250.29 * time 5.64 * step 143465\n",
      "Ep 637 * AvgReward 8.83 * true AvgReward 8.83 * Reward 24.63 * True Reward 24.63 * time 1.45 * step 143585\n",
      "Ep 638 * AvgReward 30.65 * true AvgReward 30.65 * Reward 282.67 * True Reward 282.67 * time 3.26 * step 143851\n",
      "Ep 639 * AvgReward 35.41 * true AvgReward 35.41 * Reward -142.81 * True Reward -142.81 * time 1.24 * step 143952\n",
      "Ep 640 * AvgReward 35.99 * true AvgReward 35.99 * Reward -181.46 * True Reward -181.46 * time 1.34 * step 144064\n",
      "Ep 641 * AvgReward 62.29 * true AvgReward 62.29 * Reward 275.13 * True Reward 275.13 * time 3.31 * step 144334\n",
      "Ep 642 * AvgReward 41.35 * true AvgReward 41.35 * Reward -141.72 * True Reward -141.72 * time 1.17 * step 144430\n",
      "Ep 643 * AvgReward 44.75 * true AvgReward 44.75 * Reward 266.06 * True Reward 266.06 * time 1.98 * step 144594\n",
      "Ep 644 * AvgReward 53.72 * true AvgReward 53.72 * Reward 189.25 * True Reward 189.25 * time 4.15 * step 144931\n",
      "Ep 645 * AvgReward 77.63 * true AvgReward 77.63 * Reward 290.00 * True Reward 290.00 * time 2.22 * step 145116\n",
      "Ep 646 * AvgReward 103.13 * true AvgReward 103.13 * Reward 255.05 * True Reward 255.05 * time 4.54 * step 145482\n",
      "Ep 647 * AvgReward 122.68 * true AvgReward 122.68 * Reward 262.99 * True Reward 262.99 * time 2.38 * step 145679\n",
      "Ep 648 * AvgReward 144.46 * true AvgReward 144.46 * Reward 248.62 * True Reward 248.62 * time 7.75 * step 146292\n",
      "Ep 649 * AvgReward 160.03 * true AvgReward 160.03 * Reward 248.38 * True Reward 248.38 * time 8.33 * step 146944\n",
      "Ep 650 * AvgReward 160.96 * true AvgReward 160.96 * Reward -26.06 * True Reward -26.06 * time 1.08 * step 147033\n",
      "Ep 651 * AvgReward 157.83 * true AvgReward 157.83 * Reward -20.93 * True Reward -20.93 * time 1.49 * step 147158\n",
      "Ep 652 * AvgReward 139.47 * true AvgReward 139.47 * Reward -62.17 * True Reward -62.17 * time 0.82 * step 147227\n",
      "Ep 653 * AvgReward 138.18 * true AvgReward 138.18 * Reward 235.69 * True Reward 235.69 * time 2.12 * step 147400\n",
      "Ep 654 * AvgReward 115.00 * true AvgReward 115.00 * Reward -181.80 * True Reward -181.80 * time 7.70 * step 148007\n",
      "Ep 655 * AvgReward 92.61 * true AvgReward 92.61 * Reward -219.59 * True Reward -219.59 * time 1.16 * step 148105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 656 * AvgReward 75.13 * true AvgReward 75.13 * Reward -99.42 * True Reward -99.42 * time 1.23 * step 148208\n",
      "Ep 657 * AvgReward 65.98 * true AvgReward 65.98 * Reward -158.26 * True Reward -158.26 * time 1.65 * step 148346\n",
      "Ep 658 * AvgReward 49.66 * true AvgReward 49.66 * Reward -43.74 * True Reward -43.74 * time 1.15 * step 148441\n",
      "Ep 659 * AvgReward 47.32 * true AvgReward 47.32 * Reward -189.62 * True Reward -189.62 * time 1.11 * step 148533\n",
      "Ep 660 * AvgReward 50.32 * true AvgReward 50.32 * Reward -121.51 * True Reward -121.51 * time 5.55 * step 148985\n",
      "Ep 661 * AvgReward 24.78 * true AvgReward 24.78 * Reward -235.70 * True Reward -235.70 * time 1.47 * step 149105\n",
      "Ep 662 * AvgReward 27.54 * true AvgReward 27.54 * Reward -86.55 * True Reward -86.55 * time 12.91 * step 150105\n",
      "Ep 663 * AvgReward 24.34 * true AvgReward 24.34 * Reward 202.09 * True Reward 202.09 * time 5.91 * step 150574\n",
      "Ep 664 * AvgReward 28.25 * true AvgReward 28.25 * Reward 267.55 * True Reward 267.55 * time 3.04 * step 150820\n",
      "Ep 665 * AvgReward 14.73 * true AvgReward 14.73 * Reward 19.55 * True Reward 19.55 * time 1.82 * step 150971\n",
      "Ep 666 * AvgReward 12.86 * true AvgReward 12.86 * Reward 217.71 * True Reward 217.71 * time 6.41 * step 151474\n",
      "Ep 667 * AvgReward 11.10 * true AvgReward 11.10 * Reward 227.82 * True Reward 227.82 * time 2.71 * step 151696\n",
      "Ep 668 * AvgReward -1.06 * true AvgReward -1.06 * Reward 5.32 * True Reward 5.32 * time 1.40 * step 151812\n",
      "Ep 669 * AvgReward 0.18 * true AvgReward 0.18 * Reward 273.12 * True Reward 273.12 * time 3.88 * step 152127\n",
      "Ep 670 * AvgReward 3.27 * true AvgReward 3.27 * Reward 35.73 * True Reward 35.73 * time 1.47 * step 152247\n",
      "Ep 671 * AvgReward 5.11 * true AvgReward 5.11 * Reward 15.87 * True Reward 15.87 * time 1.13 * step 152340\n",
      "Ep 672 * AvgReward 9.33 * true AvgReward 9.33 * Reward 22.39 * True Reward 22.39 * time 1.77 * step 152486\n",
      "Ep 673 * AvgReward -2.36 * true AvgReward -2.36 * Reward 1.76 * True Reward 1.76 * time 1.52 * step 152612\n",
      "Ep 674 * AvgReward 6.86 * true AvgReward 6.86 * Reward 2.70 * True Reward 2.70 * time 1.45 * step 152732\n",
      "Ep 675 * AvgReward 30.46 * true AvgReward 30.46 * Reward 252.32 * True Reward 252.32 * time 2.34 * step 152924\n",
      "Ep 676 * AvgReward 47.57 * true AvgReward 47.57 * Reward 242.85 * True Reward 242.85 * time 3.82 * step 153236\n",
      "Ep 677 * AvgReward 52.03 * true AvgReward 52.03 * Reward -69.09 * True Reward -69.09 * time 1.32 * step 153345\n",
      "Ep 678 * AvgReward 45.49 * true AvgReward 45.49 * Reward -174.44 * True Reward -174.44 * time 0.91 * step 153421\n",
      "Ep 679 * AvgReward 46.19 * true AvgReward 46.19 * Reward -175.74 * True Reward -175.74 * time 0.82 * step 153489\n",
      "Ep 680 * AvgReward 44.44 * true AvgReward 44.44 * Reward -156.47 * True Reward -156.47 * time 0.81 * step 153557\n",
      "Ep 681 * AvgReward 47.65 * true AvgReward 47.65 * Reward -171.49 * True Reward -171.49 * time 1.04 * step 153644\n",
      "Ep 682 * AvgReward 41.36 * true AvgReward 41.36 * Reward -212.39 * True Reward -212.39 * time 1.07 * step 153734\n",
      "Ep 683 * AvgReward 24.71 * true AvgReward 24.71 * Reward -130.96 * True Reward -130.96 * time 0.68 * step 153792\n",
      "Ep 684 * AvgReward 4.12 * true AvgReward 4.12 * Reward -144.06 * True Reward -144.06 * time 0.90 * step 153867\n",
      "Ep 685 * AvgReward -1.67 * true AvgReward -1.67 * Reward -96.32 * True Reward -96.32 * time 1.17 * step 153964\n",
      "Ep 686 * AvgReward -19.48 * true AvgReward -19.48 * Reward -138.45 * True Reward -138.45 * time 0.69 * step 154023\n",
      "Ep 687 * AvgReward -36.88 * true AvgReward -36.88 * Reward -120.31 * True Reward -120.31 * time 0.74 * step 154086\n",
      "Ep 688 * AvgReward -43.83 * true AvgReward -43.83 * Reward -133.58 * True Reward -133.58 * time 0.73 * step 154148\n",
      "Ep 689 * AvgReward -63.52 * true AvgReward -63.52 * Reward -120.67 * True Reward -120.67 * time 0.90 * step 154224\n",
      "Ep 690 * AvgReward -71.06 * true AvgReward -71.06 * Reward -115.21 * True Reward -115.21 * time 0.90 * step 154300\n",
      "Ep 691 * AvgReward -77.54 * true AvgReward -77.54 * Reward -113.71 * True Reward -113.71 * time 1.16 * step 154397\n",
      "Ep 692 * AvgReward -84.38 * true AvgReward -84.38 * Reward -114.41 * True Reward -114.41 * time 1.64 * step 154535\n",
      "Ep 693 * AvgReward -82.74 * true AvgReward -82.74 * Reward 34.65 * True Reward 34.65 * time 1.65 * step 154671\n",
      "Ep 694 * AvgReward -69.13 * true AvgReward -69.13 * Reward 274.87 * True Reward 274.87 * time 3.26 * step 154936\n",
      "Ep 695 * AvgReward -82.38 * true AvgReward -82.38 * Reward -12.72 * True Reward -12.72 * time 1.25 * step 155040\n",
      "Ep 696 * AvgReward -99.31 * true AvgReward -99.31 * Reward -95.62 * True Reward -95.62 * time 1.13 * step 155133\n",
      "Ep 697 * AvgReward -107.49 * true AvgReward -107.49 * Reward -232.75 * True Reward -232.75 * time 0.93 * step 155210\n",
      "Ep 698 * AvgReward -111.06 * true AvgReward -111.06 * Reward -245.86 * True Reward -245.86 * time 1.25 * step 155314\n",
      "Ep 699 * AvgReward -105.59 * true AvgReward -105.59 * Reward -66.31 * True Reward -66.31 * time 1.22 * step 155415\n",
      "Ep 700 * AvgReward -106.92 * true AvgReward -106.92 * Reward -183.06 * True Reward -183.06 * time 1.59 * step 155547\n",
      "Ep 701 * AvgReward -85.42 * true AvgReward -85.42 * Reward 258.53 * True Reward 258.53 * time 3.07 * step 155797\n",
      "Ep 702 * AvgReward -61.69 * true AvgReward -61.69 * Reward 262.09 * True Reward 262.09 * time 2.88 * step 156030\n",
      "Ep 703 * AvgReward -42.91 * true AvgReward -42.91 * Reward 244.75 * True Reward 244.75 * time 3.88 * step 156339\n",
      "Ep 704 * AvgReward -32.81 * true AvgReward -32.81 * Reward 57.82 * True Reward 57.82 * time 1.48 * step 156460\n",
      "Ep 705 * AvgReward -17.11 * true AvgReward -17.11 * Reward 217.70 * True Reward 217.70 * time 4.29 * step 156800\n",
      "Ep 706 * AvgReward 1.30 * true AvgReward 1.30 * Reward 229.71 * True Reward 229.71 * time 4.85 * step 157185\n",
      "Ep 707 * AvgReward 20.28 * true AvgReward 20.28 * Reward 259.38 * True Reward 259.38 * time 3.89 * step 157479\n",
      "Ep 708 * AvgReward 19.06 * true AvgReward 19.06 * Reward -158.04 * True Reward -158.04 * time 1.56 * step 157608\n",
      "Ep 709 * AvgReward 11.26 * true AvgReward 11.26 * Reward -276.53 * True Reward -276.53 * time 1.25 * step 157712\n",
      "Ep 710 * AvgReward 10.28 * true AvgReward 10.28 * Reward -134.83 * True Reward -134.83 * time 1.43 * step 157831\n",
      "Ep 711 * AvgReward -14.45 * true AvgReward -14.45 * Reward -608.29 * True Reward -608.29 * time 3.92 * step 158150\n",
      "Ep 712 * AvgReward -40.61 * true AvgReward -40.61 * Reward -637.63 * True Reward -637.63 * time 0.83 * step 158217\n",
      "Ep 713 * AvgReward -72.89 * true AvgReward -72.89 * Reward -610.98 * True Reward -610.98 * time 1.04 * step 158301\n",
      "Ep 714 * AvgReward -104.87 * true AvgReward -104.87 * Reward -364.72 * True Reward -364.72 * time 2.12 * step 158473\n",
      "Ep 715 * AvgReward -121.59 * true AvgReward -121.59 * Reward -347.10 * True Reward -347.10 * time 1.03 * step 158558\n",
      "Ep 716 * AvgReward -104.45 * true AvgReward -104.45 * Reward 247.19 * True Reward 247.19 * time 5.09 * step 158956\n",
      "Ep 717 * AvgReward -78.71 * true AvgReward -78.71 * Reward 282.01 * True Reward 282.01 * time 9.93 * step 159733\n",
      "Ep 718 * AvgReward -54.92 * true AvgReward -54.92 * Reward 229.97 * True Reward 229.97 * time 4.00 * step 160052\n",
      "Ep 719 * AvgReward -39.18 * true AvgReward -39.18 * Reward 248.51 * True Reward 248.51 * time 5.88 * step 160520\n",
      "Ep 720 * AvgReward -32.77 * true AvgReward -32.77 * Reward -55.05 * True Reward -55.05 * time 2.63 * step 160733\n",
      "Ep 721 * AvgReward -33.85 * true AvgReward -33.85 * Reward 237.11 * True Reward 237.11 * time 4.49 * step 161093\n",
      "Ep 722 * AvgReward -34.81 * true AvgReward -34.81 * Reward 242.79 * True Reward 242.79 * time 4.72 * step 161465\n",
      "Ep 723 * AvgReward -33.76 * true AvgReward -33.76 * Reward 265.85 * True Reward 265.85 * time 2.43 * step 161664\n",
      "Ep 724 * AvgReward -22.99 * true AvgReward -22.99 * Reward 273.05 * True Reward 273.05 * time 10.51 * step 162498\n",
      "Ep 725 * AvgReward -25.21 * true AvgReward -25.21 * Reward 173.40 * True Reward 173.40 * time 12.77 * step 163498\n",
      "Ep 726 * AvgReward -34.05 * true AvgReward -34.05 * Reward 52.82 * True Reward 52.82 * time 1.36 * step 163609\n",
      "Ep 727 * AvgReward -36.50 * true AvgReward -36.50 * Reward 210.39 * True Reward 210.39 * time 2.56 * step 163818\n",
      "Ep 728 * AvgReward -18.46 * true AvgReward -18.46 * Reward 202.77 * True Reward 202.77 * time 4.43 * step 164164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 729 * AvgReward 11.19 * true AvgReward 11.19 * Reward 316.59 * True Reward 316.59 * time 4.15 * step 164502\n",
      "Ep 730 * AvgReward 15.88 * true AvgReward 15.88 * Reward -41.04 * True Reward -41.04 * time 2.21 * step 164681\n",
      "Ep 731 * AvgReward 56.74 * true AvgReward 56.74 * Reward 208.78 * True Reward 208.78 * time 1.88 * step 164834\n",
      "Ep 732 * AvgReward 82.48 * true AvgReward 82.48 * Reward -122.80 * True Reward -122.80 * time 0.91 * step 164909\n",
      "Ep 733 * AvgReward 107.55 * true AvgReward 107.55 * Reward -109.54 * True Reward -109.54 * time 0.82 * step 164977\n",
      "Ep 734 * AvgReward 122.02 * true AvgReward 122.02 * Reward -75.25 * True Reward -75.25 * time 0.65 * step 165031\n",
      "Ep 735 * AvgReward 129.01 * true AvgReward 129.01 * Reward -207.36 * True Reward -207.36 * time 1.02 * step 165116\n",
      "Ep 736 * AvgReward 109.00 * true AvgReward 109.00 * Reward -152.90 * True Reward -152.90 * time 0.81 * step 165184\n",
      "Ep 737 * AvgReward 87.47 * true AvgReward 87.47 * Reward -148.72 * True Reward -148.72 * time 0.79 * step 165250\n",
      "Ep 738 * AvgReward 64.52 * true AvgReward 64.52 * Reward -229.05 * True Reward -229.05 * time 0.67 * step 165306\n",
      "Ep 739 * AvgReward 40.72 * true AvgReward 40.72 * Reward -227.52 * True Reward -227.52 * time 0.87 * step 165378\n",
      "Ep 740 * AvgReward 28.82 * true AvgReward 28.82 * Reward -293.01 * True Reward -293.01 * time 0.71 * step 165436\n",
      "Ep 741 * AvgReward -5.27 * true AvgReward -5.27 * Reward -444.60 * True Reward -444.60 * time 0.92 * step 165511\n",
      "Ep 742 * AvgReward -25.92 * true AvgReward -25.92 * Reward -170.23 * True Reward -170.23 * time 0.73 * step 165571\n",
      "Ep 743 * AvgReward -46.85 * true AvgReward -46.85 * Reward -152.69 * True Reward -152.69 * time 1.09 * step 165661\n",
      "Ep 744 * AvgReward -64.66 * true AvgReward -64.66 * Reward -83.23 * True Reward -83.23 * time 0.90 * step 165735\n",
      "Ep 745 * AvgReward -77.11 * true AvgReward -77.11 * Reward -75.51 * True Reward -75.51 * time 0.98 * step 165817\n",
      "Ep 746 * AvgReward -87.35 * true AvgReward -87.35 * Reward -152.04 * True Reward -152.04 * time 0.63 * step 165869\n",
      "Ep 747 * AvgReward -118.65 * true AvgReward -118.65 * Reward -415.61 * True Reward -415.61 * time 1.42 * step 165987\n",
      "Ep 748 * AvgReward -134.74 * true AvgReward -134.74 * Reward -119.04 * True Reward -119.04 * time 0.80 * step 166054\n",
      "Ep 749 * AvgReward -158.56 * true AvgReward -158.56 * Reward -159.88 * True Reward -159.88 * time 1.02 * step 166139\n",
      "Ep 750 * AvgReward -156.93 * true AvgReward -156.93 * Reward -8.45 * True Reward -8.45 * time 1.37 * step 166250\n",
      "Ep 751 * AvgReward -175.79 * true AvgReward -175.79 * Reward -168.35 * True Reward -168.35 * time 0.74 * step 166311\n",
      "Ep 752 * AvgReward -179.16 * true AvgReward -179.16 * Reward -190.25 * True Reward -190.25 * time 0.95 * step 166390\n",
      "Ep 753 * AvgReward -178.12 * true AvgReward -178.12 * Reward -88.78 * True Reward -88.78 * time 1.07 * step 166478\n",
      "Ep 754 * AvgReward -178.33 * true AvgReward -178.33 * Reward -79.42 * True Reward -79.42 * time 1.27 * step 166581\n",
      "Ep 755 * AvgReward -181.42 * true AvgReward -181.42 * Reward -269.19 * True Reward -269.19 * time 1.40 * step 166694\n",
      "Ep 756 * AvgReward -186.14 * true AvgReward -186.14 * Reward -247.25 * True Reward -247.25 * time 1.23 * step 166794\n",
      "Ep 757 * AvgReward -165.49 * true AvgReward -165.49 * Reward 264.32 * True Reward 264.32 * time 2.68 * step 167012\n",
      "Ep 758 * AvgReward -142.00 * true AvgReward -142.00 * Reward 240.76 * True Reward 240.76 * time 3.16 * step 167268\n",
      "Ep 759 * AvgReward -117.95 * true AvgReward -117.95 * Reward 253.44 * True Reward 253.44 * time 8.27 * step 167921\n",
      "Ep 760 * AvgReward -90.36 * true AvgReward -90.36 * Reward 258.76 * True Reward 258.76 * time 6.72 * step 168450\n",
      "Ep 761 * AvgReward -52.67 * true AvgReward -52.67 * Reward 309.17 * True Reward 309.17 * time 3.04 * step 168694\n",
      "Ep 762 * AvgReward -29.99 * true AvgReward -29.99 * Reward 283.36 * True Reward 283.36 * time 2.51 * step 168899\n",
      "Ep 763 * AvgReward -10.11 * true AvgReward -10.11 * Reward 245.00 * True Reward 245.00 * time 10.87 * step 169746\n",
      "Ep 764 * AvgReward 5.46 * true AvgReward 5.46 * Reward 228.22 * True Reward 228.22 * time 4.04 * step 170062\n",
      "Ep 765 * AvgReward 19.45 * true AvgReward 19.45 * Reward 204.21 * True Reward 204.21 * time 6.63 * step 170580\n",
      "Ep 766 * AvgReward 38.09 * true AvgReward 38.09 * Reward 220.76 * True Reward 220.76 * time 10.50 * step 171398\n",
      "Ep 767 * AvgReward 48.75 * true AvgReward 48.75 * Reward -202.42 * True Reward -202.42 * time 1.25 * step 171498\n",
      "Ep 768 * AvgReward 45.08 * true AvgReward 45.08 * Reward -192.36 * True Reward -192.36 * time 0.97 * step 171578\n",
      "Ep 769 * AvgReward 64.86 * true AvgReward 64.86 * Reward 235.67 * True Reward 235.67 * time 4.24 * step 171914\n",
      "Ep 770 * AvgReward 78.63 * true AvgReward 78.63 * Reward 266.89 * True Reward 266.89 * time 5.25 * step 172321\n",
      "Ep 771 * AvgReward 84.95 * true AvgReward 84.95 * Reward -41.87 * True Reward -41.87 * time 13.10 * step 173321\n",
      "Ep 772 * AvgReward 93.06 * true AvgReward 93.06 * Reward -28.04 * True Reward -28.04 * time 1.81 * step 173469\n",
      "Ep 773 * AvgReward 89.33 * true AvgReward 89.33 * Reward -163.36 * True Reward -163.36 * time 1.09 * step 173560\n",
      "Ep 774 * AvgReward 107.91 * true AvgReward 107.91 * Reward 292.09 * True Reward 292.09 * time 4.20 * step 173898\n",
      "Ep 775 * AvgReward 127.83 * true AvgReward 127.83 * Reward 129.31 * True Reward 129.31 * time 9.63 * step 174631\n",
      "Ep 776 * AvgReward 133.25 * true AvgReward 133.25 * Reward -138.88 * True Reward -138.88 * time 1.15 * step 174726\n",
      "Ep 777 * AvgReward 108.67 * true AvgReward 108.67 * Reward -227.34 * True Reward -227.34 * time 1.04 * step 174812\n",
      "Ep 778 * AvgReward 91.19 * true AvgReward 91.19 * Reward -108.89 * True Reward -108.89 * time 1.12 * step 174905\n",
      "Ep 779 * AvgReward 73.59 * true AvgReward 73.59 * Reward -98.56 * True Reward -98.56 * time 1.17 * step 174999\n",
      "Ep 780 * AvgReward 51.57 * true AvgReward 51.57 * Reward -181.47 * True Reward -181.47 * time 1.22 * step 175098\n",
      "Ep 781 * AvgReward 29.09 * true AvgReward 29.09 * Reward -140.61 * True Reward -140.61 * time 1.00 * step 175179\n",
      "Ep 782 * AvgReward 26.60 * true AvgReward 26.60 * Reward 233.73 * True Reward 233.73 * time 3.81 * step 175483\n",
      "Ep 783 * AvgReward 26.01 * true AvgReward 26.01 * Reward 233.20 * True Reward 233.20 * time 1.96 * step 175642\n",
      "Ep 784 * AvgReward 25.85 * true AvgReward 25.85 * Reward 224.88 * True Reward 224.88 * time 2.26 * step 175827\n",
      "Ep 785 * AvgReward 8.52 * true AvgReward 8.52 * Reward -142.33 * True Reward -142.33 * time 0.93 * step 175902\n",
      "Ep 786 * AvgReward -2.30 * true AvgReward -2.30 * Reward 4.28 * True Reward 4.28 * time 1.37 * step 176014\n",
      "Ep 787 * AvgReward 7.60 * true AvgReward 7.60 * Reward -4.39 * True Reward -4.39 * time 1.91 * step 176170\n",
      "Ep 788 * AvgReward 19.42 * true AvgReward 19.42 * Reward 44.16 * True Reward 44.16 * time 2.06 * step 176337\n",
      "Ep 789 * AvgReward 20.33 * true AvgReward 20.33 * Reward 253.73 * True Reward 253.73 * time 3.03 * step 176581\n",
      "Ep 790 * AvgReward 7.09 * true AvgReward 7.09 * Reward 2.12 * True Reward 2.12 * time 1.07 * step 176669\n",
      "Ep 791 * AvgReward 8.83 * true AvgReward 8.83 * Reward -7.07 * True Reward -7.07 * time 1.30 * step 176775\n",
      "Ep 792 * AvgReward 10.32 * true AvgReward 10.32 * Reward 1.73 * True Reward 1.73 * time 0.98 * step 176856\n",
      "Ep 793 * AvgReward 5.67 * true AvgReward 5.67 * Reward -256.22 * True Reward -256.22 * time 1.43 * step 176973\n",
      "Ep 794 * AvgReward -16.85 * true AvgReward -16.85 * Reward -158.31 * True Reward -158.31 * time 1.30 * step 177079\n",
      "Ep 795 * AvgReward -10.31 * true AvgReward -10.31 * Reward 260.12 * True Reward 260.12 * time 2.12 * step 177249\n",
      "Ep 796 * AvgReward 6.68 * true AvgReward 6.68 * Reward 200.92 * True Reward 200.92 * time 4.07 * step 177572\n",
      "Ep 797 * AvgReward 27.40 * true AvgReward 27.40 * Reward 187.04 * True Reward 187.04 * time 4.45 * step 177921\n",
      "Ep 798 * AvgReward 45.86 * true AvgReward 45.86 * Reward 260.27 * True Reward 260.27 * time 4.22 * step 178259\n",
      "Ep 799 * AvgReward 64.35 * true AvgReward 64.35 * Reward 271.18 * True Reward 271.18 * time 3.46 * step 178533\n",
      "Ep 800 * AvgReward 64.24 * true AvgReward 64.24 * Reward -183.74 * True Reward -183.74 * time 1.01 * step 178615\n",
      "Ep 801 * AvgReward 69.18 * true AvgReward 69.18 * Reward -41.79 * True Reward -41.79 * time 1.19 * step 178712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 802 * AvgReward 57.95 * true AvgReward 57.95 * Reward 9.17 * True Reward 9.17 * time 1.18 * step 178809\n",
      "Ep 803 * AvgReward 59.69 * true AvgReward 59.69 * Reward 267.97 * True Reward 267.97 * time 2.30 * step 178996\n",
      "Ep 804 * AvgReward 45.50 * true AvgReward 45.50 * Reward -58.76 * True Reward -58.76 * time 1.75 * step 179141\n",
      "Ep 805 * AvgReward 44.21 * true AvgReward 44.21 * Reward -168.29 * True Reward -168.29 * time 1.21 * step 179240\n",
      "Ep 806 * AvgReward 58.23 * true AvgReward 58.23 * Reward 284.84 * True Reward 284.84 * time 2.29 * step 179424\n",
      "Ep 807 * AvgReward 70.93 * true AvgReward 70.93 * Reward 249.49 * True Reward 249.49 * time 2.35 * step 179616\n",
      "Ep 808 * AvgReward 82.94 * true AvgReward 82.94 * Reward 284.47 * True Reward 284.47 * time 4.88 * step 180003\n",
      "Ep 809 * AvgReward 65.60 * true AvgReward 65.60 * Reward -93.23 * True Reward -93.23 * time 2.51 * step 180207\n",
      "Ep 810 * AvgReward 67.08 * true AvgReward 67.08 * Reward 31.87 * True Reward 31.87 * time 13.78 * step 181207\n",
      "Ep 811 * AvgReward 56.23 * true AvgReward 56.23 * Reward -224.20 * True Reward -224.20 * time 1.99 * step 181368\n",
      "Ep 812 * AvgReward 48.11 * true AvgReward 48.11 * Reward -160.71 * True Reward -160.71 * time 1.23 * step 181470\n",
      "Ep 813 * AvgReward 71.39 * true AvgReward 71.39 * Reward 209.55 * True Reward 209.55 * time 7.64 * step 182055\n",
      "Ep 814 * AvgReward 76.73 * true AvgReward 76.73 * Reward -51.62 * True Reward -51.62 * time 0.85 * step 182126\n",
      "Ep 815 * AvgReward 53.89 * true AvgReward 53.89 * Reward -196.55 * True Reward -196.55 * time 1.08 * step 182215\n",
      "Ep 816 * AvgReward 40.00 * true AvgReward 40.00 * Reward -76.96 * True Reward -76.96 * time 1.11 * step 182306\n",
      "Ep 817 * AvgReward 43.52 * true AvgReward 43.52 * Reward 257.41 * True Reward 257.41 * time 6.67 * step 182817\n",
      "Ep 818 * AvgReward 43.90 * true AvgReward 43.90 * Reward 267.89 * True Reward 267.89 * time 3.09 * step 183068\n",
      "Ep 819 * AvgReward 27.08 * true AvgReward 27.08 * Reward -65.14 * True Reward -65.14 * time 1.22 * step 183168\n",
      "Ep 820 * AvgReward 36.38 * true AvgReward 36.38 * Reward 2.12 * True Reward 2.12 * time 0.89 * step 183242\n",
      "Ep 821 * AvgReward 26.04 * true AvgReward 26.04 * Reward -248.62 * True Reward -248.62 * time 1.44 * step 183357\n",
      "Ep 822 * AvgReward 26.10 * true AvgReward 26.10 * Reward 10.54 * True Reward 10.54 * time 1.36 * step 183467\n",
      "Ep 823 * AvgReward 20.58 * true AvgReward 20.58 * Reward 157.51 * True Reward 157.51 * time 12.96 * step 184467\n",
      "Ep 824 * AvgReward 38.14 * true AvgReward 38.14 * Reward 292.40 * True Reward 292.40 * time 4.47 * step 184823\n",
      "Ep 825 * AvgReward 60.26 * true AvgReward 60.26 * Reward 274.11 * True Reward 274.11 * time 4.15 * step 185150\n",
      "Ep 826 * AvgReward 60.28 * true AvgReward 60.28 * Reward 285.34 * True Reward 285.34 * time 4.68 * step 185528\n",
      "Ep 827 * AvgReward 59.81 * true AvgReward 59.81 * Reward 239.96 * True Reward 239.96 * time 4.13 * step 185861\n",
      "Ep 828 * AvgReward 59.11 * true AvgReward 59.11 * Reward 270.60 * True Reward 270.60 * time 4.72 * step 186235\n",
      "Ep 829 * AvgReward 79.16 * true AvgReward 79.16 * Reward 307.63 * True Reward 307.63 * time 2.62 * step 186444\n",
      "Ep 830 * AvgReward 92.06 * true AvgReward 92.06 * Reward 289.87 * True Reward 289.87 * time 3.34 * step 186718\n",
      "Ep 831 * AvgReward 91.56 * true AvgReward 91.56 * Reward -234.11 * True Reward -234.11 * time 1.08 * step 186806\n",
      "Ep 832 * AvgReward 104.63 * true AvgReward 104.63 * Reward 100.69 * True Reward 100.69 * time 13.04 * step 187806\n",
      "Ep 833 * AvgReward 107.75 * true AvgReward 107.75 * Reward 271.89 * True Reward 271.89 * time 4.14 * step 188136\n",
      "Ep 834 * AvgReward 124.51 * true AvgReward 124.51 * Reward 283.65 * True Reward 283.65 * time 2.98 * step 188378\n",
      "Ep 835 * AvgReward 147.35 * true AvgReward 147.35 * Reward 260.23 * True Reward 260.23 * time 3.51 * step 188660\n",
      "Ep 836 * AvgReward 163.97 * true AvgReward 163.97 * Reward 255.35 * True Reward 255.35 * time 5.50 * step 189090\n",
      "Ep 837 * AvgReward 153.21 * true AvgReward 153.21 * Reward 42.34 * True Reward 42.34 * time 1.60 * step 189220\n",
      "Ep 838 * AvgReward 136.12 * true AvgReward 136.12 * Reward -73.96 * True Reward -73.96 * time 0.97 * step 189300\n",
      "Ep 839 * AvgReward 152.48 * true AvgReward 152.48 * Reward 262.14 * True Reward 262.14 * time 2.93 * step 189537\n",
      "Ep 840 * AvgReward 165.49 * true AvgReward 165.49 * Reward 262.32 * True Reward 262.32 * time 3.05 * step 189785\n",
      "Ep 841 * AvgReward 189.50 * true AvgReward 189.50 * Reward 231.52 * True Reward 231.52 * time 3.15 * step 190037\n",
      "Ep 842 * AvgReward 202.66 * true AvgReward 202.66 * Reward 273.72 * True Reward 273.72 * time 3.67 * step 190330\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEGCAYAAACZ0MnKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABX6ElEQVR4nO2dd5xcdbn/P8/03Z3tu+kJqQQCBAghNOkdVBRUEEUQlKtGRa9XpXjFclWwceVHUbyioAiiVAHpIKBASEIgvbfdtM1m++z05/fHKXNm9pwzZ2an7e7zfr3mlTOnzPnOyez3+T6dmBmCIAiC4ARXuQcgCIIgjBxEaAiCIAiOEaEhCIIgOEaEhiAIguAYERqCIAiCYzzlHkAxaWlp4enTp5d7GIIgCCOKZcuW7WfmVrNjo1poTJ8+HUuXLi33MARBEEYURLTd6piYpwRBEATHiNAQBEEQHCNCQxAEQXDMqPZpmBGLxdDW1oZwOFzuodgSCAQwZcoUeL3ecg9FEARBZ8wJjba2NtTW1mL69OkgonIPxxRmRmdnJ9ra2jBjxoxyD0cQBEFnzJmnwuEwmpubK1ZgAAARobm5ueK1IUEQxh5lExpENJWIXiGiNUS0moiuU/c3EdELRLRR/bdR3U9EdDsRbSKi94lowTDuXaivUTRGwhgFQRh7lFPTiAP4BjPPA3A8gMVENA/A9QBeYuY5AF5S3wPA+QDmqK9rAdxd+iELgiBUPo8sa8ODS3YU5bPLJjSYeTczL1e3+wCsBTAZwEUA7lNPuw/AR9TtiwDczwpvAWggoomlHXXhePbZZzF37lzMnj0bt9xyS7mHIwjCKOKR5W14ZFlbUT67InwaRDQdwNEA3gYwnpl3q4f2ABivbk8GsNNwWZu6L/OzriWipUS0tKOjo3iDHgaJRAKLFy/GP/7xD6xZswYPPvgg1qxZU+5hCYIwSugZjKG+qjiRl2UXGkQUBPAIgK8xc6/xGCttBXNqLcjM9zDzQmZe2NpqWjql7CxZsgSzZ8/GzJkz4fP5cNlll+GJJ54o97AEQRgl9IZjqCuS0ChryC0ReaEIjAeY+VF1914imsjMu1Xz0z51fzuAqYbLp6j78ub7f1+NNbt6s5+YA/Mm1eHmDx1me057ezumTk19lSlTpuDtt98u6DgEQRi79IRGoaZBSnjQ7wCsZeZfGg49CeBKdftKAE8Y9n9GjaI6HkCPwYwlCIIgAEgmGX2ROOoCxdEJyqlpnATgCgAriWiFuu9GALcAeJiIrgGwHcAn1GPPALgAwCYAIQCfHe4AsmkExWLy5MnYuTPlnmlra8PkyUPcM4IgCDnTF4mDGaPPPMXMbwCwSkY40+R8BrC4qIMqEcceeyw2btyIrVu3YvLkyXjooYfw5z//udzDEgRhFNA7GAMwCoXGWMbj8eCOO+7Aueeei0QigauvvhqHHVYerUcQhNFFjyo0iuXTEKFRJi644AJccMEF5R6GIAijDF3TCIwyR7ggCIJQeIqtaYjQEARBGEX0hjWfRnEMSWNSaCg+9cpmJIxREITKQzSNAhMIBNDZ2VnRk7LWTyMQCJR7KIIgjCBe39iBFTu74SIg6B99eRplYcqUKWhra0Ol1qXS0Dr3CYJgTSSewBMrduH8wyegtkiO35HEFb9bAgBoqPYWrb3CmBMaXq9XuuEJwijhT2/twA+fWoPtnQP45rmHlHs4FUOxTFPAGDRPCYIwetjdPQgAWLqtq8wjKT+xRFLfLla4LSBCQxCEEUy36vTtDcfLPJLyMxBJPQPRNARBEEzoDilCo08NMx3L9BkEZ7XPXbT7iNAQBGHEomU/94mmgX6DplEkHzgAERqCIIxgugejAJQJs5LD6EuBUWgUExEagiCMWPpVDSORZISiiTKPprz0l0jbEqEhCMKIZSCa0J2+/9q0v8yjKS99omkIgiDYE4rG8bFjlCTYtbv7yjwa50TiCfSECuu8N0ZPHTG5vqCfbWTMJfcJgjA6iMaTiCUYTTU+VHndGIiOHGf4Fb9bgiVbD2DbLRcW7DM189SfrjkOJ8xqLtjnZpJV0yCicUT0USJaTERXE9EiIhINRRizxBPJkjkdBWtCqpCo9rlR4/eUPIJq075+fOPh9xA3JNU5ZcnWAwUfj2aeOnFWM9yu4oVPWU7+RHQ6ET0H4GkA5wOYCGAegO9A6ev9fSKqK9rIBKFC+fYjK3H4zc+N+WidcjOgOr5rfB4E/e4080wp+Pz9S/HI8jZs6wzl/RnReO4Cx4r+cBxBvweuIgoMwN48dQGAzzPzjswDROQB8EEAZwN4pEhjE4SK5JHlbQCAzoEoWoL+Mo9m7KIJiWq/ommUWmjsUkuYxHLUNBLJ1GJjIBKHz+MryHj6wrGiVbY1YqlpMPM3zQSGeizOzI8zswgMYUzR0RfRt9u7Bss4ktEBM+Nnz63Duj29OV+rCYkanwc1fk/JTYYRVUvIVVgZx1nIMfeGY0VrvGTE1jdBROcS0d1E9KT6upuIziv6qAShQlm9q0ff1laaQv70ReK485XNuPy3b+d8rZaXUeP3IOj3lM0RnuvEbzy/kGPuGYwVteaUhqVYIqL/BXAwgPsBtKm7pwD4KhGdz8zXFX10glBhGBPI2itUaGzbPwAXEaY1V5d7KFkJx5TnGcpj8tTNU6ojfGB/eZL7ck0qNCbhFdKk1jsYx8T64jdus/VpMPPBmTuJ6C8ANgAQoSGMOYyrxLYKNU+d9vNXAaCg4ZzFYlCdcJN5+IPTNQ13Sc1TRr9Ervc1FlfsjxRO0PUMxnDIhNqCfZ4VduapMBEda7L/WADhIo1HECqakDpBtNb6xTxVALSJP5lHJJpm2qnxuRXzVAmFhlYoEchdWzBmbhey9Ifi0yijeQrAVQDuJqJapMxTUwH0qMeGDRHdCyUKax8zH67uawLwFwDTAWwD8Alm7iKld+GvoER1hQBcxczLCzEOQXCKFuY5uaEKPYOVXY6bmYvW8rNQaEIjkY/Q0KOnFEd4KJpAMslFDzkFlAk6cxxOKYZ5anNHP/rCcRxUApOkXfTUcmY+DsAZAG5QX6cz8/HMvKxA9/8DgEzH+vUAXmLmOQBeUt8DSq7IHPV1LYC7CzQGQXDMQCQOj4vQEvRVZDnupMFsUqpaRMNBM0/lk/IyoJp2qrxuPdS0VM5wox8jVxOT8XdTKJPaih3dAICT57QW5PPscJLZ3cnMy9TXHgAgopZC3JyZXwOQmRp5EYD71O37AHzEsP9+VngLQAMRTSzEOATBKQOROGr8HtQGvOiLVJamsWlfH2be+Iz+fm9P5VuR83GAG6+t8rrhdhFqVKFRKr+GUWjkHnKbv5ZixYEBpUT8uLri5w1lywhvA7CbiJ4noumGw88XcUzjmXm3ur0HwHh1ezKAnYbz2tR9aRDRtUS0lIiWdnR0FHGYwlikL6Jk3dYGSl+2Ihvr9/Snvd/bG7E4s3IYjOXvCB6IJnRhof1bKr9GODYMoRGOgwjwuV3oL5Bm1DkQhddNqC1nch+AnwI4l5lbANwD4AUiOl49VhJDKSt1GnJSXJn5HmZeyMwLW1uLr6oJY4uugSiaany60KikUiKZfoG9vZWvaQwYTDsPL92J5Tu6HF8bisRR41famgbVfwsZjWR7b6OmkcPEz8y4/eVNYAaCgcI5719etxduF5XEh2UnNHzMvBoAmPlvUMxE9xHRR5DjRJ4jezWzk/rvPnV/OxRHvMYUdZ8glIwDA1E01vhQF/AikeRhrZQLTU9IMVF88bRZAICO/srXNIzhp9/62/u4+K5/IxJ39kwHoglU+1RNw1daTUMzqzVUe9MEXzaMFQVq/O6CRE/1DMawYW8/XCUKerATGjEimqC9UQXImQC+B8UZXSyeBHClun0lgCcM+z9DCscD6DGYsQShJBwIRdFc40NtQAltrBQT1RMr2nHrs+sBAF87aw7cLipZJ7fhYPb8nnh3l6NrQ9E4anyKhlFqn4bmwG8J+nO65+aOAX076PcWRDPSBNF1ZxZzWk5hJzSuR8qfAABg5jYApwK4pRA3J6IHAbwJYC4RtRHRNepnn01EGwGcZbjXMwC2ANgE4LcAvlSIMQhCLhzoj6KxWjFPAenx+uUiHEvguodW6JOX3+NGja+0yW75Ygxd1dh+YMDkzKH0RxKoVoVFsMQ+Dc081Rr053TPrfuV7/av689Ard+T5hS3Y0tHvy6oMtGc4PMmlabouKXXhJlftNjfA+BHhbg5M3/S4tCZJucygMWFuK8g5EM4lsBANIHmoEFoVMBqvks1SxmpDXgrRguyI1PoTm6ocpxpH4rEMUktmxEMlFZoaGbJ1lo/tnc6E3IAsHV/P/weFybWBRAMeLCvL7vfKRpP4oxf/BPnzBuPez6zcMjxAwOKptFUU5hqudmwi576OxF9iIiGpBgS0Uwi+gERXV3c4QlC5aBNzoqmoZmnyq9pdJu0DQ3msIotNT2hGHb3DKKtK4TdGWHBkxurHGfahww+jaBuniqNj2kwmoDbRWis9uak0W3dP4AZLTVwuUj5P3Ig2LXf3WsbO9Adig4JU+5UNY3mmtKU6beLz/o8gP8E8L9EdABAB4AAlEztzQDuYOYnrC8XhNGFZgZoqvGhTl3ZVsJqXptUTprdjC+frti1g4HSlwp3ylm3/TPNIWxkXK0fq3c5K5M+EI3rUVN+jwtuF5XUPFXtdeuZ6E6z7zv6Ihhfl9KOnPwfdfYr/79etwtH/eAFzJtYh2euO1k/rv0GS1HhFrA3T+0B8C0A31JzNCYCGASwgZnzb1UlCCOUNKGh/oGu39OHma09OGxSfdnG1aNqGt+5cB4OnajYtWv8nootc5IpMPwel96borXWbylQMgkZfBpEyqq/c6A0EWODsTgCanXdeJIRiScR8LqzXtcbjmNacw0AoNZhi1rtd6flhqzZnS5U+8NxuAgIeEvThdvRXZh5GzO/ycwrRGAIY5VN+5TkuYn1ATRWK/bjO17ZhAtvf6Ocw0KXKjQaqlMrzVq/B/0VYDpzQo0hIa21VolG+uULG2yvicaTiCaSevQUAExqqEJ7d2lyUxTTmFu/v1MNR+l5kTKpReJJy85/7+7owt2vbtYFYSxhnunQryaclqrOWGlEkyCMAl5etw8Hjw9ialM1fB4Xmg2Ox3Im+XUPpnwtGsEydLLLl2rDxD+zJQgAuP2ljbbXaHZ9zacBAJPqnftDhksomkCVap4C4ChXg5nROxhDneoPy+a8/+hd/8atz67DviyZ/X3huO5jKwUiNATBAcyM1bt6sWBao76vtTbleMy1EU8h6Q7F4Pe40swjwYAzJ2sl8JkTDtK3j5/ZlPX8aDyJf25QSgRpGeEAML7Oj30lyoIPxxRNI5hDfshgLIF4knXTpnatmYlqw94+020zBlRNo1SI0BBGPbe9sAFn/OLVYRXHW7u7DwcGopg/pUHfN7mhSt/WnJXloDsUTdMyAMXkM6CWCi808UQSd7+6GfsLkHG+7ofn4fMnz9TfN1T78KEjJ9k6dW/5xzpc99AKAOmaRn2VF32ReFG+cyZa5JbmUxmMZf9taT4m7btpYdtmAmeLIQnw0XetC1/87o2teHb1nrz6keSLXcjtSiJ63+pVshEKwjD51UsbsaVjAO15dtr7r7++hwtufx1eN+H8w/UiCZjcmBIau3vK15CpKxRL82cA0AvXFaNU+Nrdfbj12XVY+D8vDnuCDnjdICKMr/Pjv85RGoVOagikFQTMZM3uVJ92o6ZRV+UFc2ki2kLRBKrSfBrZNc3eQWVcmnnKLovduC+RZMwZFzT9zN/8czOA0iX2AfaaxgcBfAjAs+rrU+rrGfUlCCOKz/7hnZxDMpNJxt+WKT3Irj1lJhoNfoyrT5qBUw5WimIuyyi0969N+7F+j71ZoRC8t7MbL6zZO6RjW9BmFTtcjJ+ZGcmTL2/feBa+fIYSLlztVRzECQuB5DY0WcrUNADzLPNCE44lEPC6UaUKDSfmyUxNQzdtmQi5zPwfoykUSPnQQtEELl04FbdcPD/Hb5A/dk2YtjPzdgBnM/O3mHml+roewDklG6EgFIi2rkH8z9NrcrpGK/p31YnT8Y2z56Ydm95Sg/uvXoTpzdVY2daTduxT//c2zv3f14Y3YAdc9fslAIY64rUJSVvdFhKjKebdnd0F//xqfSI2H7uxMF+dwQGsTcb/3rx/yDXLtnfh3NteK5hAicaT8LldeqFEJ6ZPLfu9To2eSlUVGDomTVu64AhFs83M9ta6FPZH4hhfH9CFVylw4tMgIjrJ8OZEh9cJQsXx4JKd2U8ysOOAEmF+2txWyzaic8bXZnVWFgttMZ5p0p7WpLT91GodFRKjKabHpISJHU7MWdoEaFVrySg0jH4lbWL99iMrhwjR7zy+Cuv39uHOlzehrWv4WQPRRBI+j8sg4LJrGt9/ajWAoeYps2v7wjEEvC60BhUNozlDaHSForrpsRQ9NIw4mfyvBnAXEW0jom0A7lL3CULFM9xQ2O2dygRzkJqQZcZBTdVoN4R6liP8NtMRevD4WhABa3b1WFyRP8ZVda4JhFoSX7XPjT9dc5zpOZqfwmoiNpqntFU7ABw5tUHfDsfScx8SSeX9b17bgst/+3ZOYzYjGk/C73HpjnAnmsbOA8pvRDMl2jWO0sJoNTNjwOvGLRcfoR/fuLdfNxNq55QKW6FBRG4ApzLzkQCOBHAkMx/FzMtLMjpBGCbaJKVBlNukvuNACC5KX9FmUu33IBxL6qvoUvbY0FbjmXlfVT43jp7agJfW7TO5anhomobf48pZaGjP5tvnHYIPzDHvGl3ltV6BA+mahjGhzet24VvnzVWvTZ+IjeHImvY4HKJxRdOo8jrXNDQ0M1q119qJ3heJozbgwQkzlWd0yMRaXLZoGh754gkAFP+cVtixppI0DWZOAPikut2jVrgVhBFD5h8z89BVqB3tXYMYXxeAz2P9p6JNHGG1eVAp61Fpq9ZPLZo25Nj8KQ0FmSAz0Sb+SQ1VeQuNKpuSG9l8Gm71v+Ljx0wZcqxFLdqX+f/eH4njwiMm4tKFU9OyyPMlmkjC6ya4XYQqrztrgEVUXbx84+yDdU3J43bB73GZfk9N0/jAnBYsuelMXHSk0tnaGIq8pUOpUFCJ5ql/EdEdRHQyES3QXkUfmSAUALM/5lzyNfb1hTGu1r56aHWGDd4oNKxKRBQKIuCTi6biE8dOHXKsTi2IV+i8hYFIHB4XoSXoy11oqM8oYDNxZ/MTtHcPYmZLDW69ZGjEkO4PydD2tAS4iQ0BDEQTiA/j/yWRZCSSDJ9buVdTjU+vNGtFt+r7acjwTQT9HtOw6L5wTC+KOa42oPvTZrYEcdwMJQHyjlc2KZ9RSeYplaMAHAbgBwB+ob5+XsQxCULB0P4gL104FSer5pBcTAkdfRG01gZsz9FWzf/xx2VIJjktXLKYTZqYGV0DQxP7NIIBD5gLn6ux40AI4+sCqK/yoifH6CxNaNhpGnZhrDs6Q1jV3osFBzWaBiZYCZz+cBzBgEcvt5FLi9ZMNK1B0z5bHBRZ7FZ/B40Z+TTVfjdCZuapsHmWt8tFuPGCQwGkfCSlzAYHHAgNZj7d5HVGKQYnCMNFmxzOP2ICLjtWMeHclqUYnpF9fRGMq7PXNLRJbun2LuwfiKTlMRSz0mxfJI54ki2b72gT5NfU7OlCkEgy3t3RjSMm16OuypuzUHRintLCWM2yrN/ZdgAA8LmTZ5heaxZ5lUwyBqIJ1Pg9tmGuTomqWorXrQit1qAP+7NUBOhSNZGGqozMfZ+5ptEfjutjzWRITk6lCQ0AIKILiehbRPRd7VXsgQlCIdBMUTV+DxiKmebRd9t1c4Ed0XgSBwaiWc1TxglwT084zTzVneOkurtnEL98fr0jk5I2EVlpGtq4CukM/8O/t6G9e1Av9ZG3T8NnPfVU22RZa1Fqs1rNM6S1ZL9P/vYtvL5RqU9lDE2ttan35BRN0/BrmkbQj84sJVXMKhEDio9i077+ISbTvnDMsghhpjCxEi7FIqvQIKJfA7gUwFcAEICPAzjI9iJBqBC0iafG58E4g5npnW1dVpfoaLWVxmUxT7kMf0V7esJpGb49Jl317Pj6X1bg9pc3Ocq0XqueM6XRPLKrGFrOm5s7Mb25GhccMQH1VUrXulz8AynzlPVEZ5enMRCNw+9xwes2n7p8hv2aRqlpfoqmMfyOi5qmoZmnqnzurBFz2iKlMUMr/OjRk7G5YwBX/+EdfV9C1YyshEFDhqZRUdFTKicy82cAdDHz9wGcAODg4g5LEApDStNwY9GMJrz4n6cCANY5mJQ1O3U2TcOYdb23N5xm+tDKljtFu+f2zpBt/SVAEXwBrwvHHNRoevyMQ8bldG9H4+uPYGpTNYjIULbD+apdMznZNQyq9lmH3A5E4raT5OxxQcxsVXJq5oyr1a8BoPo0smsa4VgCOzqto84yfRp+j3tIaHcmVj6NS4+disMn16GtaxA7OkPoCcVS+RcW39PjdmHzjy/Q31sJ0GLh5G5a1lKIiCYBiEHp4icIFc+AOvFoE9HscUFMbarCBrWhkh2r1MS4CfX2msZZ88brNah2Z5incnW4ao12Fv95Of7z4RW25w5E4qgLeOGxmDSmNlXjiuMPGjJRDYf9fRG9DpK2as+lBLsmFFtsBLHbRQh4XXjq/V1D6ncNRBJpRQoz8XlcePkbp2FGS41ultL+P4J+t21lWY27XtmEU372CtZYtJ3VhIY2Wfs9LkTjSdv8n65QFD63a4gvh4iw8KAmtHUN4pSfvYIfPbNG14LqbHpkuF2EM4uwKHCCE6HxFBE1APgZgOUAtgH4cxHHJAgFIxRJaRoaB4+rxavr92U1qzy3ei9mtNRg3kT7CqJBvwf3X70Ik+oD2NMbTpuQrEphWGEM0X1xjb0vIqQ6d+1orPGhezBmWfwvG5s7+jHjhqexuaMfzKxEk6mlLTRtIRJ3/h3buwZRG/DYTogA0Fzjx8Z9/UPqd/VH4rqj3I6mGp/eO10T3EF/KsPazjy1ZrciqN7a0ml6XNc0NKGhPwfr31P3gFKJ2Ky7Xp3BDPWPVXt0IZfNV3HPZxZiw/+cb3tOMXASPfVDZu5m5keg+DIOYWZxhAsjgt5wTFm5elJCo6nGh75wHA+9Y1+HakfnAOZNqrOsOZXJ+PoA9vaG0ReOoSVonmRmBzOnaSnZyl2HonHbKCQAaKpWyoXn6994bHk7mIGn3tuNiNpitV7VXPzqM81mmjHS3h3GpHrr7HoNo/nKmGsTitqbpzSmNlbh/bYedPZH0B9RvnvQnxJWdiY1bbLe3mlet2vLfkVLnaRWCdCfg03SaPegdWi0MRrK2Dc8W/6F20W2SafFwokj/A0i+hERnQfAJ1nhwkhiX6+yMjZO/FeoneJ22hSuu/eNrdjWGdIL/zmhsVpJduuPxNFY7YXP7XJcUuT3/9qKj971b/RH4lh8+izU+j1oCZpPMhqKpmEvNDTH64EsyWdWaJqP10NDbO1a9FAumkZ3KIrmLN9LOS8l5Iw5EP2R7NoVAHz5jNnoj8Rx35vb8fPnN+jjVpzoZOvT0I49s2qPaXLmyrYe+D0uHDJB8Zk4eQ5mPU80jFrXrp4wfviUUom5lC1cc8GJmLoCwHoAlwD4NxEtJaLbijssa4joPCJaT0SbiOj6co1DqHzufnUz/rqsDeMz8izmT2lAjc+NeGbBJpW+cAw/fW4dJtQFcMmCoaUqrKgNKKvEPjWRrMrnxqCDxLpV7T34/t/XYIVaZvzDR07GoRPrsvpDBqIJVGUx1Wg5HF05VqPV0COF3C7dd6GZh7R6TrmUZenP4sjWONfQ7GqfQWj0DsYchZjOHleL1qAfd7y8EZtU/1Uw4AERoTbg1bUPMzTTVUdfxPS59UfiqKtK+ZJSQsNG0whFrYVGRjTUynZlXV7qUFqnODFPbQXwAoCXALwGoBrAoUUelylqAcU7AZwPYB6ATxLRvHKMRah8bn12HQCgOTjU6WqXY7CrO4xwLInvfPBQzLbomGZG0J8SGrUBL6q8bkfmKaPD9defPgZzJ9Si2u/OmskdisT1ondWaCaRfNvRGp2+mVVV89E0+iNxR7WSvnPhobj/6kUAUqHPzIzdPYOYWGcfmKDRHPTD6MrRfAdBv8e2z4hRCzHzSSkNmFJTpyY8s2kaVuYpY4MlY12sUteUcooT89RmAI8DGA/gdwAOZ+bzijwuKxYB2MTMW5g5CuAhABeVaSzCCMEsvLPORmhoq0urP3IragNe9IfjSmKW34NqnxshB+apNjVhbdH0JpynrrBrfJ6sRfBC0QSqs5inhtvNTjPPROPJVOiqZp7SHMA5ahpOaiVV+zyY0VKjXwMoJqtwLImJNhWHjWQGlWmawZTGKkt/hXY/zVdgJvQHY4k0X5ImPK00LmZGTyiGBovfkzGk++YPH6Zvj2Tz1O0AdkCpdvtVAFcS0ayijsqayQCM3ss2dZ8OEV2rmtCWdnR0lHRwQmViFm1jVwKj2yJ7Nxu1AQ+iiSQ6B6Ko1c1T2YVGe9cgJtQF8PAXTkiN2e92YJ7KHkmkh5jmmQGtmfBC0YSu+dToPo306r7ZYGalBpTDFXRmIchdah/2SVlCoDVaTTRMAJg3sQ7r9vRZRpT1hmO6SdNMaIRjybRS636vfUBAKJpANJG0/D0Zy9QY/z/tclnKSdb/PWb+FYBfEVEQwGcBfA/AFACl6y+YA8x8D4B7AGDhwoWl74YjVAweFyGeZNMKsPVVXuy0KBt+xysbAcByZWiFNkF3h2IIapqGA5/Gpo5+PSFNY0JdAPv6whiMJkxbeWqRVsYmRGbYNfpxgiYQBmOJtHwHwBBy61DTiMSTiCfZcVVWLbfm5idX45Hlbfiq2kPcqabxo48egT29Yby2oSOt892khipE4kn0hYeu/pkZvYMxzBkXxM4Dg9bmKc9QTcPKPJXSXM2Fht/jxqePn4az501Ia6ZlFp5bCTgxT/2CiN4G8DaA+QC+C2BOsQdmQTsA4wwwRd0nCENorfXjY8dMwbHTm4Ycqwt4LSNoVrUrPoZck+KMjsvagBdVPk9WTSOZZGzc24eDx9em7Z83qR5JBtbtMU8wC0UTSCQ5qwnDq/ZssEtms0Nbaf/6n5t1IRv0p4fcXv/oSkefpY3Bqa3ebwgnfb+tB7t7wwCAiQ41jUkNVVgwrRFfO+tgXHHCdH2/5ng2+/8fiCaQZGCCGhZsFv0WjifTSrvrjZgsNMOU5mq9CPmfjxyBUw9uLXnxwXxwov+8CeDDzHwYM3+eme9j5i3FHpgF7wCYQ0QziMgH4DIAT5ZpLEKF0zMYS2taY6S+yovOgQgef7c9zUyhbU+oC+grXafU+lP3CgY8qPZmr0nU3j2IUDSBuRPShYYW6runJ2x6nTbhZUuSA9SornyFhmEifOxdZX2mhfn6c8wR0KOvHE6MLrXBkcbu7kG1j4d9WZdsaMLdzKelmSwn6Oapoc8tHE0gYPjumuZkFbigCw2L36KR6gI0iCo2Tv7XHwVwNhH9NwAQ0TQiWlTcYZnDzHEAXwbwHIC1AB5m5tXlGItQ2cQSSYSiCctJta5KadH6tb+s0CdDIJXP8MXTcnfbBdM0Dc08ZS80tDIZmZpGY40ybqsquZpjO5t5ClAb/eQrNGJx3VGrVWrNDLl1SraaSmYYk9fau5Uuim6HyZZWpBL8TISGum+8GqFlap6KJ9K+e7bKuVp4rxPHtpNs93LjRGjcCaVI4eXq+z51X1lg5meY+WBmnsXMPyrXOITKRlsx1ltMqsaJy9gSddl2pfptZm6HE4zmqbqABwEHjnAtwXB6c3oSoRa5ZZVfoeUSOJmIggFP3o7wUDSBI6c2AFAEarXPrSdKul2EL502y3HfdaeZzkaM2sD6PX2Y1ODMNGWHXdFCLRRXExrmjvD06KlglnpW/XoZk+zfWxNGTp395cCJ0DiOmRcDCAMAM3cByM1DKAglRisTkZk4pWFcwd7+0kZccve/sW5PL77wp2UAgJPntOZ8T6NWE/R7Ue0gT2NPbxheNw1ppBTwuuH3uNIyo41o+63Mb0ZqfMMzTzVUefXnlTnx1VcpZUqc5KOkfBr5hZKu29OHiQ5KkGRDD0O2MU9pfhMz8+JgND1Po8rrhousI9QGTOqfWTG+zo//OGUm/vS547KeWy6cCI2YmlTHAEBErQCK2/hYEIbJbjX3wWpS/fgxU3HPFcfgd1cuBKBoGH/41zYAyh9uPj0KjJpGc9CHarXPgl1DpX29EYyrDZhGylT73LjntS2mdnUtWa/Zomtf5rjy1zTiqPa50xLjjGRbZRvRa0DloGlcdeL0tH4hC6ebl4HPBbv6U5p5qiXoh4vSfRrbOwfw7b+9j141eVODiBD0e2w0Dee+HCLCDRccipkWTaYqAad5Go8BGEdEPwLwBoCfFHVUgjBMvvrQuwCsNY0qnxvnHDYBZx46Hl89UwkG1JoaPb74pLzuqU0kR09rwKET6/QSH3Z5DDsPhCxNLleeOB0A8Or6oflGHWqWtBOncNDvwZrdvZh+/dN6drUTmFmvpKt9t8wJP5jFnm8kFzONxvc+fBgeMKy6P3L0ZJuznWFX6TZl1vSi2ufBYDS1Pn7onZ34y1IlTWxo9zyvpdAYiMThcVHOgQOVipMyIg8A+BYUQbEbwEcAPF3cYQnC8NCcpYdmKWsOAPMn1wNQzB+LZjTlbQJxuwhbfnwBHvuSInQ0c8Tj7+4yPT+eSGL1rl4cNqne9Pjlxyk9zc1aiXb2R1Hjc5vmcGRiXOEuddCxUMPYg1wTbJnObzuncibdapBBrjWVtH4mDdVeR9Fi2XC7yLKUSK+hLLnSkc9cEJj16bYzT9X4PRWbd5ErtkKDiCYT0UIAW5j5TgAPQylguLEUgxOEfGms9uHseeMdrWq1CSASTzrOAbDCWE33g/MnAVB6Upixry+CwdjQcFt9XFprUpMV7KpdPY6T3IzawRf+tMyR0xpI70F+4wVKubk5GbW4tLpJxkq0VuzpDaOx2ptz1JXf48a9Vy3E8187Jafr7KgLeMyjpwZjqPG54XG70qLfVrX34N+b9uvnZQq+Gr/b1hE+EvIvnGIpNIjoawBWAPh/AN4ios9BCXOtAnBMKQYnCPlyYCCKJocZ3cYJYILDYnhOaKrxYfa4INq7Bk2P645hi5W33+OCx0VDVrCD0QSWbD2ACwyVYO3ITKbb5KBrIZAKP26q8eGwSfV48PPH46YL02uVakJjnxOh0RPWo5Jy5YxDxmNcAf9vagNeU/PUgVBUT8IzFpz88B1v4L22nrTrjQQDXstgA0XTqPz8C6fYaRrXApjLzCdAMUndAeAcZv46M+8uxeAEIR+YGV2hqN5LIhtpQqPAoY4T6wN4dvUe/PGt7UOOZctbICIlXDZjMmrvVsJ0ZzmswJs52W7MUWhoz/GEWc1DEh6ba3wgyq5pdPRF8NK6fWkVXctJXZXHNDJtb29YD7fWaoeFonG9Wu5Js5sBDK0WUOv3oN/CRDfgsHHUSMFOaISZ+QAAMPMOAOuZeVlphiUI+TMYSyCWYEfhqAAw2WDmKaSmAaQE0s1PrEJvOJaWZNcfthca2rFMJ/NOVXOZ7NA89bEFU/DHa1L5uDssam5lomkPds2gPG4XpjRW4faXNmJHp/Xntqn5KKfkEcpcDKY2Vps+hz09YX3hoNUO27ZfOe+Oy4/Gn645Dk995QOYP6Uh7Tq76KmBiPMijSMBO6ExhYhu114AJma8F4SKJNUT2plJgIhw/EylPlUu4aBO+M+z5wJQzCvzv/c8Trr1Zf1YZn8KM8zMKBvULPLpLTVmlwzB5SI9QQ+AZaHGTNq7BuGi7IL0mpNmAABeWLvX8hzt/8Q4jnIya1wQu3vCQzLl96oh0IBingrHkugOaeHNfhARDp88NHDBLoFyIJIYEZneTrH7Jt/MeC9ahjAi0GLrc6kd9fmTZ+KtLQccRVvlwuxxQcxsrdF7TxhNInr8vs04m2t86MhooLR8RxemN1fnVIPJeA+n/cLbukKYUBfQ+1BYcdVJM/Cb17ZgZVu35Tn9OSS4lQIt4KGjL6KbjhJJRn8krpcw93vciMQT+vOyK5Uf9HswoBaRzCxz0h+JZ+17MpKw/LUy832lHIggFArNeZnLBHXmoeOx7ZYLizKeap8bT7+fcgMqnd/c+srULgR1alMVXliTWsEzM3Z1hx1rGRpuF+H68w/Bz59b7ygRb8PePjy7eg/OmefM2T6rNYitNuapfOpOFRNtHMZnoRUcNDaZCseSev0vO3NnraFoYWZY8EB0dJmnRs83EQSVfDSNYlLtTR9HdyiGCfVu7OuLwOsm2/pRUxqrsb8/im37B3DtH5dix4EQqrxuyzBdO75w6iy8tqEjayIeM2PxA8uRZOCb58519NnTmqvxj5XW8TEDOWRFl4KgSf0pbYzVhoKMuWgagOKnGiI0HPZFHymMjhRFQTCg2c8rxRQSTaRX3dHyA9q6QpjUUGVbtfUDs1sAAOfc9ho27O1HOJZEVyiWd3lwJyVFtneGsHFfP64/7xBMbaq2PVdjUn0AXaGYZSOiStM0tPpXaZpGhgnN73EhEkuiZzAGrzu9THsmVuVU4okkYgm2vXakIUJDGHVUmqaxrze9J0afLjQG0+oqmXHk1AZcdeL0IYIn39BVq/wEI1pUkZnD1wptJW1V1XcgEoe7gkpppCZ5o48pvcxJwOtGOJ5wlNFtZu4CUguGSvnehcBJ5777iKjB8L6RiO4t6qgEYRhomkalNLTZkyE0tPIVvSbtRs24cP7EIfvm5emwD/o96BmMWfbHjieSern2yVkEmhHtWQ9YCI09vWGMq/VXTCkNozlJI9OE5ve4EEsozvHqLJqCVS92rRWubywJDQDzmblbe6OWRj+6aCMShGHSm0OviVJw39WL8F/nHIyXv3EqgNT4wtGEI7OFmQP2yKnOtQAjx05vwkA0gVk3PmMaRTXv5udw02Or4HERxuegzWhaXcjCyd7eNeg4r6QUmHXvyzShaeVOukOxrDW+tBa4mf6ilKZRGQuYQuBEaLiISK9HTERNEAe6UMFoE0FdgXMu8uXkOa348hlz9BpXWiXVcDyZ1pfBikyhoVVgzWssB7fo28+uSndcJ5KMaFyZ5JpqfFlDbY1ofgCzvhrMjF09gzlpLsUm4HVjXK0f2ztDet6KZtY0ahqA1nzK/nlrTvLMplna8xxNmoaTX94vALxJRH8FQAA+BkA65gkVS89gDLV+T06TXinQVrdaJdXBPDSNFd89G95hfC9jZM/K9h5cemzqmNHX4aSWlBFtUs3sk/3S2r245r6lAIAzDxmf63CLyszWGvx1WRv+uqwNt3/yaN2noQlATdPoCkWzJjhalVPRAgNGk9BwUhr9fgAXA9gLYA+Ai5n5j8UemCDkS08ohnqb8Mhy4fco3fh6wzEw85Be01Zo51yyYAoaqn3DDt/87EnTAQAb9qbXoDKWCr904dScPlPzaYQi6ZrGc6v36NtOyriXklmGRkfLth3QfRop85RR07Afu8ftUhMxM4WGqmlU2AJmOFj++oiojpl7VXPUHgB/Nhxr0upSCUKl0TMYc1x3qtTUVXnROxhHJJ4E89D+FFas++F5w9IwjNz8ocOwpyc8pNqtZtb79acX4NzDnCX1aVhpGlpJDgBZncmlxig0GIoj3EXQtT/ND9EXjjsyB7YE/djXmy40NPOU34EZcqRg9yT+DOCDUMqHGEMtSH0/s4jjEoS8CMcSWLGzG4tmNJV7KKZofRy0qBqn8fu59qDIPg7vkH4SmtBoqsk9ykkz6WSG3BpDTStN05jZmsqqT7ISJVXjS4XWpvUBdzD21lq/pabhHwuaBjN/UP13RumGIwjDY+3uXnQORHHRUZPKPRRTagNe9A7GMBhTJtdCCwOn1Fd7h0RPvbaxA24X4aBmZwl9RlKaRrrQML6vlLwZDaOmMRhNIupKppn+jBFPTsK3W2v92NIxkLZvTDnCiWiB3YXMvLzwwxGE4bFerQA7b2J+IanFpq5KmazDqtCo8pVnMqkLeBCOJRGJJ/TJccnWAzh2emNejZJSPo1081TIYK6qlAx9DWMI8IGBCKp9nrQx5qppjKsNoKMvAmbWtZUxJTSgRE0BQADAQgDvQTFNzQewFMAJxR2aIOSOlkhXSeGdRuoCHrR1hXTbf7nKS2jhv92hGMbXubF1/wBW7OzGFccflNfned0u+NyuIZqGMUO6UhL7NFwuwuOLT8J3Hl+JAwNRJDm9zEmapuF14tPwIZpIoncwrgdi6OapsZCnwcynM/PpAHYDWMDMC5n5GCiJfe2lGqAg5MJAJI4qr9u2nlM50RzhWkhruTrZHTxeKXioVd89/eevAgAOn5x/afhqvxuDGY5wYzRVT0YOQyVw1NQGHDyuFvv7o0MKCxo1DSfmKe3aUCz1DKKJMRhyC6Xl60rtDTOvAnCozflZIaKPE9FqIkoS0cKMYzcQ0SYiWk9E5xr2n6fu20RE1w/n/sLoZSCaqDgziBHNAb23R9GI8u2ZPVyOn9mMqU1VWLo9PQjytLnj8v7MGp9niKZxYCCKueNrccmCKbjo6Ml5f3Yxaarx4cBAVHGEW2kaDn5TmpAJx1J1wsI5BjyMBJx4pt4nov8D8Cf1/acAvD/M+66CkvvxG+NOIpoH4DIAhwGYBOBFIjpYPXwngLMBtAF4h4ieZOY1wxyHMMoIVXgZ6tqAB9F4EtvVLGRjSGqpOWpqI97cvB/ReBIHNVdj3sS6YQmxKrU9qpFdPYNYeFAjfvGJI4c73KLRHPRjMJbA/v5oWhMuf46aRkAVMpq/CkhFk40moeFE0/gsgNUArlNfa9R9ecPMa5l5vcmhiwA8xMwRZt4KYBOAReprEzNvYeYogIfUcwUhjf5IouKidIxovoSNe/vREvSV1Wzx4SMnYX9/FEu3HcBAJIHGmuzFE+2o8bn1rGpAKUuypyeMSRVUc8qMZrUH+v7+SIYjPLVd5cCnoZ2fJjS0KLkyBTwUg6xPgpnDRHQngBeh5GesZ2Zn/SJzZzKAtwzv29R9ALAzY/9xZh9ARNcCuBYApk2bVoQhCpVMKBpHTYXlAxjR6mFt3NdXNtOUxlFqv+51e/oUe/4wn1tjjQ/7DXkKHX0RxJOMiZUuNAzCMt08lZumoZ2vOb8BRYC4aHRlhDspjX4agI0A7gBwF4ANRHSKg+teJKJVJq+iagjMfI/qtF/Y2tpazFsJFYji06h8TWN7ZyhrPaNi0xL0oSXox7LtXRiMDV9Dm9RQhV3dqTLwu3oGAQCTG8r7PbPRbGhoFU+k8piNE70TP5nfTNNQ64tVWuTYcHBasPAczZyk+hgeBHCM3UXMfFYe42kHYCx6MwWpSC2r/UKF8ut/bkZtwINPHZdfGGc+DETiFT1JGSvvljssmIhw9rxxeHCJosQPt6ve5IYqHBiIKhOlz41d3YrQmFhf2ZqGUXifNLtZ3zZO9JktXM0wc4QPxhIVlwk/XJzoTF6j/4GZNwAoVmGfJwFcRkR+IpoBYA6AJQDeATCHiGYQkQ+Ks/zJIo1BKABbOvpxyz/W4abHVqE7h1DLe9/YikeWteV935BaCqJSMU4+x04vf6kTzUQFDL/MxyRVWO9WNYzdqtZR6T6NCfXKuImAMywq8dY5qGWm+TSMLW8HY86KUo4knPx1LTWJnlo6nJsS0UcB/D8ArQCeJqIVzHwuM68mooehONvjABYzc0K95ssAngPgBnAvM68ezhiE4rJhb5++veNAyFGHuk37+vCDp5SAuEuOmZLXfTPDJisN4+QzzWH/7WIyd0IqWqhhmJWBNY1iV3cYM1uDaO8eRI3PXTF9Tex449un2+b2ONE0NJ+G0TwVjjkrfz+ScPK/+UUAiwF8VX3/OhTfRt4w82MAHrM49iOY9Otg5mcAPDOc+wrFozccg8dFul18s6EGz8r2Hsyf0pD1M15Z16Fv7+sL5xyO+j9PrUFvOF4xbV7NME4+lTDOSfWpZ9zkQLDboZXl0MxSu3sGMamhakTY86c02gtwJ82yUtFTBvNUdPRpGk76aUSY+ZfMfLH6uo2Zc+vQIox6FvzgBZz/q9f195qJAgBuemxV1uuZGQ+8vV13Pv757R05j+H/3tgKoLJLNuRaz6jYGJ3Aww25HVenfNZetZTLnt6IbvoZ6TgRfDUm5eFD0URFLA4KiaXQUM1EIKKVRPR+5qt0QxQqnUg8gXiSsb0zhLjaE3lPTwRz1VIVTmjrGsS2zhC+88FDMaWxaki10FzHU6kYJ59KyCcxmmSahik0/B43gn4PukJKRH7vYMyRWbKS+f6HD8PFC5xlsge8Sv0tY/XgUIVH8+WD3be5Tv33g6UYiDByMU7wHf0RTKyvwp7eQUyoD+DoaQ14Zf2+rJ/R1qVoJrPHBXFQc7WeMe0UTVgB6eaBSqZSVqALpjVg+Y5uNBZggm+o9up9snsHYyPCn2HHlSdOd3wuEam1xVJCYyAax0G+8vuuColdPw2t6/x+AIPMnFTDbQ8B8I9SDE4YGRhNUXt6whhfG8CWjgEsPKgJSea0ZCcrOgcUi2dL0I9J9VV4bWNHlivSCRmcj0lmmzMrB3+FFLH76xdOREdfpCDZ6U01PnSFomBm9IZjjqKORhP1VZ40TWMgEh92KHOl4eRX8hqAABFNBvA8gCsA/KGYgxJGFrt7Uglde3sj2LJ/AKFoAodOrIXf49K71FkRjSdx/5vbASjZuePq/NjfH0Uy6Xzy16qpugj46plz8vgWpadSHMRuFxXM99BQ7UPXQBThWBKxBDuKOhpN1FelN7cKVXhZm3xwIjSImUNQCgzexcwfh1JQUBAAKNqFxrbOAfzxzW3wuAgnz2mF3+NGNGEvNH7yj7VYslWpttpQ7UNr0I9EknUzhxM05+Ntlx41bNu8kD9N1V50hWJ6K9naEW6eyhWj0GBmDETjFV11OR+c/I8SEZ0AJT/jGnXf6HoKwrA4MBBFU40PTTU+/P29Xdi0rx8XL5iMSQ1V8HtcSCQZ8UQSHov6O/9cnzJFuV2EVjXUdl9fJC26xw5N0xgJq7ovnjYL/97cWe5hFAVN09AWEs1jTIDX+D26Py4STyLJI+M3mQtOvs3XANwA4DE1+W4mgFeKOiphRNGjOjznT67Ho+8q1V200iE+QxE3M6GRTDK2dSqO9B9cpCiwdVXKz7I/o3WokbW7ezGlsQq1qvlD0zQquVihxrfPO6TcQygaTTU+9EXiWLq9CwAw35BxPhao9rn1BcyA+vsdbZqGkzyNfzLzhwHcTUS1annyr2a7Thg79AzGUF/lxczWGn3fDHXbrPKnkVAsgSQDN15wCD5zwnQAqaiiwah56Gw0nsT5v3odV/3+HX2f3rdgBAiN0UyjmlW+dncvvG5KSx4cC1T7PPoCJhQdOdpvLjipcruQiFZCaby0iojeIyLbYoXC2CEcS+D1jfvh97ixaEaq2JvmANUqf0YthEZqNWZss6kKjZi50NhxQNFMlqmrWSCVmzHasm9HGlqC4O6ewVFX3dUJ1T43BqMJ3Z8BjAztNxeciMB7AXyJmV8HACL6AIDfA5hfzIEJI4NnViqR2Uu2HcCiGU249ZIjsPNAKgQ3pWmYCwDNBGUMS9Rq9VhpGmaJf5omUylhrGMVLddjV3d4TGp9NX4P4klGNJHUF0TVoyzk1sm3SWgCAwCY+Q0isjY2C454+v3d+M+HV+DDR07CTz82f8SuyDQN4nMfmAEAuPTY9MZXvizmKV3TMKjwmjpvpWkcGEhFVTEziEgP6/WLplFWNKGxdf8ADmoeXUltTjAueAZU38Zo0zScLMv+SUS/IaLTiOhUIroLwKtEtICIFhR7gKOVZ1fvQSSexF+XtWFHjtnPhWZvbxid/fmVE+voU6775nlzTY9rdaCscjX6TcxT2TQNYxy8lv2taTKiaZSXxppUXkaggmuAFQutr/jL6/bp/dJHm0/DybfROsLfnLH/aCjtX88o6IjGCB5DzR8re38peGntXlxz31J4XIRNP74g5+t/8cIGANZFArVJPJowFwDaasxontL6KVtpGloOgLZd5XOLeapCMJYisfr/G81o3/+Bt3fg8kWK1j3aMsKd9Ag/vRQDGWv0hVMWvj6b0NJsdIeiqK/y5mXeemjJDlz/6EoAQDzJuqnHKVrfALu2pbpPw0LT0FdjhrBEn9sFFznTNHoHYxhfFzAIjbG3uq0kjIEI+/rCNmeOTs6ZpzRxmt0aNP1tjwbsqtz+r2H7uoxjfyjekCqLmx5bqTt7h0s8kcT065/G9Oufxsr2bn3/xXf9G9fen3tfq037+nHUD17Aw0t35nxtMsm6wNDY3pmbmUybvL9y5mzLc7L5NPRQWcNkQ6T05bDUNAZTQlarqBqJJUAEeN0j0zc0mnjkiycCGDmFIwuJx+3C7HFB9EViGIhqPo3RpWnY6fKnGLavzDg2JiKn+iNxPPD2DnzpgeUF+TzjCnlvbyQtW/b5NXtz/rw1u3sBAP/ckFtxPyBd09HQEvOc8NLavXj6fUWYNlRZZ/3qPg0LoaFpK5mhsgGv21Jo9AzGMK5WyRR/b2e3/vl+j2vEBhSMJg6bVJf9pFFMbcCDvnAcoUgcRM4aOI0k7L4NWWyPGdbv6ct+Ug5kTtRfOSN9hc45Vme1mnCdYKzrtPy/z8ai6U14aa1zwXXNfUv11qx2bUI1x6BVyK2VL6LK57I0T/WGY5g7oRYzW2rw9tYDuPXZdfjNa1vENFUhaL/HWYZkz7FE0K8Ijf5IAjU+z6hbyNjpTS4iaoQiWLRt7duPib9OLbSzUP/nRgfuuh+eh0SS8b2/r9H3DUQTOTnN+lUhlI/Q6Fa1nt9duRBNNT5Maghg2Y6uLFeZY7eSypYRrpkwMr9DtddjLTQGY5hUX4XWaX68tmE/XlSFXSFKewuF4a0bzhx1tnyn1AW82NU9iFC0slsP54vdDFUPYBlSgsJooxkZDQuGiWYeKVR7BqMt3myi7wvHchIaT6xQzEleV+5SrVvVNDQtoTbg1TWhXB3iR0xusDyWzacRjifgdVNaBzkACPjszFNx1FV5MW9iLR5dnjKpdedQFVcoLqOlzWs+tNb68fTKAWzuGMCMltGnbVkuzZh5OjPPZOYZJq+ZpRxkuQhbrHTzRdM07rt6kfnxwdyiqLbsVzKjV+/qRZ9Bi3FCZ78ywWohgnVVikq9cW8fZtzwjK2pKmYodX7tKTNtV/iaycgqrDgcS5jG81d5XbYht3VVHiyc3pQxrjGxlhEqnPMOn6Bv788z/6mSEX3eBuOkFS5AzLlm7jp4fFDf99NL5uOk2UrNpt++vgXfe3I1Eg6aD8USSV0zWLq9C0d87/mcxqJ125tYXwVA0TQSScYLqrB4dtUey2u71YilDx05CddlaXiUrYxIJJ40zeKu8rqHmKei8STCsQSi8STqq7w4dGIdfvzRI3C++kd65iHjbMciCKXg+JnNeOxLSgSZWcDJSGd0xYIVGKPQWLO7FwumNQ7r8zbu7UONz43xtSnV/RPHTsVZ88bjhJ+8hL8tawOgxHqfOLvF9rO0iTttvNFE1no/G/f24e5XN+uRUtr5WoHBnz67HgCGmIuMvLJO6fn94SMnpWVym5EtTyMcS5j6RJSQW0WwxRJJPLtqD77y4Ls4eloDAGBak1Ki4vLjpuHy46Zh/Z4+TGmssh2LIJSKo0ZxSXjRNGwwrnQvvuvfw/qscCyBF9fuw2GT6+HKmJCbanz4/VXH6u9Xtvdk/byX1ykawVWGxveb9vVjVXsPbnpsJeIW3fLu/dc209DazDDJzDFqMDPufHUTmmt8jlb2RASf22Xp04jEkqb+nYBB07jzlU34yoPvAgDe3dENADg6Q4DPnVCbVYAJQqkgIvzxmkV4fPFJ5R5KwSmL0CCinxHROiJ6n4geI6IGw7EbiGgTEa0nonMN+89T920ioutLMc5Mk1SuIbFGnlu9B+3dg/jSabNMj58wK1VW3Ikd9Pf/2gYAOHJqvb5vZ1cItz67Dg+8vUOPKMpk+fYuHDu9EU8sPgnv3XyOvv/IqQ3Y+pNUGRGPhdB4Z1sXtneGcCAUtRQsmfg9LlufhlnpjypfyqexYe/Q0Oex1hFOGHmcPKd1VGoceQkNInpqmPd9AcDhzDwfwAYonQFBRPMAXAalB/l5AO4iIjcRuQHcCeB8APMAfFI9t6gMxhJpk+dwyn28teUA6gIenDKn1fQ4EelZ0Uu3d+k1+a2Y1ar4RT5y1GRdEH3pgeV4feN+AMD7bUO1lT09Yazf24czDx2PI6c2oL4qPb/CGDHlsoie2rq/HwDwo48cYTm2TPxel71Pw0RoNFT50DMYQzLJiGc4uD0ukhpTglAm8v3L+/xwbsrMzzOzNgO/BWCKun0RgIeYOcLMWwFsArBIfW1SuwZGATyknltUQtEExtX6ceslygRp5dT6+l9W4L/++p7tZ63Z3Yt5k+psV+fv3XwODplQi3d3dOPQ7z6LGTc8Yyk4QtE4jphcDyLCt847ZEgZ6j++uT3Nob6yrQc/fmYtAOC0ueaCCwA+ctQkANaO/+2dIXhchE8snGJ63Ay/x21pnorGk6ZJeS1BHxJJRvdgTNc4Fqj+jGrf2GvuIwiVQl5Cg5kLU4xJ4WoA/1C3JwMwFlJqU/dZ7R8CEV1LREuJaGlHR+7lNYxokT1Bv7Iiv+PlTYgllAier/9lBbapIa+PvduOvy1rSysTksn2zgHMHhe0PA4oOQ1Xq30pNH7yj3Wm54aiibTEoQuPmKhvz2ypQV8kjjW7lDIjiSTjQ3e8gSff24UJdQHMHV9rOYZffOIojKv146F3duKGR99HMiOSq6Mvgpag37Tft933sjJPRRJJ05Dd5qBSJmR/fwSD0QROnNWMg5qVmPfRVjVUEEYSTtq9rlR9D8bX60R0GxE121z3IhGtMnldZDjnJgBxAA8U5usAzHwPMy9k5oWtrdYraifE4kn43C7UBpRJ6sElO3D9IytxyH8/i8febcd1f1mB1zemBNOWjn7Tz+kLx9AdimFKY/amNJ9YOBVnHZpyMN/z2hbTpLVModGk2vhPm9uKX1+hdOPd1NGnrNYN158wq9l2le52EcbV+dXvuxMzb3wm7XuFYomcM339HhvzlIVPo0UTGn0R/btq31cc3oJQPpwsF/8B4GkAn1JffwewFMAeAH+wuoiZz2Lmw01eTwAAEV0F4IMAPsUpG0w7gKmGj5mi7rPaX1SiiSS8HkIwkJqkHlnepm+3HQjhit8t0d9v3Z9qQ9ozGNO70rV3K6GjkxuchYRmdr9bs6sXn7vvnTRNJhSNp7WR1CKQmqp9mN5cAyLg6395D7NufEavBHvirGZ8/6LDst7/t59ZmPZ+7e6UI3owmsi5aqciNCzMUxaaRmutIgT3D0QxGEugyufRNYxkoVL0BUHIGSdC4yxmvoGZV6qvmwCcysy3Apiez02J6DwA3wLwYWY21uN+EsBlROQnohkA5gBYAuAdAHOIaAYR+aA4y5/M5965EEsk4XW7LDuQdQ6kawAvrd2HM37xKnpCMRz5/edx6s9eUc5Ts69b1cqs2cgMZb3p8VV4ce0+PGdIuAtFE2ltJLVJeVpzNXweF5oMzXC04oRfOHWWno9hh5bwl7pXPG07197Pfo/bMk8jGrcwT9WkNI3BaAJVXhdOOVjRHDeb9AgXBKE0OFkyuoloETMvAQAiOhapgoX5hhPdAcAP4AXVVPIWM3+BmVcT0cMA1qifvZiZE+p9vwzgOfXe9zLz6jzv7YjH323H6xv347gZTbq5JhtPq303Xt+kmKz2q8Li1mcVv0STwzBRl4vw1g1nYu2eXnz29+/oGkzCsMIeiMTT2kheduxU7O0N4/MnKxVeWoJ+Xajt61VCeI1d1XKhwxACHIomHH8PDZ/HuiRIxMIRrkV2/eCpNagNeFDt8+Ck2S247dIjh0R9CYJQOpwIjc8BuJeINC9uH4BriKgGwE/yuSkzW3btYeYfAfiRyf5nADyTz/3y4Wt/WQFAmfBagn787GPz8c2/vW967p2XL8BvX9+CFWpvhy//+V392Ls7uvTwV7sS4plMqA8M8QPs7lE6ofWGY+gNx9McwjV+D2684FD9vd+QZb1LNY/lcv9ff/oYPL9mDx5d3o43N3fip8+ux+8/eyxC0QSmNObu0+geNC8mGLUIuTVGmfWFU9rNR492HrUlCELhcWKeWs7MRwA4CsBRzDyfmd9h5gFmfri4wys/XjVK6OMLp+LmD6VSQy6cn4pWmtpUhZ9/3Lwv1bLtqXLjds2KzNBKZWjc/tJGvLR2L+ardaYabVb8xixrzadid34m5x0+Ab/8xFH45KKpeu7H3a9sRihDw3GC3+uyNE9F4gnLgoeXLEgJiOo8yr8LglB4nAiNrUR0D4CFAHqLPJ6Kw2cILb3yhOn42xdOwLZbLkxb1Y+rDWD2OPMw1n19KdNOrv0eiAiLMiq5XnNfqi2sXVb07ZcdjUZVs2jrGoTXTWk+EKfMn9Kgb6/Y2Y1dPWFsNMnQtsPndiFqUdbEStMAgJ99LCWIcxF4giAUDyez2CEAXgSwGIoAuYOIPlDcYVUOXsOE5nKRXo7bOGG3BJXtuz+1AD/+aHqm9KNqtNXi083LhwwHu+ZHE+oD+PnHjwSgaBqN1b68EuKMEV/axH/8TMtIa1OsHOHxRBJJThfMRlwu0sNspzZlD1cWBKH4ZBUazBxi5oeZ+WIARwOoA/DPoo+sQvC6zSdao/lHS3Q7/4iJuPy4afiPU2bipx+bj/F1ft0ZPqPFPrHPClb7XZ1vqNGvkc1MpPkB1u7uzdsJ/gGTartftKifZTeOgejQmAkt4stOAzt8klJba+IYbuojCJWEI3sJEZ1KRHdB6eQXAPCJoo6qgrCrcTS1yTzv4oYLDsUnFk6F0SKTj2nIyJWGarYzWmpwx+VH4+Q59uXTjY7y8XlOumZlT2odhO0aaarxoS8cxw2PpgcSRC36gxu54/Kjcf35h2BOlmx6QRBKQ1aPJhFtA/AugIcBfJOZx1SQvNemXMYLXz8VcZuGScYktOo8s5i1jyAAjy8+Cd99YhV+8fEjMcemFIjGEZNTFXCvyShPki+1fo9trw0zmlXz3YNLduInF6f8FJq5y2eRBwMA4+oC+MKphTftCYKQH040jfnM/FFmfhDABCL6byIqao5EJWEnNAJet20dpLSQ2Dw1DS2hbWJ9FY6a2oAnv/wBRwIDUBzpf/78cTj/8Ak4aVZufggjv/70MYYPzf16qwRuzc+Ra4CAIAjlw8lfa5CIvk5E7wBYrV5zWXGHVTkMZ0LTVtjHTm/EEVPqs5xtzpdPn41/XX8GpjXn5wg+cVYL7v70MTkVGMzkvMMn4N6rlNIi+bSvNBZqfHNzp74dTSh5KFLmXBBGDpZ/rWq12FcAvAqgGcA1AHYz8/eZeWWJxld2vDmaYoz88hNH4aKjJuFPnzvONOvZCS4XOa5ZVUxmtyrajVZIMBeOn9mMR9WeycaGSk4c4YIgVBZ2hvY7ALwJ4HJmXgoARDTmKsUFhuHAntFSg19ddnQBR1M+pjRW4ZoPzEhLuMuF+ZPrQZRer0uEhiCMPOyExkQAHwfwCyKaAMURPuaK/lRJJjIAReP57w/m3yzR43ahvsqLAwOpZEcn0VOCIFQWln+tzNzJzL9m5lMBnAmgG8BeIlpLRD8u1QDLjQiNwtFU40PXQKq8uwgNQRh5OPprZeY2Zv4FMy+E0mY1XNxhVQ65lgEXrGms9uGAmXnKLc9YEEYKOS/xmHkDM/+gGIOpRAKiaRSMoN+Tlhmuaxo25VAEQags5K81C/PzDJUVhhL0e9AfMQgNNeTWqvaUIAiVhzRbtmDu+FrMaKkZ0sVOyJ+g34N+Q56HJPcJwsgj618rKXyaiL6rvp9GRIuKP7TykmRGHkVhBRuCAY/eNx1IlRERR7ggjByc/LXeBeAEAJ9U3/cBuLNoI6oQGIBLpEZBqfF7MBBNIKnW69rXG4HbRajJsy6XIAilx4nQOI6ZF0ONmGLmLgCjviOOaBqFp1YVDpoz/L22bhw8vlaCDQRhBOFEaMSIyA1l8Q0iagVg3oZtFMGMvJoWCdZo3fc61G6G7d2DmNEizZUEYSThRGjcDuAxAOOI6EcA3gAw6pP7mBnDKDslmHCQWnRx+4EQAKAnFENDns2hBEEoD1mNycz8ABEtg5IVTgA+wsxriz6yMpPkvKqACzZoQmNHZwjMjO7BmN7HXBCEkYGTJkzTAIQA/N24j5l3FHNg5YbB4ggvMK1BP6p9bmzrHEBfJI5EktFQJZqGIIwknIStPA3Fn0FQWr3OALAewGFFHFfZSSbFp1FoiAgHNdfg9//apvdOrxdNQxBGFE7MU0cY3xPRAgBfKtqIKgSW6Kmi0Kw6w//+3i4AwLja3PtzCIJQPvKpPbUcwHHDuSkR/ZCI3ieiFUT0PBFNUvcTEd1ORJvU4wsM11xJRBvV15XDub8TlDyNYt9l7OF1pz/Ug5pryjQSQRDywYlP4z8Nb10AFgDYNcz7/oyZ/1v9/K8C+C6ALwA4H8Ac9XUcgLsBHEdETQBuBrAQyny+jIieVHNGikKSGSSu8ILTVJOuWUxqCJRpJIIg5IMTn0atYTsOxcfxyHBuysy9hrc1UHNAoJRdv5+ZGcBbRNRARBMBnAbgBWY+AABE9AKA8wA8OJxx2I8RcEl1i4Jz4wWHoKnGiyuOn44Ne/vyboMrCEJ5sBUaalJfLTP/V6FvrOZ8fAZAD4DT1d2TAew0nNam7rPab/a51wK4FgCmTZuW9/iSktxXFJqDftx0odIBcFqzJPYJwkjDci1NRB5mTgA4KZ8PJqIXiWiVyesiAGDmm5h5KoAHAHw5r9GbwMz3MPNCZl7Y2to6nM8R45QgCEIGdprGEij+ixVE9CSAvwIY0A4y86N2H8zMZzkcwwMAnoHis2gHMNVwbIq6rx2Kicq4/1WHn58XUrBQEARhKE6s9gEAnQDOAPBBAB9S/80bIppjeHsRgHXq9pMAPqNGUR0PoIeZdwN4DsA5RNRIRI0AzlH3FQ0pWCgIgjAUO01jnBo5tQqp5D4NNr/EMbcQ0VwohQ+3Q4mcAhSN4wIAm6BkoX8WAJj5ABH9EMA76nk/0JzixYJZNA1BEIRM7ISGG0AQ5iWYhiU0mPkSi/0MYLHFsXsB3Duc++aCaBqCIAhDsRMau5n5ByUbSYXBDMnTEARByMDOpzGmZ0wpjS4IgjAUO6FxZslGUYEoeRrlHoUgCEJlYSk0iu1ornSkNLogCMJQpFCGBZIRLgiCMBQRGhZIaXRBEIShiNCwQMnTKPcoBEEQKgsRGhZIaXRBEIShiNCwQJowCYIgDEWEhgnMrCT3iVNDEAQhDREaJrBaJEVkhiAIQjoiNEzQCmtJnoYgCEI6IjRMSKqqhogMQRCEdERomKCZp1ziCRcEQUhDhIYJuqYhMkMQBCENERom6I5wMVAJgiCkIULDBFZd4WKdEgRBSEeEhglJCbkVBEEwRYSGCcyapiFSQxAEwYgIDRNSmoYIDUEQBCMiNExgydMQBEEwRYSGCXqehkgNQRCENERomJDK0xCpIQiCYESEhglejwsXHjERBzVXl3sogiAIFUVZhQYRfYOImIha1PdERLcT0SYiep+IFhjOvZKINqqvK4s5rrqAF3d+agFOmzuumLcRBEEYcXjKdWMimgrgHAA7DLvPBzBHfR0H4G4AxxFRE4CbASyEUoR2GRE9ycxdpR21IAjC2KacmsZtAL6FVCVyALgIwP2s8BaABiKaCOBcAC8w8wFVULwA4LySj1gQBGGMUxahQUQXAWhn5vcyDk0GsNPwvk3dZ7VfEARBKCFFM08R0YsAJpgcugnAjVBMU8W477UArgWAadOmFeMWgiAIY5aiCQ1mPstsPxEdAWAGgPfUkNYpAJYT0SIA7QCmGk6fou5rB3Baxv5XLe57D4B7AGDhwoVsdo4gCIKQHyU3TzHzSmYex8zTmXk6FFPTAmbeA+BJAJ9Ro6iOB9DDzLsBPAfgHCJqJKJGKFrKc6UeuyAIwlinbNFTFjwD4AIAmwCEAHwWAJj5ABH9EMA76nk/YOYD5RmiIAjC2KXsQkPVNrRtBrDY4rx7AdxbomEJgiAIJpBWnG80QkQdALYP4yNaAOwv0HBGI/J87JHnkx15RvaU6/kcxMytZgdGtdAYLkS0lJkXlnsclYo8H3vk+WRHnpE9lfh8pPaUIAiC4BgRGoIgCIJjRGjYc0+5B1DhyPOxR55PduQZ2VNxz0d8GoIgCIJjRNMQBEEQHCNCQxAEQXCMCA0TiOg8IlqvNoO6vtzjKQdENJWIXiGiNUS0moiuU/c3EdELajOsF9SyLrYNtEYzROQmoneJ6Cn1/Qwielt9Dn8hIp+636++36Qen17WgZcIImogor8R0ToiWktEJ8hvKAURfV39+1pFRA8SUaDSf0MiNDIgIjeAO6E0hJoH4JNENK+8oyoLcQDfYOZ5AI4HsFh9DtcDeImZ5wB4SX0PpDfQuhZKA62xwHUA1hre3wrgNmaeDaALwDXq/msAdKn7b1PPGwv8CsCzzHwIgCOhPCv5DQEgoskAvgpgITMfDsAN4DJU+m+ImeVleAE4AcBzhvc3ALih3OMq9wvAEwDOBrAewER130QA69Xt3wD4pOF8/bzR+oJSbfklAGcAeAoAQcne9WT+lqAU2DxB3fao51G5v0ORn089gK2Z31N+Q/r30/oENam/iaegNJyr6N+QaBpDkYZPGahq8NEA3gYwnpXKwwCwB8B4dXssPrf/hdJ9Mqm+bwbQzcxx9b3xGejPRz3eo54/mpkBoAPA71UT3v8RUQ3kNwQAYOZ2AD+H0vJ6N5TfxDJU+G9IhIZgCxEFATwC4GvM3Gs8xsqSZ0zGbBPRBwHsY+Zl5R5LBeMBsADA3cx8NIABpExRAMb8b6gRSovrGQAmAajBCGhjLUJjKFaNoMYcROSFIjAeYOZH1d171b7tUP/dp+4fa8/tJAAfJqJtAB6CYqL6FZS+9lr1aOMz0J+PerweQGcpB1wG2gC0MfPb6vu/QREi8htSOAvAVmbuYOYYgEeh/K4q+jckQmMo7wCYo0Yw+KA4pp4s85hKDiltFX8HYC0z/9Jw6EkAV6rbV0LxdWj7zRpojUqY+QZmnsJKaf/LALzMzJ8C8AqAj6mnZT4f7bl9TD1/VK+wWWmstpOI5qq7zgSwBvIb0tgB4Hgiqlb/3rTnU9m/oXI7gyrxBaUR1AYAmwHcVO7xlOkZfACK2eB9ACvU1wVQbKgvAdgI4EUATer5BCXqbDOAlVAiQsr+PUr0rE4D8JS6PRPAEiiNxP4KwK/uD6jvN6nHZ5Z73CV6NkcBWKr+jh4H0Ci/obTn830A6wCsAvBHAP5K/w1JGRFBEATBMWKeEgRBEBwjQkMQBEFwjAgNQRAEwTEiNARBEATHiNAQBEEQHCNCQxBygIgSRLTC8LKtgkxEXyCizxTgvtuIqGW4nyMIw0VCbgUhB4ion5mDZbjvNih5C/tLfW9BMCKahiAUAFUT+CkRrSSiJUQ0W93/PSL6L3X7q2p/kveJ6CF1XxMRPa7ue4uI5qv7m4noebXXwv9BSXzT7vVp9R4riOg3ajl/QSgJIjQEITeqMsxTlxqO9TDzEQDugFIBN5PrARzNzPMBfEHd930A76r7bgRwv7r/ZgBvMPNhAB4DMA0AiOhQAJcCOImZjwKQAPCpQn5BQbDDk/0UQRAMDKqTtRkPGv69zeT4+wAeIKLHoZTUAJRyLZcAADO/rGoYdQBOAXCxuv9pIupSzz8TwDEA3lHKFaEKqYJ/glB0RGgIQuFgi22NC6EIgw8BuImIjsjjHgTgPma+IY9rBWHYiHlKEArHpYZ/3zQeICIXgKnM/AqAb0Mpax0E8DpU8xIRnQZgPyt9S14DcLm6/3wohf4ApdDfx4honHqsiYgOKt5XEoR0RNMQhNyoIqIVhvfPMrMWdttIRO8DiAD4ZMZ1bgB/IqJ6KNrC7czcTUTfA3Cvel0IqdLX3wfwIBGtBvBvKGW0wcxriOg7AJ5XBVEMwGIA2wv8PQXBFAm5FYQCICGxwlhBzFOCIAiCY0TTEARBEBwjmoYgCILgGBEagiAIgmNEaAiCIAiOEaEhCIIgOEaEhiAIguCY/w8B2N4AX1lUzwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 2305.831007003784 s\n"
     ]
    }
   ],
   "source": [
    "run(total_trials=1, total_episodes=1500, buffer_capacity=500000, tau=0.004, critic_lr=0.002, \n",
    "    actor_lr=0.001, start_steps=20000, continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0e59ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.341841697692871s\n",
      "0.8937985897064209s\n",
      "0.737602949142456s\n",
      "1.1789038181304932s\n",
      "1.5776898860931396s\n",
      "2.927838087081909s\n",
      "0.8583450317382812s\n",
      "2.054826259613037s\n",
      "0.9302225112915039s\n",
      "1.343721628189087s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(render=False, continuous=True, actor_weights='Weights/actor-trial0_LunarLander-v2_True_2022.8.14.21.46.30.h5', seed=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
